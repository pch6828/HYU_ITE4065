diff --git libmariadb libmariadb
--- libmariadb
+++ libmariadb
@@ -1 +1 @@
-Subproject commit 735a7299dbae19cc2b82b9697becaf90e9b43047
+Subproject commit 735a7299dbae19cc2b82b9697becaf90e9b43047-dirty
diff --git mysys/my_largepage.c mysys/my_largepage.c
index 0fdc4e17a26..1948adf69a2 100644
--- mysys/my_largepage.c
+++ mysys/my_largepage.c
@@ -28,8 +28,8 @@
 #endif
 
 #ifdef HAVE_SOLARIS_LARGE_PAGES
-#if defined(__sun__) && defined(__GNUC__) && defined(__cplusplus) \
-    && defined(_XOPEN_SOURCE)
+#if defined(__sun__) && defined(__GNUC__) && defined(__cplusplus) &&          \
+    defined(_XOPEN_SOURCE)
 /* memcntl exist within sys/mman.h, but under-defines what is need to use it */
 extern int memcntl(caddr_t, size_t, int, caddr_t, int, int);
 #endif /* __sun__ ... */
@@ -67,7 +67,6 @@ static int size_t_cmp(const void *a, const void *b)
 }
 #endif /* defined(HAVE_GETPAGESIZES) || defined(__linux__) */
 
-
 #if defined(__linux__) || defined(HAVE_GETPAGESIZES)
 #define my_large_page_sizes_length 8
 static size_t my_large_page_sizes[my_large_page_sizes_length];
@@ -77,7 +76,7 @@ static size_t my_large_page_sizes[my_large_page_sizes_length];
   Linux-specific function to determine the sizes of large pages
 */
 #ifdef __linux__
-static inline my_bool my_is_2pow(size_t n) { return !((n) & ((n) - 1)); }
+static inline my_bool my_is_2pow(size_t n) { return !((n) & ((n) -1)); }
 
 static void my_get_large_page_sizes(size_t sizes[my_large_page_sizes_length])
 {
@@ -102,8 +101,8 @@ static void my_get_large_page_sizes(size_t sizes[my_large_page_sizes_length])
         {
           my_printf_error(0,
                           "non-power of 2 large page size (%zu) found,"
-                          " skipping", MYF(ME_NOTE | ME_ERROR_LOG_ONLY),
-                          sizes[i]);
+                          " skipping",
+                          MYF(ME_NOTE | ME_ERROR_LOG_ONLY), sizes[i]);
           sizes[i]= 0;
           continue;
         }
@@ -119,7 +118,6 @@ static void my_get_large_page_sizes(size_t sizes[my_large_page_sizes_length])
   DBUG_VOID_RETURN;
 }
 
-
 #elif defined(HAVE_GETPAGESIZES)
 static void my_get_large_page_sizes(size_t sizes[my_large_page_sizes_length])
 {
@@ -136,10 +134,12 @@ static void my_get_large_page_sizes(size_t sizes[my_large_page_sizes_length])
   }
 }
 
-
 #elif defined(_WIN32)
 #define my_large_page_sizes_length 0
-#define my_get_large_page_sizes(A) do {} while(0)
+#define my_get_large_page_sizes(A)                                            \
+  do                                                                          \
+  {                                                                           \
+  } while (0)
 
 #else
 #define my_large_page_sizes_length 1
@@ -150,7 +150,6 @@ static void my_get_large_page_sizes(size_t sizes[])
 }
 #endif
 
-
 /**
   Returns the next large page size smaller or equal to the passed in size.
 
@@ -167,8 +166,8 @@ static void my_get_large_page_sizes(size_t sizes[])
   *start is updated during search and can be used to search again if 0 isn't
   returned.
 
-  @returns the next size found. *start will be incremented to the next potential
-           size.
+  @returns the next size found. *start will be incremented to the next
+  potential size.
   @retval  a large page size that is valid on this system or 0 if no large page
            size possible.
 */
@@ -177,7 +176,8 @@ static size_t my_next_large_page_size(size_t sz, int *start)
 {
   DBUG_ENTER("my_next_large_page_size");
 
-  while (*start < my_large_page_sizes_length && my_large_page_sizes[*start] > 0)
+  while (*start < my_large_page_sizes_length &&
+         my_large_page_sizes[*start] > 0)
   {
     size_t cur= *start;
     (*start)++;
@@ -190,7 +190,6 @@ static size_t my_next_large_page_size(size_t sz, int *start)
 }
 #endif /* defined(MMAP) || !defined(_WIN32) */
 
-
 int my_init_large_pages(my_bool super_large_pages)
 {
 #ifdef _WIN32
@@ -199,7 +198,8 @@ int my_init_large_pages(my_bool super_large_pages)
     my_printf_error(EE_PERM_LOCK_MEMORY,
                     "Lock Pages in memory access rights required for use with"
                     " large-pages, see https://mariadb.com/kb/en/library/"
-                    "mariadb-memory-allocation/#huge-pages", MYF(MY_WME));
+                    "mariadb-memory-allocation/#huge-pages",
+                    MYF(MY_WME));
   }
   my_large_page_size= GetLargePageMinimum();
 #endif
@@ -236,28 +236,27 @@ int my_init_large_pages(my_bool super_large_pages)
     mpss.mha_flags= 0;
     if (memcntl(NULL, 0, MC_HAT_ADVISE, (caddr_t) &mpss, 0, 0))
     {
-      my_error(EE_MEMCNTL, MYF(ME_WARNING | ME_ERROR_LOG_ONLY), "MC_HAT_ADVISE",
-               "MHA_MAPSIZE_BSSBRK");
+      my_error(EE_MEMCNTL, MYF(ME_WARNING | ME_ERROR_LOG_ONLY),
+               "MC_HAT_ADVISE", "MHA_MAPSIZE_BSSBRK");
     }
     mpss.mha_cmd= MHA_MAPSIZE_STACK;
     if (memcntl(NULL, 0, MC_HAT_ADVISE, (caddr_t) &mpss, 0, 0))
     {
-      my_error(EE_MEMCNTL, MYF(ME_WARNING | ME_ERROR_LOG_ONLY), "MC_HAT_ADVISE",
-               "MHA_MAPSIZE_STACK");
+      my_error(EE_MEMCNTL, MYF(ME_WARNING | ME_ERROR_LOG_ONLY),
+               "MC_HAT_ADVISE", "MHA_MAPSIZE_STACK");
     }
   }
 #endif /* HAVE_SOLARIS_LARGE_PAGES */
   return 0;
 }
 
-
 #if defined(HAVE_MMAP) && !defined(_WIN32)
 /* Solaris for example has only MAP_ANON, FreeBSD has MAP_ANONYMOUS and
 MAP_ANON but MAP_ANONYMOUS is marked "for compatibility" */
 #if defined(MAP_ANONYMOUS)
-#define OS_MAP_ANON     MAP_ANONYMOUS
+#define OS_MAP_ANON MAP_ANONYMOUS
 #elif defined(MAP_ANON)
-#define OS_MAP_ANON     MAP_ANON
+#define OS_MAP_ANON MAP_ANON
 #else
 #error unsupported mmap - no MAP_ANON{YMOUS}
 #endif
@@ -299,7 +298,7 @@ uchar *my_large_malloc(size_t *size, myf my_flags)
       }
       else
       {
-        my_error(EE_OUTOFMEMORY, MYF(ME_BELL+ME_ERROR_LOG), *size);
+        my_error(EE_OUTOFMEMORY, MYF(ME_BELL + ME_ERROR_LOG), *size);
       }
     }
     if (my_use_large_pages)
@@ -308,7 +307,7 @@ uchar *my_large_malloc(size_t *size, myf my_flags)
       ptr= VirtualAlloc(NULL, *size, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE);
       if (!ptr && my_flags & MY_WME)
       {
-        my_error(EE_OUTOFMEMORY, MYF(ME_BELL+ME_ERROR_LOG), *size);
+        my_error(EE_OUTOFMEMORY, MYF(ME_BELL + ME_ERROR_LOG), *size);
       }
     }
   }
@@ -328,12 +327,12 @@ uchar *my_large_malloc(size_t *size, myf my_flags)
       /* this might be 0, in which case we do a standard mmap */
       if (large_page_size)
       {
-#if defined(MAP_HUGETLB) /* linux 2.6.32 */
+#if defined(MAP_HUGETLB)    /* linux 2.6.32 */
         mapflag|= MAP_HUGETLB;
 #if defined(MAP_HUGE_SHIFT) /* Linux-3.8+ */
         mapflag|= my_bit_log2_size_t(large_page_size) << MAP_HUGE_SHIFT;
 #else
-# warning "No explicit large page (HUGETLB pages) support in Linux < 3.8"
+#warning "No explicit large page (HUGETLB pages) support in Linux < 3.8"
 #endif
 #elif defined(MAP_ALIGNED)
         mapflag|= MAP_ALIGNED(my_bit_log2_size_t(large_page_size));
@@ -349,22 +348,23 @@ uchar *my_large_malloc(size_t *size, myf my_flags)
       }
     }
     ptr= mmap(NULL, aligned_size, PROT_READ | PROT_WRITE, mapflag, -1, 0);
-    if (ptr == (void*) -1)
+    if (ptr == (void *) -1)
     {
       ptr= NULL;
       if (my_flags & MY_WME)
       {
         if (large_page_size)
         {
-          my_printf_error(EE_OUTOFMEMORY,
-                          "Couldn't allocate %zu bytes (Large/HugeTLB memory "
-                          "page size %zu); errno %u; continuing to smaller size",
-                          MYF(ME_WARNING | ME_ERROR_LOG_ONLY),
-                          aligned_size, large_page_size, errno);
+          my_printf_error(
+              EE_OUTOFMEMORY,
+              "Couldn't allocate %zu bytes (Large/HugeTLB memory "
+              "page size %zu); errno %u; continuing to smaller size",
+              MYF(ME_WARNING | ME_ERROR_LOG_ONLY), aligned_size,
+              large_page_size, errno);
         }
         else
         {
-          my_error(EE_OUTOFMEMORY, MYF(ME_BELL+ME_ERROR_LOG), aligned_size);
+          my_error(EE_OUTOFMEMORY, MYF(ME_BELL + ME_ERROR_LOG), aligned_size);
         }
       }
       /* try next smaller memory size */
@@ -397,13 +397,13 @@ uchar *my_large_malloc(size_t *size, myf my_flags)
 
   if (ptr != NULL)
   {
+
     MEM_MAKE_DEFINED(ptr, *size);
   }
 
   DBUG_RETURN(ptr);
 }
 
-
 /**
   General large pages deallocator.
   Tries to deallocate memory as if it was from large pages pool and falls back
@@ -430,12 +430,12 @@ void my_large_free(void *ptr, size_t size)
   {
     my_error(EE_BADMEMORYRELEASE, MYF(ME_ERROR_LOG_ONLY), ptr, size, errno);
   }
-# if !__has_feature(memory_sanitizer)
+#if !__has_feature(memory_sanitizer)
   else
   {
     MEM_MAKE_ADDRESSABLE(ptr, size);
   }
-# endif
+#endif
 #elif defined(_WIN32)
   /*
      When RELEASE memory, the size parameter must be 0.
@@ -446,12 +446,12 @@ void my_large_free(void *ptr, size_t size)
     my_error(EE_BADMEMORYRELEASE, MYF(ME_ERROR_LOG_ONLY), ptr, size,
              GetLastError());
   }
-# if !__has_feature(memory_sanitizer)
+#if !__has_feature(memory_sanitizer)
   else
   {
     MEM_MAKE_ADDRESSABLE(ptr, size);
   }
-# endif
+#endif
 #else
   my_free_lock(ptr);
 #endif
diff --git storage/innobase/buf/buf0buf.cc storage/innobase/buf/buf0buf.cc
index 1c126191df3..76e62e39f03 100644
--- storage/innobase/buf/buf0buf.cc
+++ storage/innobase/buf/buf0buf.cc
@@ -24,12 +24,12 @@ this program; if not, write to the Free Software Foundation, Inc.,
 
 *****************************************************************************/
 
-/**************************************************//**
-@file buf/buf0buf.cc
-The database buffer buf_pool
+/**************************************************/ /**
+ @file buf/buf0buf.cc
+ The database buffer buf_pool
 
-Created 11/5/1995 Heikki Tuuri
-*******************************************************/
+ Created 11/5/1995 Heikki Tuuri
+ *******************************************************/
 
 #include "assume_aligned.h"
 #include "mtr0types.h"
@@ -76,38 +76,41 @@ using st_::span;
 #include <numaif.h>
 struct set_numa_interleave_t
 {
-	set_numa_interleave_t()
-	{
-		if (srv_numa_interleave) {
-
-			struct bitmask *numa_mems_allowed = numa_get_mems_allowed();
-			ib::info() << "Setting NUMA memory policy to"
-				" MPOL_INTERLEAVE";
-			if (set_mempolicy(MPOL_INTERLEAVE,
-					  numa_mems_allowed->maskp,
-					  numa_mems_allowed->size) != 0) {
-
-				ib::warn() << "Failed to set NUMA memory"
-					" policy to MPOL_INTERLEAVE: "
-					<< strerror(errno);
-			}
-			numa_bitmask_free(numa_mems_allowed);
-		}
-	}
-
-	~set_numa_interleave_t()
-	{
-		if (srv_numa_interleave) {
-
-			ib::info() << "Setting NUMA memory policy to"
-				" MPOL_DEFAULT";
-			if (set_mempolicy(MPOL_DEFAULT, NULL, 0) != 0) {
-				ib::warn() << "Failed to set NUMA memory"
-					" policy to MPOL_DEFAULT: "
-					<< strerror(errno);
-			}
-		}
-	}
+  set_numa_interleave_t()
+  {
+    if (srv_numa_interleave)
+    {
+
+      struct bitmask *numa_mems_allowed= numa_get_mems_allowed();
+      ib::info() << "Setting NUMA memory policy to"
+                    " MPOL_INTERLEAVE";
+      if (set_mempolicy(MPOL_INTERLEAVE, numa_mems_allowed->maskp,
+                        numa_mems_allowed->size) != 0)
+      {
+
+        ib::warn() << "Failed to set NUMA memory"
+                      " policy to MPOL_INTERLEAVE: "
+                   << strerror(errno);
+      }
+      numa_bitmask_free(numa_mems_allowed);
+    }
+  }
+
+  ~set_numa_interleave_t()
+  {
+    if (srv_numa_interleave)
+    {
+
+      ib::info() << "Setting NUMA memory policy to"
+                    " MPOL_DEFAULT";
+      if (set_mempolicy(MPOL_DEFAULT, NULL, 0) != 0)
+      {
+        ib::warn() << "Failed to set NUMA memory"
+                      " policy to MPOL_DEFAULT: "
+                   << strerror(errno);
+      }
+    }
+  }
 };
 
 #define NUMA_MEMPOLICY_INTERLEAVE_IN_SCOPE set_numa_interleave_t scoped_numa
@@ -116,19 +119,19 @@ struct set_numa_interleave_t
 #endif /* HAVE_LIBNUMA */
 
 /*
-		IMPLEMENTATION OF THE BUFFER POOL
-		=================================
+                IMPLEMENTATION OF THE BUFFER POOL
+                =================================
 
-		Buffer frames and blocks
-		------------------------
+                Buffer frames and blocks
+                ------------------------
 Following the terminology of Gray and Reuter, we call the memory
 blocks where file pages are loaded buffer frames. For each buffer
 frame there is a control block, or shortly, a block, in the buffer
 control array. The control info which does not need to be stored
 in the file along with the file page, resides in the control block.
 
-		Buffer pool struct
-		------------------
+                Buffer pool struct
+                ------------------
 The buffer buf_pool contains a single mutex which protects all the
 control data structures of the buf_pool. The content of a buffer frame is
 protected by a separate read-write lock in its control block, though.
@@ -148,8 +151,8 @@ create a separate mutex for the page hash table. On Pentium,
 accessing the hash table takes 2 microseconds, about half
 of the total buf_pool.mutex hold time.
 
-		Control blocks
-		--------------
+                Control blocks
+                --------------
 
 The control block contains, for instance, the bufferfix count
 which is incremented when a thread wants a file page to be fixed
@@ -175,8 +178,8 @@ possibly, extra space required on non-leaf pages for memory pointers.
 A simpler solution is just to speed up the hash table mechanism
 in the database, using tables whose size is a power of 2.
 
-		Lists of blocks
-		---------------
+                Lists of blocks
+                ---------------
 
 There are several lists of control blocks.
 
@@ -227,8 +230,8 @@ BUF_BLOCK_MEMORY that the buddy allocator requests from the buffer
 pool.  The buddy allocator is solely used for allocating control
 blocks for compressed pages (buf_page_t) and compressed page frames.
 
-		Loading a file page
-		-------------------
+                Loading a file page
+                -------------------
 
 First, a victim block for replacement has to be found in the
 buf_pool. It is taken from the free list or searched for from the
@@ -242,8 +245,8 @@ A thread may request the above operation using the function
 buf_page_get(). It may then continue to request a lock on the frame.
 The lock is granted when the io-handler releases the x-lock.
 
-		Read-ahead
-		----------
+                Read-ahead
+                ----------
 
 The read-ahead mechanism is intended to be intelligent and
 isolated from the semantically higher levels of the database
@@ -282,7 +285,7 @@ the read requests for the whole area.
 void page_hash_latch::read_lock_wait()
 {
   /* First, try busy spinning for a while. */
-  for (auto spin= srv_n_spin_wait_rounds; spin--; )
+  for (auto spin= srv_n_spin_wait_rounds; spin--;)
   {
     ut_delay(srv_spin_wait_delay);
     if (read_trylock())
@@ -299,7 +302,7 @@ void page_hash_latch::write_lock_wait()
   write_lock_wait_start();
 
   /* First, try busy spinning for a while. */
-  for (auto spin= srv_n_spin_wait_rounds; spin--; )
+  for (auto spin= srv_n_spin_wait_rounds; spin--;)
   {
     if (write_lock_poll())
       return;
@@ -316,7 +319,7 @@ void page_hash_latch::write_lock_wait()
 constexpr int WAIT_FOR_READ= 100;
 constexpr int WAIT_FOR_WRITE= 100;
 /** Number of attempts made to read in a page in the buffer pool */
-constexpr ulint	BUF_PAGE_READ_MAX_RETRIES= 100;
+constexpr ulint BUF_PAGE_READ_MAX_RETRIES= 100;
 /** The maximum portion of the buffer pool that can be used for the
 read-ahead buffer.  (Divide buf_pool size by this amount) */
 constexpr uint32_t BUF_READ_AHEAD_PORTION= 32;
@@ -334,7 +337,7 @@ buf_pool_t::chunk_t::map *buf_pool_t::chunk_t::map_ref;
 
 #ifdef UNIV_DEBUG
 /** Disable resizing buffer pool to make assertion code not expensive. */
-my_bool			buf_disable_resize_buffer_pool_debug = TRUE;
+my_bool buf_disable_resize_buffer_pool_debug= TRUE;
 
 /** This is used to insert validation operations in execution
 in the debug version */
@@ -343,51 +346,47 @@ static ulint buf_dbg_counter;
 
 /** Macro to determine whether the read of write counter is used depending
 on the io_type */
-#define MONITOR_RW_COUNTER(io_type, counter)		\
-	((io_type == BUF_IO_READ)			\
-	 ? (counter##_READ)				\
-	 : (counter##_WRITTEN))
-
+#define MONITOR_RW_COUNTER(io_type, counter)                                  \
+  ((io_type == BUF_IO_READ) ? (counter##_READ) : (counter##_WRITTEN))
 
 /** Decrypt a page for temporary tablespace.
 @param[in,out]	tmp_frame	Temporary buffer
 @param[in]	src_frame	Page to decrypt
 @return true if temporary tablespace decrypted, false if not */
-static bool buf_tmp_page_decrypt(byte* tmp_frame, byte* src_frame)
+static bool buf_tmp_page_decrypt(byte *tmp_frame, byte *src_frame)
 {
-	if (buf_is_zeroes(span<const byte>(src_frame, srv_page_size))) {
-		return true;
-	}
-
-	/* read space & lsn */
-	uint header_len = FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION;
-
-	/* Copy FIL page header, it is not encrypted */
-	memcpy(tmp_frame, src_frame, header_len);
-
-	/* Calculate the offset where decryption starts */
-	const byte* src = src_frame + header_len;
-	byte* dst = tmp_frame + header_len;
-	uint srclen = uint(srv_page_size)
-		- (header_len + FIL_PAGE_FCRC32_CHECKSUM);
-	ulint offset = mach_read_from_4(src_frame + FIL_PAGE_OFFSET);
-
-	if (!log_tmp_block_decrypt(src, srclen, dst,
-				   (offset * srv_page_size))) {
-		return false;
-	}
-
-	static_assert(FIL_PAGE_FCRC32_CHECKSUM == 4, "alignment");
-	memcpy_aligned<4>(tmp_frame + srv_page_size - FIL_PAGE_FCRC32_CHECKSUM,
-			  src_frame + srv_page_size - FIL_PAGE_FCRC32_CHECKSUM,
-			  FIL_PAGE_FCRC32_CHECKSUM);
-
-	memcpy_aligned<OS_FILE_LOG_BLOCK_SIZE>(src_frame, tmp_frame,
-					       srv_page_size);
-	srv_stats.pages_decrypted.inc();
-	srv_stats.n_temp_blocks_decrypted.inc();
-
-	return true; /* page was decrypted */
+  if (buf_is_zeroes(span<const byte>(src_frame, srv_page_size)))
+  {
+    return true;
+  }
+
+  /* read space & lsn */
+  uint header_len= FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION;
+
+  /* Copy FIL page header, it is not encrypted */
+  memcpy(tmp_frame, src_frame, header_len);
+
+  /* Calculate the offset where decryption starts */
+  const byte *src= src_frame + header_len;
+  byte *dst= tmp_frame + header_len;
+  uint srclen= uint(srv_page_size) - (header_len + FIL_PAGE_FCRC32_CHECKSUM);
+  ulint offset= mach_read_from_4(src_frame + FIL_PAGE_OFFSET);
+
+  if (!log_tmp_block_decrypt(src, srclen, dst, (offset * srv_page_size)))
+  {
+    return false;
+  }
+
+  static_assert(FIL_PAGE_FCRC32_CHECKSUM == 4, "alignment");
+  memcpy_aligned<4>(tmp_frame + srv_page_size - FIL_PAGE_FCRC32_CHECKSUM,
+                    src_frame + srv_page_size - FIL_PAGE_FCRC32_CHECKSUM,
+                    FIL_PAGE_FCRC32_CHECKSUM);
+
+  memcpy_aligned<OS_FILE_LOG_BLOCK_SIZE>(src_frame, tmp_frame, srv_page_size);
+  srv_stats.pages_decrypted.inc();
+  srv_stats.n_temp_blocks_decrypted.inc();
+
+  return true; /* page was decrypted */
 }
 
 /** Decrypt a page.
@@ -397,109 +396,113 @@ static bool buf_tmp_page_decrypt(byte* tmp_frame, byte* src_frame)
 static bool buf_page_decrypt_after_read(buf_page_t *bpage,
                                         const fil_node_t &node)
 {
-	ut_ad(node.space->referenced());
-	ut_ad(node.space->id == bpage->id().space());
-	const auto flags = node.space->flags;
-
-	byte* dst_frame = bpage->zip.data ? bpage->zip.data :
-		((buf_block_t*) bpage)->frame;
-	bool page_compressed = node.space->is_compressed()
-		&& buf_page_is_compressed(dst_frame, flags);
-	const page_id_t id(bpage->id());
-
-	if (id.page_no() == 0) {
-		/* File header pages are not encrypted/compressed */
-		return (true);
-	}
-
-	if (node.space->purpose == FIL_TYPE_TEMPORARY
-	    && innodb_encrypt_temporary_tables) {
-		buf_tmp_buffer_t* slot = buf_pool.io_buf_reserve();
-		ut_a(slot);
-		slot->allocate();
-
-		if (!buf_tmp_page_decrypt(slot->crypt_buf, dst_frame)) {
-			slot->release();
-			ib::error() << "Encrypted page " << id
-				    << " in file " << node.name;
-			return false;
-		}
-
-		slot->release();
-		return true;
-	}
-
-	/* Page is encrypted if encryption information is found from
-	tablespace and page contains used key_version. This is true
-	also for pages first compressed and then encrypted. */
-
-	buf_tmp_buffer_t* slot;
-	uint key_version = buf_page_get_key_version(dst_frame, flags);
-
-	if (page_compressed && !key_version) {
-		/* the page we read is unencrypted */
-		/* Find free slot from temporary memory array */
-decompress:
-		if (fil_space_t::full_crc32(flags)
-		    && buf_page_is_corrupted(true, dst_frame, flags)) {
-			return false;
-		}
-
-		slot = buf_pool.io_buf_reserve();
-		ut_a(slot);
-		slot->allocate();
-
-decompress_with_slot:
-		ut_d(fil_page_type_validate(node.space, dst_frame));
-
-		ulint write_size = fil_page_decompress(
-			slot->crypt_buf, dst_frame, flags);
-		slot->release();
-		ut_ad(!write_size
-		      || fil_page_type_validate(node.space, dst_frame));
-		ut_ad(node.space->referenced());
-		return write_size != 0;
-	}
-
-	if (key_version && node.space->crypt_data) {
-		/* Verify encryption checksum before we even try to
-		decrypt. */
-		if (!buf_page_verify_crypt_checksum(dst_frame, flags)) {
-decrypt_failed:
-			ib::error() << "Encrypted page " << id
-				    << " in file " << node.name
-				    << " looks corrupted; key_version="
-				    << key_version;
-			return false;
-		}
-
-		slot = buf_pool.io_buf_reserve();
-		ut_a(slot);
-		slot->allocate();
-		ut_d(fil_page_type_validate(node.space, dst_frame));
-
-		/* decrypt using crypt_buf to dst_frame */
-		if (!fil_space_decrypt(node.space, slot->crypt_buf, dst_frame)) {
-			slot->release();
-			goto decrypt_failed;
-		}
-
-		ut_d(fil_page_type_validate(node.space, dst_frame));
-
-		if ((fil_space_t::full_crc32(flags) && page_compressed)
-		    || fil_page_get_type(dst_frame)
-		    == FIL_PAGE_PAGE_COMPRESSED_ENCRYPTED) {
-			goto decompress_with_slot;
-		}
-
-		slot->release();
-	} else if (fil_page_get_type(dst_frame)
-		   == FIL_PAGE_PAGE_COMPRESSED_ENCRYPTED) {
-		goto decompress;
-	}
-
-	ut_ad(node.space->referenced());
-	return true;
+  ut_ad(node.space->referenced());
+  ut_ad(node.space->id == bpage->id().space());
+  const auto flags= node.space->flags;
+
+  byte *dst_frame=
+      bpage->zip.data ? bpage->zip.data : ((buf_block_t *) bpage)->frame;
+  bool page_compressed=
+      node.space->is_compressed() && buf_page_is_compressed(dst_frame, flags);
+  const page_id_t id(bpage->id());
+
+  if (id.page_no() == 0)
+  {
+    /* File header pages are not encrypted/compressed */
+    return (true);
+  }
+
+  if (node.space->purpose == FIL_TYPE_TEMPORARY &&
+      innodb_encrypt_temporary_tables)
+  {
+    buf_tmp_buffer_t *slot= buf_pool.io_buf_reserve();
+    ut_a(slot);
+    slot->allocate();
+
+    if (!buf_tmp_page_decrypt(slot->crypt_buf, dst_frame))
+    {
+      slot->release();
+      ib::error() << "Encrypted page " << id << " in file " << node.name;
+      return false;
+    }
+
+    slot->release();
+    return true;
+  }
+
+  /* Page is encrypted if encryption information is found from
+  tablespace and page contains used key_version. This is true
+  also for pages first compressed and then encrypted. */
+
+  buf_tmp_buffer_t *slot;
+  uint key_version= buf_page_get_key_version(dst_frame, flags);
+
+  if (page_compressed && !key_version)
+  {
+    /* the page we read is unencrypted */
+    /* Find free slot from temporary memory array */
+  decompress:
+    if (fil_space_t::full_crc32(flags) &&
+        buf_page_is_corrupted(true, dst_frame, flags))
+    {
+      return false;
+    }
+
+    slot= buf_pool.io_buf_reserve();
+    ut_a(slot);
+    slot->allocate();
+
+  decompress_with_slot:
+    ut_d(fil_page_type_validate(node.space, dst_frame));
+
+    ulint write_size= fil_page_decompress(slot->crypt_buf, dst_frame, flags);
+    slot->release();
+    ut_ad(!write_size || fil_page_type_validate(node.space, dst_frame));
+    ut_ad(node.space->referenced());
+    return write_size != 0;
+  }
+
+  if (key_version && node.space->crypt_data)
+  {
+    /* Verify encryption checksum before we even try to
+    decrypt. */
+    if (!buf_page_verify_crypt_checksum(dst_frame, flags))
+    {
+    decrypt_failed:
+      ib::error() << "Encrypted page " << id << " in file " << node.name
+                  << " looks corrupted; key_version=" << key_version;
+      return false;
+    }
+
+    slot= buf_pool.io_buf_reserve();
+    ut_a(slot);
+    slot->allocate();
+    ut_d(fil_page_type_validate(node.space, dst_frame));
+
+    /* decrypt using crypt_buf to dst_frame */
+    if (!fil_space_decrypt(node.space, slot->crypt_buf, dst_frame))
+    {
+      slot->release();
+      goto decrypt_failed;
+    }
+
+    ut_d(fil_page_type_validate(node.space, dst_frame));
+
+    if ((fil_space_t::full_crc32(flags) && page_compressed) ||
+        fil_page_get_type(dst_frame) == FIL_PAGE_PAGE_COMPRESSED_ENCRYPTED)
+    {
+      goto decompress_with_slot;
+    }
+
+    slot->release();
+  }
+  else if (fil_page_get_type(dst_frame) == FIL_PAGE_PAGE_COMPRESSED_ENCRYPTED)
+  {
+    goto decompress;
+  }
+
+  ut_ad(node.space->referenced());
+  return true;
 }
 #endif /* !UNIV_INNOCHECKSUM */
 
@@ -508,30 +511,31 @@ static bool buf_page_decrypt_after_read(buf_page_t *bpage,
 @param[in]	checksum_field1		new checksum field
 @param[in]	checksum_field2		old checksum field
 @return true if the page is in crc32 checksum format. */
-bool
-buf_page_is_checksum_valid_crc32(
-	const byte*			read_buf,
-	ulint				checksum_field1,
-	ulint				checksum_field2)
+bool buf_page_is_checksum_valid_crc32(const byte *read_buf,
+                                      ulint checksum_field1,
+                                      ulint checksum_field2)
 {
-	const uint32_t	crc32 = buf_calc_page_crc32(read_buf);
+  const uint32_t crc32= buf_calc_page_crc32(read_buf);
 
 #ifdef UNIV_INNOCHECKSUM
-	if (log_file
-	    && srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_STRICT_CRC32) {
-		fprintf(log_file, "page::" UINT32PF ";"
-			" crc32 calculated = " UINT32PF ";"
-			" recorded checksum field1 = " ULINTPF " recorded"
-			" checksum field2 =" ULINTPF "\n", cur_page_num,
-			crc32, checksum_field1, checksum_field2);
-	}
+  if (log_file &&
+      srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_STRICT_CRC32)
+  {
+    fprintf(log_file,
+            "page::" UINT32PF ";"
+            " crc32 calculated = " UINT32PF ";"
+            " recorded checksum field1 = " ULINTPF " recorded"
+            " checksum field2 =" ULINTPF "\n",
+            cur_page_num, crc32, checksum_field1, checksum_field2);
+  }
 #endif /* UNIV_INNOCHECKSUM */
 
-	if (checksum_field1 != checksum_field2) {
-		return false;
-	}
+  if (checksum_field1 != checksum_field2)
+  {
+    return false;
+  }
 
-	return checksum_field1 == crc32;
+  return checksum_field1 == crc32;
 }
 
 /** Checks if the page is in innodb checksum format.
@@ -539,85 +543,82 @@ buf_page_is_checksum_valid_crc32(
 @param[in]	checksum_field1	new checksum field
 @param[in]	checksum_field2	old checksum field
 @return true if the page is in innodb checksum format. */
-bool
-buf_page_is_checksum_valid_innodb(
-	const byte*			read_buf,
-	ulint				checksum_field1,
-	ulint				checksum_field2)
+bool buf_page_is_checksum_valid_innodb(const byte *read_buf,
+                                       ulint checksum_field1,
+                                       ulint checksum_field2)
 {
-	/* There are 2 valid formulas for
-	checksum_field2 (old checksum field) which algo=innodb could have
-	written to the page:
+  /* There are 2 valid formulas for
+  checksum_field2 (old checksum field) which algo=innodb could have
+  written to the page:
 
-	1. Very old versions of InnoDB only stored 8 byte lsn to the
-	start and the end of the page.
+  1. Very old versions of InnoDB only stored 8 byte lsn to the
+  start and the end of the page.
 
-	2. Newer InnoDB versions store the old formula checksum
-	(buf_calc_page_old_checksum()). */
+  2. Newer InnoDB versions store the old formula checksum
+  (buf_calc_page_old_checksum()). */
 
-	ulint	old_checksum = buf_calc_page_old_checksum(read_buf);
-	ulint	new_checksum = buf_calc_page_new_checksum(read_buf);
+  ulint old_checksum= buf_calc_page_old_checksum(read_buf);
+  ulint new_checksum= buf_calc_page_new_checksum(read_buf);
 
 #ifdef UNIV_INNOCHECKSUM
-	if (log_file
-	    && srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_INNODB) {
-		fprintf(log_file, "page::" UINT32PF ";"
-			" old style: calculated ="
-			" " ULINTPF "; recorded = " ULINTPF "\n",
-			cur_page_num, old_checksum,
-			checksum_field2);
-		fprintf(log_file, "page::" UINT32PF ";"
-			" new style: calculated ="
-			" " ULINTPF "; crc32 = " UINT32PF "; recorded = " ULINTPF "\n",
-			cur_page_num, new_checksum,
-			buf_calc_page_crc32(read_buf), checksum_field1);
-	}
-
-	if (log_file
-	    && srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_STRICT_INNODB) {
-		fprintf(log_file, "page::" UINT32PF ";"
-			" old style: calculated ="
-			" " ULINTPF "; recorded checksum = " ULINTPF "\n",
-			cur_page_num, old_checksum,
-			checksum_field2);
-		fprintf(log_file, "page::" UINT32PF ";"
-			" new style: calculated ="
-			" " ULINTPF "; recorded checksum  = " ULINTPF "\n",
-			cur_page_num, new_checksum,
-			checksum_field1);
-	}
+  if (log_file && srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_INNODB)
+  {
+    fprintf(log_file,
+            "page::" UINT32PF ";"
+            " old style: calculated ="
+            " " ULINTPF "; recorded = " ULINTPF "\n",
+            cur_page_num, old_checksum, checksum_field2);
+    fprintf(log_file,
+            "page::" UINT32PF ";"
+            " new style: calculated ="
+            " " ULINTPF "; crc32 = " UINT32PF "; recorded = " ULINTPF "\n",
+            cur_page_num, new_checksum, buf_calc_page_crc32(read_buf),
+            checksum_field1);
+  }
+
+  if (log_file &&
+      srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_STRICT_INNODB)
+  {
+    fprintf(log_file,
+            "page::" UINT32PF ";"
+            " old style: calculated ="
+            " " ULINTPF "; recorded checksum = " ULINTPF "\n",
+            cur_page_num, old_checksum, checksum_field2);
+    fprintf(log_file,
+            "page::" UINT32PF ";"
+            " new style: calculated ="
+            " " ULINTPF "; recorded checksum  = " ULINTPF "\n",
+            cur_page_num, new_checksum, checksum_field1);
+  }
 #endif /* UNIV_INNOCHECKSUM */
 
+  if (checksum_field2 != mach_read_from_4(read_buf + FIL_PAGE_LSN) &&
+      checksum_field2 != old_checksum)
+  {
+    DBUG_LOG("checksum", "Page checksum crc32 not valid"
+                             << " field1 " << checksum_field1 << " field2 "
+                             << checksum_field2 << " crc32 "
+                             << buf_calc_page_old_checksum(read_buf) << " lsn "
+                             << mach_read_from_4(read_buf + FIL_PAGE_LSN));
+    return (false);
+  }
+
+  /* old field is fine, check the new field */
+
+  /* InnoDB versions < 4.0.14 and < 4.1.1 stored the space id
+  (always equal to 0), to FIL_PAGE_SPACE_OR_CHKSUM */
+
+  if (checksum_field1 != 0 && checksum_field1 != new_checksum)
+  {
+    DBUG_LOG("checksum", "Page checksum crc32 not valid"
+                             << " field1 " << checksum_field1 << " field2 "
+                             << checksum_field2 << " crc32 "
+                             << buf_calc_page_new_checksum(read_buf) << " lsn "
+                             << mach_read_from_4(read_buf + FIL_PAGE_LSN));
+    return (false);
+  }
 
-	if (checksum_field2 != mach_read_from_4(read_buf + FIL_PAGE_LSN)
-	    && checksum_field2 != old_checksum) {
-		DBUG_LOG("checksum",
-			 "Page checksum crc32 not valid"
-			 << " field1 " << checksum_field1
-			 << " field2 " << checksum_field2
-			 << " crc32 " << buf_calc_page_old_checksum(read_buf)
-			 << " lsn " << mach_read_from_4(
-				 read_buf + FIL_PAGE_LSN));
-		return(false);
-	}
-
-	/* old field is fine, check the new field */
-
-	/* InnoDB versions < 4.0.14 and < 4.1.1 stored the space id
-	(always equal to 0), to FIL_PAGE_SPACE_OR_CHKSUM */
-
-	if (checksum_field1 != 0 && checksum_field1 != new_checksum) {
-		DBUG_LOG("checksum",
-			 "Page checksum crc32 not valid"
-			 << " field1 " << checksum_field1
-			 << " field2 " << checksum_field2
-			 << " crc32 " << buf_calc_page_new_checksum(read_buf)
-			 << " lsn " << mach_read_from_4(
-				 read_buf + FIL_PAGE_LSN));
-		return(false);
-	}
-
-	return(true);
+  return (true);
 }
 
 /** Checks if the page is in none checksum format.
@@ -625,80 +626,73 @@ buf_page_is_checksum_valid_innodb(
 @param[in]	checksum_field1	new checksum field
 @param[in]	checksum_field2	old checksum field
 @return true if the page is in none checksum format. */
-bool
-buf_page_is_checksum_valid_none(
-	const byte*			read_buf,
-	ulint				checksum_field1,
-	ulint				checksum_field2)
+bool buf_page_is_checksum_valid_none(const byte *read_buf,
+                                     ulint checksum_field1,
+                                     ulint checksum_field2)
 {
 #ifndef DBUG_OFF
-	if (checksum_field1 != checksum_field2
-	    && checksum_field1 != BUF_NO_CHECKSUM_MAGIC) {
-		DBUG_LOG("checksum",
-			 "Page checksum crc32 not valid"
-			 << " field1 " << checksum_field1
-			 << " field2 " << checksum_field2
-			 << " crc32 " << BUF_NO_CHECKSUM_MAGIC
-			 << " lsn " << mach_read_from_4(read_buf
-							+ FIL_PAGE_LSN));
-	}
+  if (checksum_field1 != checksum_field2 &&
+      checksum_field1 != BUF_NO_CHECKSUM_MAGIC)
+  {
+    DBUG_LOG("checksum", "Page checksum crc32 not valid"
+                             << " field1 " << checksum_field1 << " field2 "
+                             << checksum_field2 << " crc32 "
+                             << BUF_NO_CHECKSUM_MAGIC << " lsn "
+                             << mach_read_from_4(read_buf + FIL_PAGE_LSN));
+  }
 #endif /* DBUG_OFF */
 
 #ifdef UNIV_INNOCHECKSUM
-	if (log_file
-	    && srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_STRICT_NONE) {
-		fprintf(log_file,
-			"page::" UINT32PF "; none checksum: calculated"
-			" = %lu; recorded checksum_field1 = " ULINTPF
-			" recorded checksum_field2 = " ULINTPF "\n",
-			cur_page_num, BUF_NO_CHECKSUM_MAGIC,
-			checksum_field1, checksum_field2);
-	}
+  if (log_file && srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_STRICT_NONE)
+  {
+    fprintf(log_file,
+            "page::" UINT32PF "; none checksum: calculated"
+            " = %lu; recorded checksum_field1 = " ULINTPF
+            " recorded checksum_field2 = " ULINTPF "\n",
+            cur_page_num, BUF_NO_CHECKSUM_MAGIC, checksum_field1,
+            checksum_field2);
+  }
 #endif /* UNIV_INNOCHECKSUM */
 
-	return(checksum_field1 == checksum_field2
-	       && checksum_field1 == BUF_NO_CHECKSUM_MAGIC);
+  return (checksum_field1 == checksum_field2 &&
+          checksum_field1 == BUF_NO_CHECKSUM_MAGIC);
 }
 
 /** Checks whether the lsn present in the page is lesser than the
 peek current lsn.
 @param[in]	check_lsn	lsn to check
 @param[in]	read_buf	page. */
-static void buf_page_check_lsn(bool check_lsn, const byte* read_buf)
+static void buf_page_check_lsn(bool check_lsn, const byte *read_buf)
 {
 #ifndef UNIV_INNOCHECKSUM
-	if (check_lsn && recv_lsn_checks_on) {
-		const lsn_t current_lsn = log_sys.get_lsn();
-		const lsn_t	page_lsn
-			= mach_read_from_8(read_buf + FIL_PAGE_LSN);
-
-		/* Since we are going to reset the page LSN during the import
-		phase it makes no sense to spam the log with error messages. */
-		if (current_lsn < page_lsn) {
-
-			const uint32_t space_id = mach_read_from_4(
-				read_buf + FIL_PAGE_SPACE_ID);
-			const uint32_t page_no = mach_read_from_4(
-				read_buf + FIL_PAGE_OFFSET);
-
-			ib::error() << "Page " << page_id_t(space_id, page_no)
-				<< " log sequence number " << page_lsn
-				<< " is in the future! Current system"
-				<< " log sequence number "
-				<< current_lsn << ".";
-
-			ib::error() << "Your database may be corrupt or"
-				" you may have copied the InnoDB"
-				" tablespace but not the InnoDB"
-				" log files. "
-				<< FORCE_RECOVERY_MSG;
-
-		}
-	}
+  if (check_lsn && recv_lsn_checks_on)
+  {
+    const lsn_t current_lsn= log_sys.get_lsn();
+    const lsn_t page_lsn= mach_read_from_8(read_buf + FIL_PAGE_LSN);
+
+    /* Since we are going to reset the page LSN during the import
+    phase it makes no sense to spam the log with error messages. */
+    if (current_lsn < page_lsn)
+    {
+
+      const uint32_t space_id= mach_read_from_4(read_buf + FIL_PAGE_SPACE_ID);
+      const uint32_t page_no= mach_read_from_4(read_buf + FIL_PAGE_OFFSET);
+
+      ib::error() << "Page " << page_id_t(space_id, page_no)
+                  << " log sequence number " << page_lsn
+                  << " is in the future! Current system"
+                  << " log sequence number " << current_lsn << ".";
+
+      ib::error() << "Your database may be corrupt or"
+                     " you may have copied the InnoDB"
+                     " tablespace but not the InnoDB"
+                     " log files. "
+                  << FORCE_RECOVERY_MSG;
+    }
+  }
 #endif /* !UNIV_INNOCHECKSUM */
 }
 
-
 /** Check if a buffer is all zeroes.
 @param[in]	buf	data to check
 @return whether the buffer is all zeroes */
@@ -713,284 +707,302 @@ bool buf_is_zeroes(span<const byte> buf)
 @param[in]	read_buf	database page
 @param[in]	fsp_flags	tablespace flags
 @return whether the page is corrupted */
-bool
-buf_page_is_corrupted(
-	bool			check_lsn,
-	const byte*		read_buf,
-	ulint			fsp_flags)
+bool buf_page_is_corrupted(bool check_lsn, const byte *read_buf,
+                           ulint fsp_flags)
 {
 #ifndef UNIV_INNOCHECKSUM
-	DBUG_EXECUTE_IF("buf_page_import_corrupt_failure", return(true); );
+  DBUG_EXECUTE_IF("buf_page_import_corrupt_failure", return (true););
 #endif
-	if (fil_space_t::full_crc32(fsp_flags)) {
-		bool compressed = false, corrupted = false;
-		const uint size = buf_page_full_crc32_size(
-			read_buf, &compressed, &corrupted);
-		if (corrupted) {
-			return true;
-		}
-		const byte* end = read_buf + (size - FIL_PAGE_FCRC32_CHECKSUM);
-		uint crc32 = mach_read_from_4(end);
-
-		if (!crc32 && size == srv_page_size
-		    && buf_is_zeroes(span<const byte>(read_buf, size))) {
-			return false;
-		}
-
-		DBUG_EXECUTE_IF(
-			"page_intermittent_checksum_mismatch", {
-			static int page_counter;
-			if (page_counter++ == 2) {
-				crc32++;
-			}
-		});
-
-		if (crc32 != ut_crc32(read_buf,
-				      size - FIL_PAGE_FCRC32_CHECKSUM)) {
-			return true;
-		}
-		static_assert(FIL_PAGE_FCRC32_KEY_VERSION == 0, "alignment");
-		static_assert(FIL_PAGE_LSN % 4 == 0, "alignment");
-		static_assert(FIL_PAGE_FCRC32_END_LSN % 4 == 0, "alignment");
-		if (!compressed
-		    && !mach_read_from_4(FIL_PAGE_FCRC32_KEY_VERSION
-					 + read_buf)
-		    && memcmp_aligned<4>(read_buf + (FIL_PAGE_LSN + 4),
-					 end - (FIL_PAGE_FCRC32_END_LSN
-						- FIL_PAGE_FCRC32_CHECKSUM),
-					 4)) {
-			return true;
-		}
-
-		buf_page_check_lsn(check_lsn, read_buf);
-		return false;
-	}
-
-	size_t		checksum_field1 = 0;
-	size_t		checksum_field2 = 0;
-	uint32_t	crc32 = 0;
-	bool		crc32_inited = false;
-	bool		crc32_chksum = false;
-	const ulint zip_size = fil_space_t::zip_size(fsp_flags);
-	const uint16_t page_type = fil_page_get_type(read_buf);
-
-	/* We can trust page type if page compression is set on tablespace
-	flags because page compression flag means file must have been
-	created with 10.1 (later than 5.5 code base). In 10.1 page
-	compressed tables do not contain post compression checksum and
-	FIL_PAGE_END_LSN_OLD_CHKSUM field stored. Note that space can
-	be null if we are in fil_check_first_page() and first page
-	is not compressed or encrypted. Page checksum is verified
-	after decompression (i.e. normally pages are already
-	decompressed at this stage). */
-	if ((page_type == FIL_PAGE_PAGE_COMPRESSED ||
-	     page_type == FIL_PAGE_PAGE_COMPRESSED_ENCRYPTED)
+  if (fil_space_t::full_crc32(fsp_flags))
+  {
+    bool compressed= false, corrupted= false;
+    const uint size=
+        buf_page_full_crc32_size(read_buf, &compressed, &corrupted);
+    if (corrupted)
+    {
+      return true;
+    }
+    const byte *end= read_buf + (size - FIL_PAGE_FCRC32_CHECKSUM);
+    uint crc32= mach_read_from_4(end);
+
+    if (!crc32 && size == srv_page_size &&
+        buf_is_zeroes(span<const byte>(read_buf, size)))
+    {
+      return false;
+    }
+
+    DBUG_EXECUTE_IF("page_intermittent_checksum_mismatch", {
+      static int page_counter;
+      if (page_counter++ == 2)
+      {
+        crc32++;
+      }
+    });
+
+    if (crc32 != ut_crc32(read_buf, size - FIL_PAGE_FCRC32_CHECKSUM))
+    {
+      return true;
+    }
+    static_assert(FIL_PAGE_FCRC32_KEY_VERSION == 0, "alignment");
+    static_assert(FIL_PAGE_LSN % 4 == 0, "alignment");
+    static_assert(FIL_PAGE_FCRC32_END_LSN % 4 == 0, "alignment");
+    if (!compressed &&
+        !mach_read_from_4(FIL_PAGE_FCRC32_KEY_VERSION + read_buf) &&
+        memcmp_aligned<4>(
+            read_buf + (FIL_PAGE_LSN + 4),
+            end - (FIL_PAGE_FCRC32_END_LSN - FIL_PAGE_FCRC32_CHECKSUM), 4))
+    {
+      return true;
+    }
+
+    buf_page_check_lsn(check_lsn, read_buf);
+    return false;
+  }
+
+  size_t checksum_field1= 0;
+  size_t checksum_field2= 0;
+  uint32_t crc32= 0;
+  bool crc32_inited= false;
+  bool crc32_chksum= false;
+  const ulint zip_size= fil_space_t::zip_size(fsp_flags);
+  const uint16_t page_type= fil_page_get_type(read_buf);
+
+  /* We can trust page type if page compression is set on tablespace
+  flags because page compression flag means file must have been
+  created with 10.1 (later than 5.5 code base). In 10.1 page
+  compressed tables do not contain post compression checksum and
+  FIL_PAGE_END_LSN_OLD_CHKSUM field stored. Note that space can
+  be null if we are in fil_check_first_page() and first page
+  is not compressed or encrypted. Page checksum is verified
+  after decompression (i.e. normally pages are already
+  decompressed at this stage). */
+  if ((page_type == FIL_PAGE_PAGE_COMPRESSED ||
+       page_type == FIL_PAGE_PAGE_COMPRESSED_ENCRYPTED)
 #ifndef UNIV_INNOCHECKSUM
-	    && FSP_FLAGS_HAS_PAGE_COMPRESSION(fsp_flags)
+      && FSP_FLAGS_HAS_PAGE_COMPRESSION(fsp_flags)
 #endif
-	) {
-		return(false);
-	}
-
-	static_assert(FIL_PAGE_LSN % 4 == 0, "alignment");
-	static_assert(FIL_PAGE_END_LSN_OLD_CHKSUM % 4 == 0, "alignment");
-
-	if (!zip_size
-	    && memcmp_aligned<4>(read_buf + FIL_PAGE_LSN + 4,
-				 read_buf + srv_page_size
-				 - FIL_PAGE_END_LSN_OLD_CHKSUM + 4, 4)) {
-		/* Stored log sequence numbers at the start and the end
-		of page do not match */
-
-		return(true);
-	}
-
-	buf_page_check_lsn(check_lsn, read_buf);
-
-	/* Check whether the checksum fields have correct values */
-
-	const srv_checksum_algorithm_t curr_algo =
-		static_cast<srv_checksum_algorithm_t>(srv_checksum_algorithm);
-
-	if (curr_algo == SRV_CHECKSUM_ALGORITHM_NONE) {
-		return(false);
-	}
-
-	if (zip_size) {
-		return !page_zip_verify_checksum(read_buf, zip_size);
-	}
-
-	checksum_field1 = mach_read_from_4(
-		read_buf + FIL_PAGE_SPACE_OR_CHKSUM);
-
-	checksum_field2 = mach_read_from_4(
-		read_buf + srv_page_size - FIL_PAGE_END_LSN_OLD_CHKSUM);
-
-	static_assert(FIL_PAGE_LSN % 8 == 0, "alignment");
-
-	/* A page filled with NUL bytes is considered not corrupted.
-	Before MariaDB Server 10.1.25 (MDEV-12113) or 10.2.2 (or MySQL 5.7),
-	the FIL_PAGE_FILE_FLUSH_LSN field may have been written nonzero
-	for the first page of each file of the system tablespace.
-	We want to ignore it for the system tablespace, but because
-	we do not know the expected tablespace here, we ignore the
-	field for all data files, except for
-	innodb_checksum_algorithm=full_crc32 which we handled above. */
-	if (!checksum_field1 && !checksum_field2) {
-		/* Checksum fields can have valid value as zero.
-		If the page is not empty then do the checksum
-		calculation for the page. */
-		bool all_zeroes = true;
-		for (size_t i = 0; i < srv_page_size; i++) {
+  )
+  {
+    return (false);
+  }
+
+  static_assert(FIL_PAGE_LSN % 4 == 0, "alignment");
+  static_assert(FIL_PAGE_END_LSN_OLD_CHKSUM % 4 == 0, "alignment");
+
+  if (!zip_size && memcmp_aligned<4>(read_buf + FIL_PAGE_LSN + 4,
+                                     read_buf + srv_page_size -
+                                         FIL_PAGE_END_LSN_OLD_CHKSUM + 4,
+                                     4))
+  {
+    /* Stored log sequence numbers at the start and the end
+    of page do not match */
+
+    return (true);
+  }
+
+  buf_page_check_lsn(check_lsn, read_buf);
+
+  /* Check whether the checksum fields have correct values */
+
+  const srv_checksum_algorithm_t curr_algo=
+      static_cast<srv_checksum_algorithm_t>(srv_checksum_algorithm);
+
+  if (curr_algo == SRV_CHECKSUM_ALGORITHM_NONE)
+  {
+    return (false);
+  }
+
+  if (zip_size)
+  {
+    return !page_zip_verify_checksum(read_buf, zip_size);
+  }
+
+  checksum_field1= mach_read_from_4(read_buf + FIL_PAGE_SPACE_OR_CHKSUM);
+
+  checksum_field2=
+      mach_read_from_4(read_buf + srv_page_size - FIL_PAGE_END_LSN_OLD_CHKSUM);
+
+  static_assert(FIL_PAGE_LSN % 8 == 0, "alignment");
+
+  /* A page filled with NUL bytes is considered not corrupted.
+  Before MariaDB Server 10.1.25 (MDEV-12113) or 10.2.2 (or MySQL 5.7),
+  the FIL_PAGE_FILE_FLUSH_LSN field may have been written nonzero
+  for the first page of each file of the system tablespace.
+  We want to ignore it for the system tablespace, but because
+  we do not know the expected tablespace here, we ignore the
+  field for all data files, except for
+  innodb_checksum_algorithm=full_crc32 which we handled above. */
+  if (!checksum_field1 && !checksum_field2)
+  {
+    /* Checksum fields can have valid value as zero.
+    If the page is not empty then do the checksum
+    calculation for the page. */
+    bool all_zeroes= true;
+    for (size_t i= 0; i < srv_page_size; i++)
+    {
 #ifndef UNIV_INNOCHECKSUM
-			if (i == FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION) {
-				i += 8;
-			}
+      if (i == FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION)
+      {
+        i+= 8;
+      }
 #endif
-			if (read_buf[i]) {
-				all_zeroes = false;
-				break;
-			}
-		}
-
-		if (all_zeroes) {
-			return false;
-		}
-	}
-
-	switch (curr_algo) {
-	case SRV_CHECKSUM_ALGORITHM_STRICT_FULL_CRC32:
-	case SRV_CHECKSUM_ALGORITHM_STRICT_CRC32:
-		return !buf_page_is_checksum_valid_crc32(
-			read_buf, checksum_field1, checksum_field2);
-	case SRV_CHECKSUM_ALGORITHM_STRICT_INNODB:
-		return !buf_page_is_checksum_valid_innodb(
-			read_buf, checksum_field1, checksum_field2);
-	case SRV_CHECKSUM_ALGORITHM_STRICT_NONE:
-		return !buf_page_is_checksum_valid_none(
-			read_buf, checksum_field1, checksum_field2);
-	case SRV_CHECKSUM_ALGORITHM_FULL_CRC32:
-	case SRV_CHECKSUM_ALGORITHM_CRC32:
-	case SRV_CHECKSUM_ALGORITHM_INNODB:
-		if (buf_page_is_checksum_valid_none(read_buf,
-			checksum_field1, checksum_field2)) {
+      if (read_buf[i])
+      {
+        all_zeroes= false;
+        break;
+      }
+    }
+
+    if (all_zeroes)
+    {
+      return false;
+    }
+  }
+
+  switch (curr_algo)
+  {
+  case SRV_CHECKSUM_ALGORITHM_STRICT_FULL_CRC32:
+  case SRV_CHECKSUM_ALGORITHM_STRICT_CRC32:
+    return !buf_page_is_checksum_valid_crc32(read_buf, checksum_field1,
+                                             checksum_field2);
+  case SRV_CHECKSUM_ALGORITHM_STRICT_INNODB:
+    return !buf_page_is_checksum_valid_innodb(read_buf, checksum_field1,
+                                              checksum_field2);
+  case SRV_CHECKSUM_ALGORITHM_STRICT_NONE:
+    return !buf_page_is_checksum_valid_none(read_buf, checksum_field1,
+                                            checksum_field2);
+  case SRV_CHECKSUM_ALGORITHM_FULL_CRC32:
+  case SRV_CHECKSUM_ALGORITHM_CRC32:
+  case SRV_CHECKSUM_ALGORITHM_INNODB:
+    if (buf_page_is_checksum_valid_none(read_buf, checksum_field1,
+                                        checksum_field2))
+    {
 #ifdef UNIV_INNOCHECKSUM
-			if (log_file) {
-				fprintf(log_file, "page::" UINT32PF ";"
-					" old style: calculated = %u;"
-					" recorded = " ULINTPF ";\n",
-					cur_page_num,
-					buf_calc_page_old_checksum(read_buf),
-					checksum_field2);
-				fprintf(log_file, "page::" UINT32PF ";"
-					" new style: calculated = " UINT32PF ";"
-					" crc32 = " UINT32PF "; recorded = " ULINTPF ";\n",
-					cur_page_num,
-					buf_calc_page_new_checksum(read_buf),
-					buf_calc_page_crc32(read_buf),
-					checksum_field1);
-			}
+      if (log_file)
+      {
+        fprintf(log_file,
+                "page::" UINT32PF ";"
+                " old style: calculated = %u;"
+                " recorded = " ULINTPF ";\n",
+                cur_page_num, buf_calc_page_old_checksum(read_buf),
+                checksum_field2);
+        fprintf(log_file,
+                "page::" UINT32PF ";"
+                " new style: calculated = " UINT32PF ";"
+                " crc32 = " UINT32PF "; recorded = " ULINTPF ";\n",
+                cur_page_num, buf_calc_page_new_checksum(read_buf),
+                buf_calc_page_crc32(read_buf), checksum_field1);
+      }
 #endif /* UNIV_INNOCHECKSUM */
-			return false;
-		}
-
-		crc32_chksum = curr_algo == SRV_CHECKSUM_ALGORITHM_CRC32
-			|| curr_algo == SRV_CHECKSUM_ALGORITHM_FULL_CRC32;
-
-		/* Very old versions of InnoDB only stored 8 byte lsn to the
-		start and the end of the page. */
-
-		/* Since innodb_checksum_algorithm is not strict_* allow
-		any of the algos to match for the old field */
-
-		if (checksum_field2
-		    != mach_read_from_4(read_buf + FIL_PAGE_LSN)
-		    && checksum_field2 != BUF_NO_CHECKSUM_MAGIC) {
-
-			if (crc32_chksum) {
-				crc32 = buf_calc_page_crc32(read_buf);
-				crc32_inited = true;
-
-				DBUG_EXECUTE_IF(
-					"page_intermittent_checksum_mismatch", {
-					static int page_counter;
-					if (page_counter++ == 2) {
-						crc32++;
-					}
-				});
-
-				if (checksum_field2 != crc32
-				    && checksum_field2
-				       != buf_calc_page_old_checksum(read_buf)) {
-					return true;
-				}
-			} else {
-				ut_ad(curr_algo
-				      == SRV_CHECKSUM_ALGORITHM_INNODB);
-
-				if (checksum_field2
-				    != buf_calc_page_old_checksum(read_buf)) {
-					crc32 = buf_calc_page_crc32(read_buf);
-					crc32_inited = true;
-
-					if (checksum_field2 != crc32) {
-						return true;
-					}
-				}
-			}
-		}
-
-		if (checksum_field1 == 0
-		    || checksum_field1 == BUF_NO_CHECKSUM_MAGIC) {
-		} else if (crc32_chksum) {
-
-			if (!crc32_inited) {
-				crc32 = buf_calc_page_crc32(read_buf);
-				crc32_inited = true;
-			}
-
-			if (checksum_field1 != crc32
-			    && checksum_field1
-			    != buf_calc_page_new_checksum(read_buf)) {
-				return true;
-			}
-		} else {
-			ut_ad(curr_algo == SRV_CHECKSUM_ALGORITHM_INNODB);
-
-			if (checksum_field1
-			    != buf_calc_page_new_checksum(read_buf)) {
-
-				if (!crc32_inited) {
-					crc32 = buf_calc_page_crc32(read_buf);
-					crc32_inited = true;
-				}
-
-				if (checksum_field1 != crc32) {
-					return true;
-				}
-			}
-		}
-
-		if (crc32_inited
-		    && ((checksum_field1 == crc32
-			 && checksum_field2 != crc32)
-			|| (checksum_field1 != crc32
-			    && checksum_field2 == crc32))) {
-			return true;
-		}
-
-		break;
-	case SRV_CHECKSUM_ALGORITHM_NONE:
-		/* should have returned false earlier */
-		break;
-	}
-
-	return false;
+      return false;
+    }
+
+    crc32_chksum= curr_algo == SRV_CHECKSUM_ALGORITHM_CRC32 ||
+                  curr_algo == SRV_CHECKSUM_ALGORITHM_FULL_CRC32;
+
+    /* Very old versions of InnoDB only stored 8 byte lsn to the
+    start and the end of the page. */
+
+    /* Since innodb_checksum_algorithm is not strict_* allow
+    any of the algos to match for the old field */
+
+    if (checksum_field2 != mach_read_from_4(read_buf + FIL_PAGE_LSN) &&
+        checksum_field2 != BUF_NO_CHECKSUM_MAGIC)
+    {
+
+      if (crc32_chksum)
+      {
+        crc32= buf_calc_page_crc32(read_buf);
+        crc32_inited= true;
+
+        DBUG_EXECUTE_IF("page_intermittent_checksum_mismatch", {
+          static int page_counter;
+          if (page_counter++ == 2)
+          {
+            crc32++;
+          }
+        });
+
+        if (checksum_field2 != crc32 &&
+            checksum_field2 != buf_calc_page_old_checksum(read_buf))
+        {
+          return true;
+        }
+      }
+      else
+      {
+        ut_ad(curr_algo == SRV_CHECKSUM_ALGORITHM_INNODB);
+
+        if (checksum_field2 != buf_calc_page_old_checksum(read_buf))
+        {
+          crc32= buf_calc_page_crc32(read_buf);
+          crc32_inited= true;
+
+          if (checksum_field2 != crc32)
+          {
+            return true;
+          }
+        }
+      }
+    }
+
+    if (checksum_field1 == 0 || checksum_field1 == BUF_NO_CHECKSUM_MAGIC)
+    {
+    }
+    else if (crc32_chksum)
+    {
+
+      if (!crc32_inited)
+      {
+        crc32= buf_calc_page_crc32(read_buf);
+        crc32_inited= true;
+      }
+
+      if (checksum_field1 != crc32 &&
+          checksum_field1 != buf_calc_page_new_checksum(read_buf))
+      {
+        return true;
+      }
+    }
+    else
+    {
+      ut_ad(curr_algo == SRV_CHECKSUM_ALGORITHM_INNODB);
+
+      if (checksum_field1 != buf_calc_page_new_checksum(read_buf))
+      {
+
+        if (!crc32_inited)
+        {
+          crc32= buf_calc_page_crc32(read_buf);
+          crc32_inited= true;
+        }
+
+        if (checksum_field1 != crc32)
+        {
+          return true;
+        }
+      }
+    }
+
+    if (crc32_inited &&
+        ((checksum_field1 == crc32 && checksum_field2 != crc32) ||
+         (checksum_field1 != crc32 && checksum_field2 == crc32)))
+    {
+      return true;
+    }
+
+    break;
+  case SRV_CHECKSUM_ALGORITHM_NONE:
+    /* should have returned false earlier */
+    break;
+  }
+
+  return false;
 }
 
 #ifndef UNIV_INNOCHECKSUM
 
-#if defined(DBUG_OFF) && defined(HAVE_MADVISE) &&  defined(MADV_DODUMP)
+#if defined(DBUG_OFF) && defined(HAVE_MADVISE) && defined(MADV_DODUMP)
 /** Enable buffers to be dumped to core files
 
 A convience function, not called anyhwere directly however
@@ -999,238 +1011,216 @@ in the event that you want all of the memory to be dumped
 to a core file.
 
 Returns number of errors found in madvise calls. */
-int
-buf_madvise_do_dump()
+int buf_madvise_do_dump()
 {
-	int ret= 0;
-
-	/* mirrors allocation in log_t::create() */
-	if (log_sys.buf) {
-		ret += madvise(log_sys.buf,
-			       srv_log_buffer_size,
-			       MADV_DODUMP);
-		ret += madvise(log_sys.flush_buf,
-			       srv_log_buffer_size,
-			       MADV_DODUMP);
-	}
-	/* mirrors recv_sys_t::create() */
-	if (recv_sys.buf)
-	{
-		ret+= madvise(recv_sys.buf, recv_sys.len, MADV_DODUMP);
-	}
-
-	mysql_mutex_lock(&buf_pool.mutex);
-	auto chunk = buf_pool.chunks;
-
-	for (ulint n = buf_pool.n_chunks; n--; chunk++) {
-		ret+= madvise(chunk->mem, chunk->mem_size(), MADV_DODUMP);
-	}
-
-	mysql_mutex_unlock(&buf_pool.mutex);
-	return ret;
+  int ret= 0;
+
+  /* mirrors allocation in log_t::create() */
+  if (log_sys.buf)
+  {
+    ret+= madvise(log_sys.buf, srv_log_buffer_size, MADV_DODUMP);
+    ret+= madvise(log_sys.flush_buf, srv_log_buffer_size, MADV_DODUMP);
+  }
+  /* mirrors recv_sys_t::create() */
+  if (recv_sys.buf)
+  {
+    ret+= madvise(recv_sys.buf, recv_sys.len, MADV_DODUMP);
+  }
+
+  mysql_mutex_lock(&buf_pool.mutex);
+  auto chunk= buf_pool.chunks;
+
+  for (ulint n= buf_pool.n_chunks; n--; chunk++)
+  {
+    ret+= madvise(chunk->mem, chunk->mem_size(), MADV_DODUMP);
+  }
+
+  mysql_mutex_unlock(&buf_pool.mutex);
+  return ret;
 }
 #endif
 
 /** Dump a page to stderr.
 @param[in]	read_buf	database page
 @param[in]	zip_size	compressed page size, or 0 */
-void buf_page_print(const byte* read_buf, ulint zip_size)
+void buf_page_print(const byte *read_buf, ulint zip_size)
 {
-	dict_index_t*	index;
+  dict_index_t *index;
 
 #ifndef UNIV_DEBUG
-	const ulint size = zip_size ? zip_size : srv_page_size;
-	ib::info() << "Page dump in ascii and hex ("
-		<< size << " bytes):";
+  const ulint size= zip_size ? zip_size : srv_page_size;
+  ib::info() << "Page dump in ascii and hex (" << size << " bytes):";
 
-	ut_print_buf(stderr, read_buf, size);
-	fputs("\nInnoDB: End of page dump\n", stderr);
+  ut_print_buf(stderr, read_buf, size);
+  fputs("\nInnoDB: End of page dump\n", stderr);
 #endif
 
-	if (zip_size) {
-		/* Print compressed page. */
-		ib::info() << "Compressed page type ("
-			<< fil_page_get_type(read_buf)
-			<< "); stored checksum in field1 "
-			<< mach_read_from_4(
-				read_buf + FIL_PAGE_SPACE_OR_CHKSUM)
-			<< "; calculated checksums for field1: "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_CRC32)
-			<< " "
-			<< page_zip_calc_checksum(
-				read_buf, zip_size,
-				SRV_CHECKSUM_ALGORITHM_CRC32)
-			<< ", "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_INNODB)
-			<< " "
-			<< page_zip_calc_checksum(
-				read_buf, zip_size,
-				SRV_CHECKSUM_ALGORITHM_INNODB)
-			<< ", "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_NONE)
-			<< " "
-			<< page_zip_calc_checksum(
-				read_buf, zip_size,
-				SRV_CHECKSUM_ALGORITHM_NONE)
-			<< "; page LSN "
-			<< mach_read_from_8(read_buf + FIL_PAGE_LSN)
-			<< "; page number (if stored to page"
-			<< " already) "
-			<< mach_read_from_4(read_buf + FIL_PAGE_OFFSET)
-			<< "; space id (if stored to page already) "
-			<< mach_read_from_4(
-				read_buf + FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID);
-
-	} else {
-		const uint32_t	crc32 = buf_calc_page_crc32(read_buf);
-		ulint page_type = fil_page_get_type(read_buf);
-
-		ib::info() << "Uncompressed page, stored checksum in field1 "
-			<< mach_read_from_4(
-				read_buf + FIL_PAGE_SPACE_OR_CHKSUM)
-			<< ", calculated checksums for field1: "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_CRC32) << " "
-			<< crc32
-			<< ", "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_INNODB) << " "
-			<< buf_calc_page_new_checksum(read_buf)
-			<< ", "
-			<< " page type " << page_type << " == "
-			<< fil_get_page_type_name(page_type) << "."
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_NONE) << " "
-			<< BUF_NO_CHECKSUM_MAGIC
-			<< ", stored checksum in field2 "
-			<< mach_read_from_4(read_buf + srv_page_size
-					    - FIL_PAGE_END_LSN_OLD_CHKSUM)
-			<< ", calculated checksums for field2: "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_CRC32) << " "
-			<< crc32
-			<< ", "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_INNODB) << " "
-			<< buf_calc_page_old_checksum(read_buf)
-			<< ", "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_NONE) << " "
-			<< BUF_NO_CHECKSUM_MAGIC
-			<< ",  page LSN "
-			<< mach_read_from_4(read_buf + FIL_PAGE_LSN)
-			<< " "
-			<< mach_read_from_4(read_buf + FIL_PAGE_LSN + 4)
-			<< ", low 4 bytes of LSN at page end "
-			<< mach_read_from_4(read_buf + srv_page_size
-					    - FIL_PAGE_END_LSN_OLD_CHKSUM + 4)
-			<< ", page number (if stored to page already) "
-			<< mach_read_from_4(read_buf + FIL_PAGE_OFFSET)
-			<< ", space id (if created with >= MySQL-4.1.1"
-			   " and stored already) "
-			<< mach_read_from_4(
-				read_buf + FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID);
-	}
-
-	switch (fil_page_get_type(read_buf)) {
-		index_id_t	index_id;
-	case FIL_PAGE_INDEX:
-	case FIL_PAGE_TYPE_INSTANT:
-	case FIL_PAGE_RTREE:
-		index_id = btr_page_get_index_id(read_buf);
-		ib::info() << "Page may be an index page where"
-			" index id is " << index_id;
-
-		index = dict_index_find_on_id_low(index_id);
-		if (index) {
-			ib::info()
-				<< "Index " << index_id
-				<< " is " << index->name
-				<< " in table " << index->table->name;
-		}
-		break;
-	case FIL_PAGE_UNDO_LOG:
-		fputs("InnoDB: Page may be an undo log page\n", stderr);
-		break;
-	case FIL_PAGE_INODE:
-		fputs("InnoDB: Page may be an 'inode' page\n", stderr);
-		break;
-	case FIL_PAGE_IBUF_FREE_LIST:
-		fputs("InnoDB: Page may be an insert buffer free list page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_TYPE_ALLOCATED:
-		fputs("InnoDB: Page may be a freshly allocated page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_IBUF_BITMAP:
-		fputs("InnoDB: Page may be an insert buffer bitmap page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_TYPE_SYS:
-		fputs("InnoDB: Page may be a system page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_TYPE_TRX_SYS:
-		fputs("InnoDB: Page may be a transaction system page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_TYPE_FSP_HDR:
-		fputs("InnoDB: Page may be a file space header page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_TYPE_XDES:
-		fputs("InnoDB: Page may be an extent descriptor page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_TYPE_BLOB:
-		fputs("InnoDB: Page may be a BLOB page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_TYPE_ZBLOB:
-	case FIL_PAGE_TYPE_ZBLOB2:
-		fputs("InnoDB: Page may be a compressed BLOB page\n",
-		      stderr);
-		break;
-	}
+  if (zip_size)
+  {
+    /* Print compressed page. */
+    ib::info() << "Compressed page type (" << fil_page_get_type(read_buf)
+               << "); stored checksum in field1 "
+               << mach_read_from_4(read_buf + FIL_PAGE_SPACE_OR_CHKSUM)
+               << "; calculated checksums for field1: "
+               << buf_checksum_algorithm_name(SRV_CHECKSUM_ALGORITHM_CRC32)
+               << " "
+               << page_zip_calc_checksum(read_buf, zip_size,
+                                         SRV_CHECKSUM_ALGORITHM_CRC32)
+               << ", "
+               << buf_checksum_algorithm_name(SRV_CHECKSUM_ALGORITHM_INNODB)
+               << " "
+               << page_zip_calc_checksum(read_buf, zip_size,
+                                         SRV_CHECKSUM_ALGORITHM_INNODB)
+               << ", "
+               << buf_checksum_algorithm_name(SRV_CHECKSUM_ALGORITHM_NONE)
+               << " "
+               << page_zip_calc_checksum(read_buf, zip_size,
+                                         SRV_CHECKSUM_ALGORITHM_NONE)
+               << "; page LSN " << mach_read_from_8(read_buf + FIL_PAGE_LSN)
+               << "; page number (if stored to page"
+               << " already) " << mach_read_from_4(read_buf + FIL_PAGE_OFFSET)
+               << "; space id (if stored to page already) "
+               << mach_read_from_4(read_buf +
+                                   FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID);
+  }
+  else
+  {
+    const uint32_t crc32= buf_calc_page_crc32(read_buf);
+    ulint page_type= fil_page_get_type(read_buf);
+
+    ib::info() << "Uncompressed page, stored checksum in field1 "
+               << mach_read_from_4(read_buf + FIL_PAGE_SPACE_OR_CHKSUM)
+               << ", calculated checksums for field1: "
+               << buf_checksum_algorithm_name(SRV_CHECKSUM_ALGORITHM_CRC32)
+               << " " << crc32 << ", "
+               << buf_checksum_algorithm_name(SRV_CHECKSUM_ALGORITHM_INNODB)
+               << " " << buf_calc_page_new_checksum(read_buf) << ", "
+               << " page type " << page_type
+               << " == " << fil_get_page_type_name(page_type) << "."
+               << buf_checksum_algorithm_name(SRV_CHECKSUM_ALGORITHM_NONE)
+               << " " << BUF_NO_CHECKSUM_MAGIC
+               << ", stored checksum in field2 "
+               << mach_read_from_4(read_buf + srv_page_size -
+                                   FIL_PAGE_END_LSN_OLD_CHKSUM)
+               << ", calculated checksums for field2: "
+               << buf_checksum_algorithm_name(SRV_CHECKSUM_ALGORITHM_CRC32)
+               << " " << crc32 << ", "
+               << buf_checksum_algorithm_name(SRV_CHECKSUM_ALGORITHM_INNODB)
+               << " " << buf_calc_page_old_checksum(read_buf) << ", "
+               << buf_checksum_algorithm_name(SRV_CHECKSUM_ALGORITHM_NONE)
+               << " " << BUF_NO_CHECKSUM_MAGIC << ",  page LSN "
+               << mach_read_from_4(read_buf + FIL_PAGE_LSN) << " "
+               << mach_read_from_4(read_buf + FIL_PAGE_LSN + 4)
+               << ", low 4 bytes of LSN at page end "
+               << mach_read_from_4(read_buf + srv_page_size -
+                                   FIL_PAGE_END_LSN_OLD_CHKSUM + 4)
+               << ", page number (if stored to page already) "
+               << mach_read_from_4(read_buf + FIL_PAGE_OFFSET)
+               << ", space id (if created with >= MySQL-4.1.1"
+                  " and stored already) "
+               << mach_read_from_4(read_buf +
+                                   FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID);
+  }
+
+  switch (fil_page_get_type(read_buf))
+  {
+    index_id_t index_id;
+  case FIL_PAGE_INDEX:
+  case FIL_PAGE_TYPE_INSTANT:
+  case FIL_PAGE_RTREE:
+    index_id= btr_page_get_index_id(read_buf);
+    ib::info() << "Page may be an index page where"
+                  " index id is "
+               << index_id;
+
+    index= dict_index_find_on_id_low(index_id);
+    if (index)
+    {
+      ib::info() << "Index " << index_id << " is " << index->name
+                 << " in table " << index->table->name;
+    }
+    break;
+  case FIL_PAGE_UNDO_LOG:
+    fputs("InnoDB: Page may be an undo log page\n", stderr);
+    break;
+  case FIL_PAGE_INODE:
+    fputs("InnoDB: Page may be an 'inode' page\n", stderr);
+    break;
+  case FIL_PAGE_IBUF_FREE_LIST:
+    fputs("InnoDB: Page may be an insert buffer free list page\n", stderr);
+    break;
+  case FIL_PAGE_TYPE_ALLOCATED:
+    fputs("InnoDB: Page may be a freshly allocated page\n", stderr);
+    break;
+  case FIL_PAGE_IBUF_BITMAP:
+    fputs("InnoDB: Page may be an insert buffer bitmap page\n", stderr);
+    break;
+  case FIL_PAGE_TYPE_SYS:
+    fputs("InnoDB: Page may be a system page\n", stderr);
+    break;
+  case FIL_PAGE_TYPE_TRX_SYS:
+    fputs("InnoDB: Page may be a transaction system page\n", stderr);
+    break;
+  case FIL_PAGE_TYPE_FSP_HDR:
+    fputs("InnoDB: Page may be a file space header page\n", stderr);
+    break;
+  case FIL_PAGE_TYPE_XDES:
+    fputs("InnoDB: Page may be an extent descriptor page\n", stderr);
+    break;
+  case FIL_PAGE_TYPE_BLOB:
+    fputs("InnoDB: Page may be a BLOB page\n", stderr);
+    break;
+  case FIL_PAGE_TYPE_ZBLOB:
+  case FIL_PAGE_TYPE_ZBLOB2:
+    fputs("InnoDB: Page may be a compressed BLOB page\n", stderr);
+    break;
+  }
 }
 
 /** Initialize a buffer page descriptor.
 @param[in,out]	block	buffer page descriptor
 @param[in]	frame	buffer page frame */
-static
-void
-buf_block_init(buf_block_t* block, byte* frame)
+static void buf_block_init(buf_block_t *block, byte *frame)
 {
-	/* This function should only be executed at database startup or by
-	buf_pool.resize(). Either way, adaptive hash index must not exist. */
-	assert_block_ahi_empty_on_init(block);
+  /* This function should only be executed at database startup or by
+  buf_pool.resize(). Either way, adaptive hash index must not exist. */
+  assert_block_ahi_empty_on_init(block);
 
-	block->frame = frame;
+  block->frame= frame;
 
-	block->modify_clock = 0;
-	block->page.init(BUF_BLOCK_NOT_USED, page_id_t(~0ULL));
+  block->modify_clock= 0;
+  block->page.init(BUF_BLOCK_NOT_USED, page_id_t(~0ULL));
 #ifdef BTR_CUR_HASH_ADAPT
-	block->index = NULL;
+  block->index= NULL;
 #endif /* BTR_CUR_HASH_ADAPT */
-	ut_d(block->in_unzip_LRU_list = false);
-	ut_d(block->in_withdraw_list = false);
+  ut_d(block->in_unzip_LRU_list= false);
+  ut_d(block->in_withdraw_list= false);
+
+  page_zip_des_init(&block->page.zip);
+
+  ut_d(block->debug_latch= (rw_lock_t *) ut_malloc_nokey(sizeof(rw_lock_t)));
 
-	page_zip_des_init(&block->page.zip);
+  rw_lock_create(PFS_NOT_INSTRUMENTED, &block->lock, SYNC_LEVEL_VARYING);
 
-	ut_d(block->debug_latch = (rw_lock_t *) ut_malloc_nokey(sizeof(rw_lock_t)));
+  ut_d(rw_lock_create(PFS_NOT_INSTRUMENTED, block->debug_latch,
+                      SYNC_LEVEL_VARYING));
 
-	rw_lock_create(PFS_NOT_INSTRUMENTED, &block->lock, SYNC_LEVEL_VARYING);
+  block->lock.is_block_lock= 1;
 
-	ut_d(rw_lock_create(PFS_NOT_INSTRUMENTED, block->debug_latch,
-			    SYNC_LEVEL_VARYING));
+  ut_ad(rw_lock_validate(&(block->lock)));
+}
 
-	block->lock.is_block_lock = 1;
+struct thread_arg_t
+{
+  void *func;
+  unsigned long int thread_id;
+};
 
-	ut_ad(rw_lock_validate(&(block->lock)));
+template <typename Function> void *thread_func(void *arg)
+{
+  thread_arg_t *args= (thread_arg_t *) arg;
+  Function *func= (Function *) (args->func);
+  return (*func)(args->thread_id);
 }
 
 /** Allocate a chunk of buffer frames.
@@ -1253,22 +1243,21 @@ inline bool buf_pool_t::chunk_t::create(size_t bytes)
   if (srv_numa_interleave)
   {
     struct bitmask *numa_mems_allowed= numa_get_mems_allowed();
-    if (mbind(mem, mem_size(), MPOL_INTERLEAVE,
-              numa_mems_allowed->maskp, numa_mems_allowed->size,
-              MPOL_MF_MOVE))
+    if (mbind(mem, mem_size(), MPOL_INTERLEAVE, numa_mems_allowed->maskp,
+              numa_mems_allowed->size, MPOL_MF_MOVE))
     {
       ib::warn() << "Failed to set NUMA memory policy of"
-              " buffer pool page frames to MPOL_INTERLEAVE"
-              " (error: " << strerror(errno) << ").";
+                    " buffer pool page frames to MPOL_INTERLEAVE"
+                    " (error: "
+                 << strerror(errno) << ").";
     }
     numa_bitmask_free(numa_mems_allowed);
   }
 #endif /* HAVE_LIBNUMA */
 
-
   /* Allocate the block descriptors from
   the start of the memory block. */
-  blocks= reinterpret_cast<buf_block_t*>(mem);
+  blocks= reinterpret_cast<buf_block_t *>(mem);
 
   /* Align a pointer to the first frame.  Note that when
   opt_large_page_size is smaller than srv_page_size,
@@ -1276,18 +1265,18 @@ inline bool buf_pool_t::chunk_t::create(size_t bytes)
   makes this true),
   we may allocate one fewer block than requested.  When
   it is bigger, we may allocate more blocks than requested. */
-  static_assert(sizeof(byte*) == sizeof(ulint), "pointer size");
+  static_assert(sizeof(byte *) == sizeof(ulint), "pointer size");
 
-  byte *frame= reinterpret_cast<byte*>((reinterpret_cast<ulint>(mem) +
-                                        srv_page_size - 1) &
-                                       ~ulint{srv_page_size - 1});
+  byte *frame= reinterpret_cast<byte *>(
+      (reinterpret_cast<ulint>(mem) + srv_page_size - 1) &
+      ~ulint{srv_page_size - 1});
   size= (mem_pfx.m_size >> srv_page_size_shift) - (frame != mem);
 
   /* Subtract the space needed for block descriptors. */
   {
     ulint s= size;
 
-    while (frame < reinterpret_cast<const byte*>(blocks + s))
+    while (frame < reinterpret_cast<const byte *>(blocks + s))
     {
       frame+= srv_page_size;
       s--;
@@ -1295,19 +1284,21 @@ inline bool buf_pool_t::chunk_t::create(size_t bytes)
 
     size= s;
   }
-
+#define HYU_2018008395
+#ifndef HYU_2018008395
   /* Init block structs and assign frames for them. Then we assign the
   frames to the first blocks (we already mapped the memory above). */
 
   buf_block_t *block= blocks;
 
-  for (auto i= size; i--; ) {
+  for (auto i= size; i--;)
+  {
     buf_block_init(block, frame);
     MEM_UNDEFINED(block->frame, srv_page_size);
     /* Add the block to the free list */
     UT_LIST_ADD_LAST(buf_pool.free, &block->page);
 
-    ut_d(block->page.in_free_list = TRUE);
+    ut_d(block->page.in_free_list= TRUE);
     block++;
     frame+= srv_page_size;
   }
@@ -1315,6 +1306,56 @@ inline bool buf_pool_t::chunk_t::create(size_t bytes)
   reg();
 
   return true;
+#endif
+#ifdef HYU_2018008395
+  buf_block_t *block= blocks;
+
+  unsigned long int num_thread= sysconf(_SC_NPROCESSORS_ONLN);
+  std::vector<pthread_t> threads(num_thread);
+  std::vector<thread_arg_t> thread_args(num_thread);
+  std::vector<UT_LIST_BASE_NODE_T(buf_page_t) *> local_free_lists(num_thread);
+
+  auto threadwise_buf_block_init= [&](unsigned long int thread_id) {
+    auto local_frame= frame + srv_page_size * thread_id;
+    auto local_block= block + thread_id;
+    for (auto i= thread_id; i < size; i+= num_thread)
+    {
+      buf_block_init(local_block, local_frame);
+      MEM_UNDEFINED(local_block->frame, srv_page_size);
+      /* Add the local_block to the free list */
+      UT_LIST_ADD_LAST(*local_free_lists[thread_id], &local_block->page);
+
+      ut_d(local_block->page.in_free_list= TRUE);
+      local_block+= num_thread;
+      local_frame+= srv_page_size * num_thread;
+    }
+    return nullptr;
+  };
+
+  for (unsigned long int i= 0; i < num_thread; i++)
+  {
+    thread_args[i].thread_id= i;
+    thread_args[i].func= (void *) &threadwise_buf_block_init;
+    local_free_lists[i]= (UT_LIST_BASE_NODE_T(buf_page_t) *) malloc(
+        sizeof(UT_LIST_BASE_NODE_T(buf_page_t)));
+    UT_LIST_INIT(*local_free_lists[i], &buf_page_t::list)
+    if (pthread_create(&threads[i], nullptr,
+                       thread_func<decltype(threadwise_buf_block_init)>,
+                       &thread_args[i]))
+    {
+      return false;
+    }
+  }
+
+  for (unsigned long int i= 0; i < num_thread; i++)
+  {
+    pthread_join(threads[i], nullptr);
+    UT_LIST_CONCAT(buf_pool.free, *local_free_lists[i]);
+  }
+
+  reg();
+  return true;
+#endif
 }
 
 #ifdef UNIV_DEBUG
@@ -1326,7 +1367,8 @@ inline const buf_block_t *buf_pool_t::chunk_t::not_freed() const
   buf_block_t *block= blocks;
   for (auto i= size; i--; block++)
   {
-    switch (block->page.state()) {
+    switch (block->page.state())
+    {
     case BUF_BLOCK_ZIP_PAGE:
       /* The uncompressed buffer pool should never
       contain ROW_FORMAT=COMPRESSED block descriptors. */
@@ -1370,11 +1412,11 @@ inline const buf_block_t *buf_pool_t::chunk_t::not_freed() const
 
 /** Free the synchronization objects of a buffer pool block descriptor
 @param[in,out]	block	buffer pool block descriptor */
-static void buf_block_free_mutexes(buf_block_t* block)
+static void buf_block_free_mutexes(buf_block_t *block)
 {
-	rw_lock_free(&block->lock);
-	ut_d(rw_lock_free(block->debug_latch));
-	ut_d(ut_free(block->debug_latch));
+  rw_lock_free(&block->lock);
+  ut_d(rw_lock_free(block->debug_latch));
+  ut_d(ut_free(block->debug_latch));
 }
 
 /** Create the hash table.
@@ -1383,9 +1425,9 @@ void buf_pool_t::page_hash_table::create(ulint n)
 {
   n_cells= ut_find_prime(n);
   const size_t size= pad(n_cells) * sizeof *array;
-  void* v= aligned_malloc(size, CPU_LEVEL1_DCACHE_LINESIZE);
+  void *v= aligned_malloc(size, CPU_LEVEL1_DCACHE_LINESIZE);
   memset(v, 0, size);
-  array= static_cast<hash_cell_t*>(v);
+  array= static_cast<hash_cell_t *>(v);
 }
 
 /** Create the buffer pool.
@@ -1403,19 +1445,19 @@ bool buf_pool_t::create()
   NUMA_MEMPOLICY_INTERLEAVE_IN_SCOPE;
 
   if (auto b= aligned_malloc(UNIV_PAGE_SIZE_MAX, 4096))
-    field_ref_zero= static_cast<const byte*>
-      (memset_aligned<4096>(b, 0, UNIV_PAGE_SIZE_MAX));
+    field_ref_zero= static_cast<const byte *>(
+        memset_aligned<4096>(b, 0, UNIV_PAGE_SIZE_MAX));
   else
     return true;
 
   chunk_t::map_reg= UT_NEW_NOKEY(chunk_t::map());
 
-  new(&allocator) ut_allocator<unsigned char>(mem_key_buf_buf_pool);
+  new (&allocator) ut_allocator<unsigned char>(mem_key_buf_buf_pool);
 
   n_chunks= srv_buf_pool_size / srv_buf_pool_chunk_unit;
   const size_t chunk_size= srv_buf_pool_chunk_unit;
 
-  chunks= static_cast<chunk_t*>(ut_zalloc_nokey(n_chunks * sizeof *chunks));
+  chunks= static_cast<chunk_t *>(ut_zalloc_nokey(n_chunks * sizeof *chunks));
   UT_LIST_INIT(free, &buf_page_t::list);
   curr_size= 0;
   auto chunk= chunks;
@@ -1426,7 +1468,7 @@ bool buf_pool_t::create()
     {
       while (--chunk >= chunks)
       {
-        buf_block_t* block= chunk->blocks;
+        buf_block_t *block= chunk->blocks;
 
         for (auto i= chunk->size; i--; block++)
           buf_block_free_mutexes(block);
@@ -1437,15 +1479,14 @@ bool buf_pool_t::create()
       chunks= nullptr;
       UT_DELETE(chunk_t::map_reg);
       chunk_t::map_reg= nullptr;
-      aligned_free(const_cast<byte*>(field_ref_zero));
+      aligned_free(const_cast<byte *>(field_ref_zero));
       field_ref_zero= nullptr;
       ut_ad(!is_initialised());
       return true;
     }
 
     curr_size+= chunk->size;
-  }
-  while (++chunk < chunks + n_chunks);
+  } while (++chunk < chunks + n_chunks);
 
   ut_ad(is_initialised());
   mysql_mutex_init(buf_pool_mutex_key, &mutex, MY_MUTEX_INIT_FAST);
@@ -1462,8 +1503,8 @@ bool buf_pool_t::create()
   old_size= s;
   s/= BUF_READ_AHEAD_PORTION;
   read_ahead_area= s >= READ_AHEAD_PAGES
-    ? READ_AHEAD_PAGES
-    : my_round_up_to_next_power(static_cast<uint32_t>(s));
+                       ? READ_AHEAD_PAGES
+                       : my_round_up_to_next_power(static_cast<uint32_t>(s));
   curr_pool_size= srv_buf_pool_size;
 
   n_chunks_new= n_chunks;
@@ -1522,16 +1563,16 @@ void buf_pool_t::close()
     /* The buffer pool must be clean during normal shutdown.
     Only on aborted startup (with recovery) or with innodb_fast_shutdown=2
     we may discard changes. */
-    ut_d(const lsn_t oldest= bpage->oldest_modification();)
-    ut_ad(fsp_is_system_temporary(bpage->id().space())
-          ? (oldest == 0 || oldest == 2)
-          : oldest <= 1 || srv_is_being_started || srv_fast_shutdown == 2);
+    ut_d(const lsn_t oldest= bpage->oldest_modification();) ut_ad(
+        fsp_is_system_temporary(bpage->id().space())
+            ? (oldest == 0 || oldest == 2)
+            : oldest <= 1 || srv_is_being_started || srv_fast_shutdown == 2);
 
     if (bpage->state() != BUF_BLOCK_FILE_PAGE)
       buf_page_free_descriptor(bpage);
   }
 
-  for (auto chunk= chunks + n_chunks; --chunk >= chunks; )
+  for (auto chunk= chunks + n_chunks; --chunk >= chunks;)
   {
     buf_block_t *block= chunk->blocks;
 
@@ -1554,7 +1595,7 @@ void buf_pool_t::close()
   io_buf.close();
   UT_DELETE(chunk_t::map_reg);
   chunk_t::map_reg= chunk_t::map_ref= nullptr;
-  aligned_free(const_cast<byte*>(field_ref_zero));
+  aligned_free(const_cast<byte *>(field_ref_zero));
   field_ref_zero= nullptr;
 }
 
@@ -1563,306 +1604,305 @@ void buf_pool_t::close()
 @return whether the reallocation succeeded */
 inline bool buf_pool_t::realloc(buf_block_t *block)
 {
-	buf_block_t*	new_block;
-
-	mysql_mutex_assert_owner(&mutex);
-	ut_ad(block->page.state() == BUF_BLOCK_FILE_PAGE);
-
-	new_block = buf_LRU_get_free_only();
-
-	if (new_block == NULL) {
-		return(false); /* free list was not enough */
-	}
-
-	const page_id_t id(block->page.id());
-	page_hash_latch* hash_lock = hash_lock_get(id);
-	hash_lock->write_lock();
-
-	if (block->page.can_relocate()) {
-		memcpy_aligned<OS_FILE_LOG_BLOCK_SIZE>(
-			new_block->frame, block->frame, srv_page_size);
-		mysql_mutex_lock(&buf_pool.flush_list_mutex);
-		new (&new_block->page) buf_page_t(block->page);
-
-		/* relocate LRU list */
-		if (buf_page_t*	prev_b = buf_pool.LRU_remove(&block->page)) {
-			UT_LIST_INSERT_AFTER(LRU, prev_b, &new_block->page);
-		} else {
-			UT_LIST_ADD_FIRST(LRU, &new_block->page);
-		}
-
-		if (LRU_old == &block->page) {
-			LRU_old = &new_block->page;
-		}
-
-		ut_ad(new_block->page.in_LRU_list);
-
-		/* relocate unzip_LRU list */
-		if (block->page.zip.data != NULL) {
-			ut_ad(block->in_unzip_LRU_list);
-			ut_d(new_block->in_unzip_LRU_list = true);
-
-			buf_block_t*	prev_block = UT_LIST_GET_PREV(unzip_LRU, block);
-			UT_LIST_REMOVE(unzip_LRU, block);
-
-			ut_d(block->in_unzip_LRU_list = false);
-			block->page.zip.data = NULL;
-			page_zip_set_size(&block->page.zip, 0);
-
-			if (prev_block != NULL) {
-				UT_LIST_INSERT_AFTER(unzip_LRU, prev_block, new_block);
-			} else {
-				UT_LIST_ADD_FIRST(unzip_LRU, new_block);
-			}
-		} else {
-			ut_ad(!block->in_unzip_LRU_list);
-			ut_d(new_block->in_unzip_LRU_list = false);
-		}
-
-		/* relocate page_hash */
-		ut_ad(block->page.in_page_hash);
-		ut_ad(new_block->page.in_page_hash);
-		const ulint fold = id.fold();
-		ut_ad(&block->page == page_hash_get_low(id, fold));
-		ut_d(block->page.in_page_hash = false);
-		HASH_REPLACE(buf_page_t, hash, &page_hash, fold,
-			     &block->page, &new_block->page);
-
-		buf_block_modify_clock_inc(block);
-		static_assert(FIL_PAGE_OFFSET % 4 == 0, "alignment");
-		memset_aligned<4>(block->frame + FIL_PAGE_OFFSET, 0xff, 4);
-		static_assert(FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID % 4 == 2,
-			      "not perfect alignment");
-		memset_aligned<2>(block->frame
-				  + FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID, 0xff, 4);
-		MEM_UNDEFINED(block->frame, srv_page_size);
-		block->page.set_state(BUF_BLOCK_REMOVE_HASH);
-		if (!fsp_is_system_temporary(id.space())) {
-			buf_flush_relocate_on_flush_list(&block->page,
-							 &new_block->page);
-		}
-		mysql_mutex_unlock(&buf_pool.flush_list_mutex);
-		block->page.set_corrupt_id();
-
-		/* set other flags of buf_block_t */
+  buf_block_t *new_block;
+
+  mysql_mutex_assert_owner(&mutex);
+  ut_ad(block->page.state() == BUF_BLOCK_FILE_PAGE);
+
+  new_block= buf_LRU_get_free_only();
+
+  if (new_block == NULL)
+  {
+    return (false); /* free list was not enough */
+  }
+
+  const page_id_t id(block->page.id());
+  page_hash_latch *hash_lock= hash_lock_get(id);
+  hash_lock->write_lock();
+
+  if (block->page.can_relocate())
+  {
+    memcpy_aligned<OS_FILE_LOG_BLOCK_SIZE>(new_block->frame, block->frame,
+                                           srv_page_size);
+    mysql_mutex_lock(&buf_pool.flush_list_mutex);
+    new (&new_block->page) buf_page_t(block->page);
+
+    /* relocate LRU list */
+    if (buf_page_t *prev_b= buf_pool.LRU_remove(&block->page))
+    {
+      UT_LIST_INSERT_AFTER(LRU, prev_b, &new_block->page);
+    }
+    else
+    {
+      UT_LIST_ADD_FIRST(LRU, &new_block->page);
+    }
+
+    if (LRU_old == &block->page)
+    {
+      LRU_old= &new_block->page;
+    }
+
+    ut_ad(new_block->page.in_LRU_list);
+
+    /* relocate unzip_LRU list */
+    if (block->page.zip.data != NULL)
+    {
+      ut_ad(block->in_unzip_LRU_list);
+      ut_d(new_block->in_unzip_LRU_list= true);
+
+      buf_block_t *prev_block= UT_LIST_GET_PREV(unzip_LRU, block);
+      UT_LIST_REMOVE(unzip_LRU, block);
+
+      ut_d(block->in_unzip_LRU_list= false);
+      block->page.zip.data= NULL;
+      page_zip_set_size(&block->page.zip, 0);
+
+      if (prev_block != NULL)
+      {
+        UT_LIST_INSERT_AFTER(unzip_LRU, prev_block, new_block);
+      }
+      else
+      {
+        UT_LIST_ADD_FIRST(unzip_LRU, new_block);
+      }
+    }
+    else
+    {
+      ut_ad(!block->in_unzip_LRU_list);
+      ut_d(new_block->in_unzip_LRU_list= false);
+    }
+
+    /* relocate page_hash */
+    ut_ad(block->page.in_page_hash);
+    ut_ad(new_block->page.in_page_hash);
+    const ulint fold= id.fold();
+    ut_ad(&block->page == page_hash_get_low(id, fold));
+    ut_d(block->page.in_page_hash= false);
+    HASH_REPLACE(buf_page_t, hash, &page_hash, fold, &block->page,
+                 &new_block->page);
+
+    buf_block_modify_clock_inc(block);
+    static_assert(FIL_PAGE_OFFSET % 4 == 0, "alignment");
+    memset_aligned<4>(block->frame + FIL_PAGE_OFFSET, 0xff, 4);
+    static_assert(FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID % 4 == 2,
+                  "not perfect alignment");
+    memset_aligned<2>(block->frame + FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID, 0xff,
+                      4);
+    MEM_UNDEFINED(block->frame, srv_page_size);
+    block->page.set_state(BUF_BLOCK_REMOVE_HASH);
+    if (!fsp_is_system_temporary(id.space()))
+    {
+      buf_flush_relocate_on_flush_list(&block->page, &new_block->page);
+    }
+    mysql_mutex_unlock(&buf_pool.flush_list_mutex);
+    block->page.set_corrupt_id();
+
+    /* set other flags of buf_block_t */
 
 #ifdef BTR_CUR_HASH_ADAPT
-		/* This code should only be executed by resize(),
-		while the adaptive hash index is disabled. */
-		assert_block_ahi_empty(block);
-		assert_block_ahi_empty_on_init(new_block);
-		ut_ad(!block->index);
-		new_block->index	= NULL;
-		new_block->n_hash_helps	= 0;
-		new_block->n_fields	= 1;
-		new_block->left_side	= TRUE;
+    /* This code should only be executed by resize(),
+    while the adaptive hash index is disabled. */
+    assert_block_ahi_empty(block);
+    assert_block_ahi_empty_on_init(new_block);
+    ut_ad(!block->index);
+    new_block->index= NULL;
+    new_block->n_hash_helps= 0;
+    new_block->n_fields= 1;
+    new_block->left_side= TRUE;
 #endif /* BTR_CUR_HASH_ADAPT */
-		ut_d(block->page.set_state(BUF_BLOCK_MEMORY));
-		/* free block */
-		new_block = block;
-	}
-
-	hash_lock->write_unlock();
-	buf_LRU_block_free_non_file_page(new_block);
-	return(true); /* free_list was enough */
+    ut_d(block->page.set_state(BUF_BLOCK_MEMORY));
+    /* free block */
+    new_block= block;
+  }
+
+  hash_lock->write_unlock();
+  buf_LRU_block_free_non_file_page(new_block);
+  return (true); /* free_list was enough */
 }
 
-/** Sets the global variable that feeds MySQL's innodb_buffer_pool_resize_status
-to the specified string. The format and the following parameters are the
-same as the ones used for printf(3).
+/** Sets the global variable that feeds MySQL's
+innodb_buffer_pool_resize_status to the specified string. The format and the
+following parameters are the same as the ones used for printf(3).
 @param[in]	fmt	format
 @param[in]	...	extra parameters according to fmt */
-static
-void
-buf_resize_status(
-	const char*	fmt,
-	...)
+static void buf_resize_status(const char *fmt, ...)
 {
-	va_list	ap;
+  va_list ap;
 
-	va_start(ap, fmt);
+  va_start(ap, fmt);
 
-	vsnprintf(
-		export_vars.innodb_buffer_pool_resize_status,
-		sizeof(export_vars.innodb_buffer_pool_resize_status),
-		fmt, ap);
+  vsnprintf(export_vars.innodb_buffer_pool_resize_status,
+            sizeof(export_vars.innodb_buffer_pool_resize_status), fmt, ap);
 
-	va_end(ap);
+  va_end(ap);
 
-	ib::info() << export_vars.innodb_buffer_pool_resize_status;
+  ib::info() << export_vars.innodb_buffer_pool_resize_status;
 }
 
 /** Withdraw blocks from the buffer pool until meeting withdraw_target.
 @return whether retry is needed */
 inline bool buf_pool_t::withdraw_blocks()
 {
-	buf_block_t*	block;
-	ulint		loop_count = 0;
-
-	ib::info() << "start to withdraw the last "
-		<< withdraw_target << " blocks";
-
-	/* Minimize zip_free[i] lists */
-	mysql_mutex_lock(&mutex);
-	buf_buddy_condense_free();
-	mysql_mutex_unlock(&mutex);
-
-	while (UT_LIST_GET_LEN(withdraw) < withdraw_target) {
-
-		/* try to withdraw from free_list */
-		ulint	count1 = 0;
-
-		mysql_mutex_lock(&mutex);
-		block = reinterpret_cast<buf_block_t*>(
-			UT_LIST_GET_FIRST(free));
-		while (block != NULL
-		       && UT_LIST_GET_LEN(withdraw) < withdraw_target) {
-			ut_ad(block->page.in_free_list);
-			ut_ad(!block->page.oldest_modification());
-			ut_ad(!block->page.in_LRU_list);
-			ut_a(!block->page.in_file());
-
-			buf_block_t*	next_block;
-			next_block = reinterpret_cast<buf_block_t*>(
-				UT_LIST_GET_NEXT(
-					list, &block->page));
-
-			if (will_be_withdrawn(block->page)) {
-				/* This should be withdrawn */
-				UT_LIST_REMOVE(free, &block->page);
-				UT_LIST_ADD_LAST(withdraw, &block->page);
-				ut_d(block->in_withdraw_list = true);
-				count1++;
-			}
-
-			block = next_block;
-		}
-		mysql_mutex_unlock(&mutex);
-
-		/* reserve free_list length */
-		if (UT_LIST_GET_LEN(withdraw) < withdraw_target) {
-			ulint n_flushed = buf_flush_LRU(
-				std::max<ulint>(withdraw_target
-						- UT_LIST_GET_LEN(withdraw),
-						srv_LRU_scan_depth));
-			buf_flush_wait_batch_end_acquiring_mutex(true);
-
-			if (n_flushed) {
-				MONITOR_INC_VALUE_CUMULATIVE(
-					MONITOR_LRU_BATCH_FLUSH_TOTAL_PAGE,
-					MONITOR_LRU_BATCH_FLUSH_COUNT,
-					MONITOR_LRU_BATCH_FLUSH_PAGES,
-					n_flushed);
-			}
-		}
-
-		/* relocate blocks/buddies in withdrawn area */
-		ulint	count2 = 0;
-
-		mysql_mutex_lock(&mutex);
-		buf_page_t*	bpage;
-		bpage = UT_LIST_GET_FIRST(LRU);
-		while (bpage != NULL) {
-			buf_page_t* next_bpage = UT_LIST_GET_NEXT(LRU, bpage);
-			if (bpage->zip.data != NULL
-			    && will_be_withdrawn(bpage->zip.data)
-			    && bpage->can_relocate()) {
-				buf_pool_mutex_exit_forbid();
-				if (!buf_buddy_realloc(
-					    bpage->zip.data,
-					    page_zip_get_size(&bpage->zip))) {
-					/* failed to allocate block */
-					buf_pool_mutex_exit_allow();
-					break;
-				}
-				buf_pool_mutex_exit_allow();
-				count2++;
-			}
-
-			if (bpage->state() == BUF_BLOCK_FILE_PAGE
-			    && will_be_withdrawn(*bpage)) {
-				if (bpage->can_relocate()) {
-					buf_pool_mutex_exit_forbid();
-					if (!realloc(
-						reinterpret_cast<buf_block_t*>(
-							bpage))) {
-						/* failed to allocate block */
-						buf_pool_mutex_exit_allow();
-						break;
-					}
-					buf_pool_mutex_exit_allow();
-					count2++;
-				}
-				/* NOTE: if the page is in use,
-				not relocated yet */
-			}
-
-			bpage = next_bpage;
-		}
-		mysql_mutex_unlock(&mutex);
-
-		buf_resize_status(
-			"withdrawing blocks. (" ULINTPF "/" ULINTPF ")",
-			UT_LIST_GET_LEN(withdraw),
-			withdraw_target);
-
-		ib::info() << "withdrew "
-			<< count1 << " blocks from free list."
-			<< " Tried to relocate " << count2 << " pages ("
-			<< UT_LIST_GET_LEN(withdraw) << "/"
-			<< withdraw_target << ")";
-
-		if (++loop_count >= 10) {
-			/* give up for now.
-			retried after user threads paused. */
-
-			ib::info() << "will retry to withdraw later";
-
-			/* need retry later */
-			return(true);
-		}
-	}
-
-	/* confirm withdrawn enough */
-	for (const chunk_t* chunk = chunks + n_chunks_new,
-	     * const echunk = chunks + n_chunks; chunk != echunk; chunk++) {
-		block = chunk->blocks;
-		for (ulint j = chunk->size; j--; block++) {
-			ut_a(block->page.state() == BUF_BLOCK_NOT_USED);
-			ut_ad(block->in_withdraw_list);
-		}
-	}
-
-	ib::info() << "withdrawn target: " << UT_LIST_GET_LEN(withdraw)
-		   << " blocks";
-
-	return(false);
-}
+  buf_block_t *block;
+  ulint loop_count= 0;
+
+  ib::info() << "start to withdraw the last " << withdraw_target << " blocks";
+
+  /* Minimize zip_free[i] lists */
+  mysql_mutex_lock(&mutex);
+  buf_buddy_condense_free();
+  mysql_mutex_unlock(&mutex);
+
+  while (UT_LIST_GET_LEN(withdraw) < withdraw_target)
+  {
 
+    /* try to withdraw from free_list */
+    ulint count1= 0;
 
+    mysql_mutex_lock(&mutex);
+    block= reinterpret_cast<buf_block_t *>(UT_LIST_GET_FIRST(free));
+    while (block != NULL && UT_LIST_GET_LEN(withdraw) < withdraw_target)
+    {
+      ut_ad(block->page.in_free_list);
+      ut_ad(!block->page.oldest_modification());
+      ut_ad(!block->page.in_LRU_list);
+      ut_a(!block->page.in_file());
+
+      buf_block_t *next_block;
+      next_block= reinterpret_cast<buf_block_t *>(
+          UT_LIST_GET_NEXT(list, &block->page));
+
+      if (will_be_withdrawn(block->page))
+      {
+        /* This should be withdrawn */
+        UT_LIST_REMOVE(free, &block->page);
+        UT_LIST_ADD_LAST(withdraw, &block->page);
+        ut_d(block->in_withdraw_list= true);
+        count1++;
+      }
+
+      block= next_block;
+    }
+    mysql_mutex_unlock(&mutex);
+
+    /* reserve free_list length */
+    if (UT_LIST_GET_LEN(withdraw) < withdraw_target)
+    {
+      ulint n_flushed= buf_flush_LRU(std::max<ulint>(
+          withdraw_target - UT_LIST_GET_LEN(withdraw), srv_LRU_scan_depth));
+      buf_flush_wait_batch_end_acquiring_mutex(true);
+
+      if (n_flushed)
+      {
+        MONITOR_INC_VALUE_CUMULATIVE(MONITOR_LRU_BATCH_FLUSH_TOTAL_PAGE,
+                                     MONITOR_LRU_BATCH_FLUSH_COUNT,
+                                     MONITOR_LRU_BATCH_FLUSH_PAGES, n_flushed);
+      }
+    }
+
+    /* relocate blocks/buddies in withdrawn area */
+    ulint count2= 0;
+
+    mysql_mutex_lock(&mutex);
+    buf_page_t *bpage;
+    bpage= UT_LIST_GET_FIRST(LRU);
+    while (bpage != NULL)
+    {
+      buf_page_t *next_bpage= UT_LIST_GET_NEXT(LRU, bpage);
+      if (bpage->zip.data != NULL && will_be_withdrawn(bpage->zip.data) &&
+          bpage->can_relocate())
+      {
+        buf_pool_mutex_exit_forbid();
+        if (!buf_buddy_realloc(bpage->zip.data,
+                               page_zip_get_size(&bpage->zip)))
+        {
+          /* failed to allocate block */
+          buf_pool_mutex_exit_allow();
+          break;
+        }
+        buf_pool_mutex_exit_allow();
+        count2++;
+      }
+
+      if (bpage->state() == BUF_BLOCK_FILE_PAGE && will_be_withdrawn(*bpage))
+      {
+        if (bpage->can_relocate())
+        {
+          buf_pool_mutex_exit_forbid();
+          if (!realloc(reinterpret_cast<buf_block_t *>(bpage)))
+          {
+            /* failed to allocate block */
+            buf_pool_mutex_exit_allow();
+            break;
+          }
+          buf_pool_mutex_exit_allow();
+          count2++;
+        }
+        /* NOTE: if the page is in use,
+        not relocated yet */
+      }
+
+      bpage= next_bpage;
+    }
+    mysql_mutex_unlock(&mutex);
+
+    buf_resize_status("withdrawing blocks. (" ULINTPF "/" ULINTPF ")",
+                      UT_LIST_GET_LEN(withdraw), withdraw_target);
+
+    ib::info() << "withdrew " << count1 << " blocks from free list."
+               << " Tried to relocate " << count2 << " pages ("
+               << UT_LIST_GET_LEN(withdraw) << "/" << withdraw_target << ")";
+
+    if (++loop_count >= 10)
+    {
+      /* give up for now.
+      retried after user threads paused. */
+
+      ib::info() << "will retry to withdraw later";
+
+      /* need retry later */
+      return (true);
+    }
+  }
+
+  /* confirm withdrawn enough */
+  for (const chunk_t *chunk= chunks + n_chunks_new, *const echunk=
+                                                        chunks + n_chunks;
+       chunk != echunk; chunk++)
+  {
+    block= chunk->blocks;
+    for (ulint j= chunk->size; j--; block++)
+    {
+      ut_a(block->page.state() == BUF_BLOCK_NOT_USED);
+      ut_ad(block->in_withdraw_list);
+    }
+  }
+
+  ib::info() << "withdrawn target: " << UT_LIST_GET_LEN(withdraw) << " blocks";
+
+  return (false);
+}
 
 inline void buf_pool_t::page_hash_table::write_lock_all()
 {
   for (auto n= pad(n_cells) & ~ELEMENTS_PER_LATCH;; n-= ELEMENTS_PER_LATCH + 1)
   {
-    reinterpret_cast<page_hash_latch&>(array[n]).write_lock();
+    reinterpret_cast<page_hash_latch &>(array[n]).write_lock();
     if (!n)
       break;
   }
 }
 
-
 inline void buf_pool_t::page_hash_table::write_unlock_all()
 {
   for (auto n= pad(n_cells) & ~ELEMENTS_PER_LATCH;; n-= ELEMENTS_PER_LATCH + 1)
   {
-    reinterpret_cast<page_hash_latch&>(array[n]).write_unlock();
+    reinterpret_cast<page_hash_latch &>(array[n]).write_unlock();
     if (!n)
       break;
   }
 }
 
-
 namespace
 {
 
@@ -1903,352 +1943,375 @@ inline void buf_pool_t::resize()
 {
   ut_ad(this == &buf_pool);
 
-	bool		warning = false;
+  bool warning= false;
 
-	NUMA_MEMPOLICY_INTERLEAVE_IN_SCOPE;
+  NUMA_MEMPOLICY_INTERLEAVE_IN_SCOPE;
 
-	ut_ad(!resize_in_progress());
-	ut_ad(srv_buf_pool_chunk_unit > 0);
+  ut_ad(!resize_in_progress());
+  ut_ad(srv_buf_pool_chunk_unit > 0);
 
-	ulint new_instance_size = srv_buf_pool_size >> srv_page_size_shift;
+  ulint new_instance_size= srv_buf_pool_size >> srv_page_size_shift;
 
-	buf_resize_status("Resizing buffer pool from " ULINTPF " to "
-			  ULINTPF " (unit=" ULINTPF ").",
-			  srv_buf_pool_old_size, srv_buf_pool_size,
-			  srv_buf_pool_chunk_unit);
+  buf_resize_status("Resizing buffer pool from " ULINTPF " to " ULINTPF
+                    " (unit=" ULINTPF ").",
+                    srv_buf_pool_old_size, srv_buf_pool_size,
+                    srv_buf_pool_chunk_unit);
 
-	mysql_mutex_lock(&mutex);
-	ut_ad(curr_size == old_size);
-	ut_ad(n_chunks_new == n_chunks);
-	ut_ad(UT_LIST_GET_LEN(withdraw) == 0);
+  mysql_mutex_lock(&mutex);
+  ut_ad(curr_size == old_size);
+  ut_ad(n_chunks_new == n_chunks);
+  ut_ad(UT_LIST_GET_LEN(withdraw) == 0);
 
-	n_chunks_new = (new_instance_size << srv_page_size_shift)
-		/ srv_buf_pool_chunk_unit;
-	curr_size = n_chunks_new * chunks->size;
-	mysql_mutex_unlock(&mutex);
+  n_chunks_new=
+      (new_instance_size << srv_page_size_shift) / srv_buf_pool_chunk_unit;
+  curr_size= n_chunks_new * chunks->size;
+  mysql_mutex_unlock(&mutex);
 
 #ifdef BTR_CUR_HASH_ADAPT
-	/* disable AHI if needed */
-	const bool btr_search_disabled = btr_search_enabled;
+  /* disable AHI if needed */
+  const bool btr_search_disabled= btr_search_enabled;
 
-	buf_resize_status("Disabling adaptive hash index.");
+  buf_resize_status("Disabling adaptive hash index.");
 
-	btr_search_s_lock_all();
-	if (btr_search_disabled) {
-		btr_search_s_unlock_all();
-	} else {
-		btr_search_s_unlock_all();
-	}
+  btr_search_s_lock_all();
+  if (btr_search_disabled)
+  {
+    btr_search_s_unlock_all();
+  }
+  else
+  {
+    btr_search_s_unlock_all();
+  }
 
-	btr_search_disable();
+  btr_search_disable();
 
-	if (btr_search_disabled) {
-		ib::info() << "disabled adaptive hash index.";
-	}
+  if (btr_search_disabled)
+  {
+    ib::info() << "disabled adaptive hash index.";
+  }
 #endif /* BTR_CUR_HASH_ADAPT */
 
-	if (curr_size < old_size) {
-		/* set withdraw target */
-		size_t w = 0;
+  if (curr_size < old_size)
+  {
+    /* set withdraw target */
+    size_t w= 0;
 
-		for (const chunk_t* chunk = chunks + n_chunks_new,
-		     * const echunk = chunks + n_chunks;
-		     chunk != echunk; chunk++)
-			w += chunk->size;
+    for (const chunk_t *chunk= chunks + n_chunks_new, *const echunk=
+                                                          chunks + n_chunks;
+         chunk != echunk; chunk++)
+      w+= chunk->size;
 
-		ut_ad(withdraw_target == 0);
-		withdraw_target = w;
-	}
+    ut_ad(withdraw_target == 0);
+    withdraw_target= w;
+  }
 
-	buf_resize_status("Withdrawing blocks to be shrunken.");
+  buf_resize_status("Withdrawing blocks to be shrunken.");
 
-	time_t		withdraw_started = time(NULL);
-	double		message_interval = 60;
-	ulint		retry_interval = 1;
+  time_t withdraw_started= time(NULL);
+  double message_interval= 60;
+  ulint retry_interval= 1;
 
 withdraw_retry:
-	/* wait for the number of blocks fit to the new size (if needed)*/
-	bool	should_retry_withdraw = curr_size < old_size
-		&& withdraw_blocks();
+  /* wait for the number of blocks fit to the new size (if needed)*/
+  bool should_retry_withdraw= curr_size < old_size && withdraw_blocks();
+
+  if (srv_shutdown_state != SRV_SHUTDOWN_NONE)
+  {
+    /* abort to resize for shutdown. */
+    return;
+  }
+
+  /* abort buffer pool load */
+  buf_load_abort();
+
+  const time_t current_time= time(NULL);
+
+  if (should_retry_withdraw &&
+      difftime(current_time, withdraw_started) >= message_interval)
+  {
+
+    if (message_interval > 900)
+    {
+      message_interval= 1800;
+    }
+    else
+    {
+      message_interval*= 2;
+    }
+
+    lock_mutex_enter();
+    bool found= false;
+    trx_sys.trx_list.for_each(
+        find_interesting_trx{found, withdraw_started, current_time});
+    lock_mutex_exit();
+
+    withdraw_started= current_time;
+  }
+
+  if (should_retry_withdraw)
+  {
+    ib::info() << "Will retry to withdraw " << retry_interval
+               << " seconds later.";
+    os_thread_sleep(retry_interval * 1000000);
+
+    if (retry_interval > 5)
+    {
+      retry_interval= 10;
+    }
+    else
+    {
+      retry_interval*= 2;
+    }
+
+    goto withdraw_retry;
+  }
+
+  buf_resize_status("Latching whole of buffer pool.");
+
+#ifndef DBUG_OFF
+  {
+    bool should_wait= true;
+
+    while (should_wait)
+    {
+      should_wait= false;
+      DBUG_EXECUTE_IF("ib_buf_pool_resize_wait_before_resize",
+                      should_wait= true;
+                      os_thread_sleep(10000););
+    }
+  }
+#endif /* !DBUG_OFF */
+
+  if (srv_shutdown_state != SRV_SHUTDOWN_NONE)
+  {
+    return;
+  }
+
+  /* Indicate critical path */
+  resizing.store(true, std::memory_order_relaxed);
+
+  mysql_mutex_lock(&mutex);
+  page_hash.write_lock_all();
+
+  chunk_t::map_reg= UT_NEW_NOKEY(chunk_t::map());
+
+  /* add/delete chunks */
+
+  buf_resize_status("buffer pool resizing with chunks " ULINTPF " to " ULINTPF
+                    ".",
+                    n_chunks, n_chunks_new);
+
+  if (n_chunks_new < n_chunks)
+  {
+    /* delete chunks */
+    chunk_t *chunk= chunks + n_chunks_new;
+    const chunk_t *const echunk= chunks + n_chunks;
+
+    ulint sum_freed= 0;
 
-	if (srv_shutdown_state != SRV_SHUTDOWN_NONE) {
-		/* abort to resize for shutdown. */
-		return;
-	}
+    while (chunk < echunk)
+    {
+      /* buf_LRU_block_free_non_file_page() invokes
+      MEM_NOACCESS() on any buf_pool.free blocks.
+      We must cancel the effect of that. In
+      MemorySanitizer, MEM_NOACCESS() is no-op, so
+      we must not do anything special for it here. */
+#ifdef HAVE_valgrind
+#if !__has_feature(memory_sanitizer)
+      MEM_MAKE_DEFINED(chunk->mem, chunk->mem_size());
+#endif
+#else
+      MEM_MAKE_ADDRESSABLE(chunk->mem, chunk->size);
+#endif
+
+      buf_block_t *block= chunk->blocks;
+
+      for (ulint j= chunk->size; j--; block++)
+      {
+        buf_block_free_mutexes(block);
+      }
 
-	/* abort buffer pool load */
-	buf_load_abort();
+      allocator.deallocate_large_dodump(chunk->mem, &chunk->mem_pfx);
+      sum_freed+= chunk->size;
+      ++chunk;
+    }
 
-	const time_t current_time = time(NULL);
+    /* discard withdraw list */
+    UT_LIST_INIT(withdraw, &buf_page_t::list);
+    withdraw_target= 0;
 
-	if (should_retry_withdraw
-	    && difftime(current_time, withdraw_started) >= message_interval) {
+    ib::info() << n_chunks - n_chunks_new << " chunks (" << sum_freed
+               << " blocks) were freed.";
 
-		if (message_interval > 900) {
-			message_interval = 1800;
-		} else {
-			message_interval *= 2;
-		}
+    n_chunks= n_chunks_new;
+  }
 
-		lock_mutex_enter();
-		bool	found = false;
-		trx_sys.trx_list.for_each(find_interesting_trx{
-			found, withdraw_started, current_time});
-		lock_mutex_exit();
+  {
+    /* reallocate chunks */
+    const size_t new_chunks_size= n_chunks_new * sizeof(chunk_t);
+
+    chunk_t *new_chunks=
+        static_cast<chunk_t *>(ut_zalloc_nokey_nofatal(new_chunks_size));
 
-		withdraw_started = current_time;
-	}
+    DBUG_EXECUTE_IF("buf_pool_resize_chunk_null", ut_free(new_chunks);
+                    new_chunks= nullptr;);
 
-	if (should_retry_withdraw) {
-		ib::info() << "Will retry to withdraw " << retry_interval
-			<< " seconds later.";
-		os_thread_sleep(retry_interval * 1000000);
+    if (!new_chunks)
+    {
+      ib::error() << "failed to allocate"
+                     " the chunk array.";
+      n_chunks_new= n_chunks;
+      warning= true;
+      chunks_old= NULL;
+      goto calc_buf_pool_size;
+    }
 
-		if (retry_interval > 5) {
-			retry_interval = 10;
-		} else {
-			retry_interval *= 2;
-		}
+    ulint n_chunks_copy= ut_min(n_chunks_new, n_chunks);
 
-		goto withdraw_retry;
-	}
+    memcpy(new_chunks, chunks, n_chunks_copy * sizeof *new_chunks);
 
-	buf_resize_status("Latching whole of buffer pool.");
+    for (ulint j= 0; j < n_chunks_copy; j++)
+    {
+      new_chunks[j].reg();
+    }
 
-#ifndef DBUG_OFF
-	{
-		bool	should_wait = true;
-
-		while (should_wait) {
-			should_wait = false;
-			DBUG_EXECUTE_IF(
-				"ib_buf_pool_resize_wait_before_resize",
-				should_wait = true; os_thread_sleep(10000););
-		}
-	}
-#endif /* !DBUG_OFF */
+    chunks_old= chunks;
+    chunks= new_chunks;
+  }
 
-	if (srv_shutdown_state != SRV_SHUTDOWN_NONE) {
-		return;
-	}
+  if (n_chunks_new > n_chunks)
+  {
+    /* add chunks */
+    ulint sum_added= 0;
+    ulint n= n_chunks;
+    const size_t unit= srv_buf_pool_chunk_unit;
+
+    for (chunk_t *chunk= chunks + n_chunks, *const echunk=
+                                                chunks + n_chunks_new;
+         chunk != echunk; chunk++)
+    {
+      if (!chunk->create(unit))
+      {
+        ib::error() << "failed to allocate"
+                       " memory for buffer pool chunk";
 
-	/* Indicate critical path */
-	resizing.store(true, std::memory_order_relaxed);
+        warning= true;
+        n_chunks_new= n_chunks;
+        break;
+      }
 
-  mysql_mutex_lock(&mutex);
-  page_hash.write_lock_all();
+      sum_added+= chunk->size;
+      ++n;
+    }
 
-	chunk_t::map_reg = UT_NEW_NOKEY(chunk_t::map());
+    ib::info() << n_chunks_new - n_chunks << " chunks (" << sum_added
+               << " blocks) were added.";
 
-	/* add/delete chunks */
+    n_chunks= n;
+  }
+calc_buf_pool_size:
+  /* recalc curr_size */
+  ulint new_size= 0;
 
-	buf_resize_status("buffer pool resizing with chunks "
-			  ULINTPF " to " ULINTPF ".",
-			  n_chunks, n_chunks_new);
+  {
+    chunk_t *chunk= chunks;
+    const chunk_t *const echunk= chunk + n_chunks;
+    do
+    {
+      new_size+= chunk->size;
+    } while (++chunk != echunk);
+  }
 
-	if (n_chunks_new < n_chunks) {
-		/* delete chunks */
-		chunk_t* chunk = chunks + n_chunks_new;
-		const chunk_t* const echunk = chunks + n_chunks;
+  curr_size= new_size;
+  n_chunks_new= n_chunks;
 
-		ulint	sum_freed = 0;
+  if (chunks_old)
+  {
+    ut_free(chunks_old);
+    chunks_old= NULL;
+  }
 
-		while (chunk < echunk) {
-			/* buf_LRU_block_free_non_file_page() invokes
-			MEM_NOACCESS() on any buf_pool.free blocks.
-			We must cancel the effect of that. In
-			MemorySanitizer, MEM_NOACCESS() is no-op, so
-			we must not do anything special for it here. */
-#ifdef HAVE_valgrind
-# if !__has_feature(memory_sanitizer)
-			MEM_MAKE_DEFINED(chunk->mem, chunk->mem_size());
-# endif
-#else
-			MEM_MAKE_ADDRESSABLE(chunk->mem, chunk->size);
-#endif
+  chunk_t::map *chunk_map_old= chunk_t::map_ref;
+  chunk_t::map_ref= chunk_t::map_reg;
 
-			buf_block_t*	block = chunk->blocks;
-
-			for (ulint j = chunk->size; j--; block++) {
-				buf_block_free_mutexes(block);
-			}
-
-			allocator.deallocate_large_dodump(
-				chunk->mem, &chunk->mem_pfx);
-			sum_freed += chunk->size;
-			++chunk;
-		}
-
-		/* discard withdraw list */
-		UT_LIST_INIT(withdraw, &buf_page_t::list);
-		withdraw_target = 0;
-
-		ib::info() << n_chunks - n_chunks_new
-			   << " chunks (" << sum_freed
-			   << " blocks) were freed.";
-
-		n_chunks = n_chunks_new;
-	}
-
-	{
-		/* reallocate chunks */
-		const size_t	new_chunks_size
-			= n_chunks_new * sizeof(chunk_t);
-
-		chunk_t*	new_chunks = static_cast<chunk_t*>(
-			ut_zalloc_nokey_nofatal(new_chunks_size));
-
-		DBUG_EXECUTE_IF("buf_pool_resize_chunk_null",
-				ut_free(new_chunks); new_chunks= nullptr; );
-
-		if (!new_chunks) {
-			ib::error() << "failed to allocate"
-				" the chunk array.";
-			n_chunks_new = n_chunks;
-			warning = true;
-			chunks_old = NULL;
-			goto calc_buf_pool_size;
-		}
-
-		ulint	n_chunks_copy = ut_min(n_chunks_new,
-					       n_chunks);
-
-		memcpy(new_chunks, chunks,
-		       n_chunks_copy * sizeof *new_chunks);
-
-		for (ulint j = 0; j < n_chunks_copy; j++) {
-			new_chunks[j].reg();
-		}
-
-		chunks_old = chunks;
-		chunks = new_chunks;
-	}
-
-	if (n_chunks_new > n_chunks) {
-		/* add chunks */
-		ulint	sum_added = 0;
-		ulint	n = n_chunks;
-		const size_t unit = srv_buf_pool_chunk_unit;
-
-		for (chunk_t* chunk = chunks + n_chunks,
-		     * const echunk = chunks + n_chunks_new;
-		     chunk != echunk; chunk++) {
-			if (!chunk->create(unit)) {
-				ib::error() << "failed to allocate"
-					" memory for buffer pool chunk";
-
-				warning = true;
-				n_chunks_new = n_chunks;
-				break;
-			}
-
-			sum_added += chunk->size;
-			++n;
-		}
-
-		ib::info() << n_chunks_new - n_chunks
-			   << " chunks (" << sum_added
-			   << " blocks) were added.";
-
-		n_chunks = n;
-	}
-calc_buf_pool_size:
-	/* recalc curr_size */
-	ulint	new_size = 0;
-
-	{
-		chunk_t* chunk = chunks;
-		const chunk_t* const echunk = chunk + n_chunks;
-		do {
-			new_size += chunk->size;
-		} while (++chunk != echunk);
-	}
-
-	curr_size = new_size;
-	n_chunks_new = n_chunks;
-
-	if (chunks_old) {
-		ut_free(chunks_old);
-		chunks_old = NULL;
-	}
-
-	chunk_t::map* chunk_map_old = chunk_t::map_ref;
-	chunk_t::map_ref = chunk_t::map_reg;
-
-	/* set size */
-	ut_ad(UT_LIST_GET_LEN(withdraw) == 0);
+  /* set size */
+  ut_ad(UT_LIST_GET_LEN(withdraw) == 0);
   ulint s= curr_size;
   old_size= s;
   s/= BUF_READ_AHEAD_PORTION;
   read_ahead_area= s >= READ_AHEAD_PAGES
-    ? READ_AHEAD_PAGES
-    : my_round_up_to_next_power(static_cast<uint32_t>(s));
+                       ? READ_AHEAD_PAGES
+                       : my_round_up_to_next_power(static_cast<uint32_t>(s));
   curr_pool_size= n_chunks * srv_buf_pool_chunk_unit;
-  srv_buf_pool_curr_size= curr_pool_size;/* FIXME: remove*/
+  srv_buf_pool_curr_size= curr_pool_size; /* FIXME: remove*/
   innodb_set_buf_pool_size(buf_pool_size_align(srv_buf_pool_curr_size));
 
-	const bool	new_size_too_diff
-		= srv_buf_pool_base_size > srv_buf_pool_size * 2
-			|| srv_buf_pool_base_size * 2 < srv_buf_pool_size;
+  const bool new_size_too_diff=
+      srv_buf_pool_base_size > srv_buf_pool_size * 2 ||
+      srv_buf_pool_base_size * 2 < srv_buf_pool_size;
 
   mysql_mutex_unlock(&mutex);
   page_hash.write_unlock_all();
 
-	UT_DELETE(chunk_map_old);
+  UT_DELETE(chunk_map_old);
 
-	resizing.store(false, std::memory_order_relaxed);
+  resizing.store(false, std::memory_order_relaxed);
 
-	/* Normalize other components, if the new size is too different */
-	if (!warning && new_size_too_diff) {
-		srv_buf_pool_base_size = srv_buf_pool_size;
+  /* Normalize other components, if the new size is too different */
+  if (!warning && new_size_too_diff)
+  {
+    srv_buf_pool_base_size= srv_buf_pool_size;
 
-		buf_resize_status("Resizing also other hash tables.");
+    buf_resize_status("Resizing also other hash tables.");
 
-		srv_lock_table_size = 5
-			* (srv_buf_pool_size >> srv_page_size_shift);
-		lock_sys.resize(srv_lock_table_size);
-		dict_sys.resize();
+    srv_lock_table_size= 5 * (srv_buf_pool_size >> srv_page_size_shift);
+    lock_sys.resize(srv_lock_table_size);
+    dict_sys.resize();
 
-		ib::info() << "Resized hash tables at lock_sys,"
+    ib::info() << "Resized hash tables at lock_sys,"
 #ifdef BTR_CUR_HASH_ADAPT
-			" adaptive hash index,"
+                  " adaptive hash index,"
 #endif /* BTR_CUR_HASH_ADAPT */
-			" dictionary.";
-	}
+                  " dictionary.";
+  }
 
-	/* normalize ibuf.max_size */
-	ibuf_max_size_update(srv_change_buffer_max_size);
+  /* normalize ibuf.max_size */
+  ibuf_max_size_update(srv_change_buffer_max_size);
 
-	if (srv_buf_pool_old_size != srv_buf_pool_size) {
+  if (srv_buf_pool_old_size != srv_buf_pool_size)
+  {
 
-		ib::info() << "Completed to resize buffer pool from "
-			<< srv_buf_pool_old_size
-			<< " to " << srv_buf_pool_size << ".";
-		srv_buf_pool_old_size = srv_buf_pool_size;
-	}
+    ib::info() << "Completed to resize buffer pool from "
+               << srv_buf_pool_old_size << " to " << srv_buf_pool_size << ".";
+    srv_buf_pool_old_size= srv_buf_pool_size;
+  }
 
 #ifdef BTR_CUR_HASH_ADAPT
-	/* enable AHI if needed */
-	if (btr_search_disabled) {
-		btr_search_enable(true);
-		ib::info() << "Re-enabled adaptive hash index.";
-	}
+  /* enable AHI if needed */
+  if (btr_search_disabled)
+  {
+    btr_search_enable(true);
+    ib::info() << "Re-enabled adaptive hash index.";
+  }
 #endif /* BTR_CUR_HASH_ADAPT */
 
-	char	now[32];
+  char now[32];
 
-	ut_sprintf_timestamp(now);
-	if (!warning) {
-		buf_resize_status("Completed resizing buffer pool at %s.",
-			now);
-	} else {
-		buf_resize_status("Resizing buffer pool failed,"
-			" finished resizing at %s.", now);
-	}
+  ut_sprintf_timestamp(now);
+  if (!warning)
+  {
+    buf_resize_status("Completed resizing buffer pool at %s.", now);
+  }
+  else
+  {
+    buf_resize_status("Resizing buffer pool failed,"
+                      " finished resizing at %s.",
+                      now);
+  }
 
-	ut_d(validate());
+  ut_d(validate());
 
-	return;
+  return;
 }
 
 /** Thread pool task invoked by innodb_buffer_pool_size changes. */
@@ -2272,21 +2335,15 @@ static void buf_resize_callback(void *)
   DBUG_VOID_RETURN;
 }
 
-/* Ensure that task does not run in parallel, by setting max_concurrency to 1 for the thread group */
+/* Ensure that task does not run in parallel, by setting max_concurrency to 1
+ * for the thread group */
 static tpool::task_group single_threaded_group(1);
-static tpool::waitable_task buf_resize_task(buf_resize_callback,
-	nullptr, &single_threaded_group);
-
-void buf_resize_start()
-{
-	srv_thread_pool->submit_task(&buf_resize_task);
-}
+static tpool::waitable_task buf_resize_task(buf_resize_callback, nullptr,
+                                            &single_threaded_group);
 
-void buf_resize_shutdown()
-{
-	buf_resize_task.wait();
-}
+void buf_resize_start() { srv_thread_pool->submit_task(&buf_resize_task); }
 
+void buf_resize_shutdown() { buf_resize_task.wait(); }
 
 /** Relocate a ROW_FORMAT=COMPRESSED block in the LRU list and
 buf_pool.page_hash.
@@ -2375,7 +2432,7 @@ inline buf_page_t *buf_pool_t::watch_set(const page_id_t id,
   /* The maximum number of purge tasks should never exceed
   the UT_ARR_SIZE(watch) - 1, and there is no way for a purge task to hold a
   watch when setting another watch. */
-  for (buf_page_t *w= &watch[UT_ARR_SIZE(watch)]; w-- >= watch; )
+  for (buf_page_t *w= &watch[UT_ARR_SIZE(watch)]; w-- >= watch;)
   {
     ut_ad(w->access_time == 0);
     ut_ad(!w->oldest_modification());
@@ -2478,15 +2535,15 @@ void buf_page_free(fil_space_t *space, uint32_t page, mtr_t *mtr,
 #if defined HAVE_FALLOC_PUNCH_HOLE_AND_KEEP_SIZE || defined _WIN32
       || space->is_compressed()
 #endif
-      )
+  )
     mtr->add_freed_offset(space, page);
 
   buf_pool.stat.n_page_gets++;
   const page_id_t page_id(space->id, page);
   const ulint fold= page_id.fold();
   page_hash_latch *hash_lock= buf_pool.page_hash.lock<false>(fold);
-  if (buf_block_t *block= reinterpret_cast<buf_block_t*>
-      (buf_pool.page_hash_get_low(page_id, fold)))
+  if (buf_block_t *block= reinterpret_cast<buf_block_t *>(
+          buf_pool.page_hash_get_low(page_id, fold)))
   {
     if (block->page.state() != BUF_BLOCK_FILE_PAGE)
       /* FIXME: convert, but avoid buf_zip_decompress() */;
@@ -2518,7 +2575,7 @@ the same set of mutexes or latches.
 @param[in]	page_id		page id
 @param[in]	zip_size	ROW_FORMAT=COMPRESSED page size
 @return pointer to the block */
-buf_page_t* buf_page_get_zip(const page_id_t page_id, ulint zip_size)
+buf_page_t *buf_page_get_zip(const page_id_t page_id, ulint zip_size)
 {
   ut_ad(zip_size);
   ut_ad(ut_is_2pow(zip_size));
@@ -2531,7 +2588,7 @@ buf_page_t* buf_page_get_zip(const page_id_t page_id, ulint zip_size)
 
   for (;;)
   {
-lookup:
+  lookup:
     bpage= buf_pool.page_hash_get_locked<false>(page_id, fold, &hash_lock);
     if (bpage)
       break;
@@ -2546,7 +2603,8 @@ buf_page_t* buf_page_get_zip(const page_id_t page_id, ulint zip_size)
     }
 
 #ifdef UNIV_DEBUG
-    if (!(++buf_dbg_counter % 5771)) buf_pool.validate();
+    if (!(++buf_dbg_counter % 5771))
+      buf_pool.validate();
 #endif /* UNIV_DEBUG */
   }
 
@@ -2555,14 +2613,15 @@ buf_page_t* buf_page_get_zip(const page_id_t page_id, ulint zip_size)
   if (!bpage->zip.data)
   {
     /* There is no compressed page. */
-err_exit:
+  err_exit:
     hash_lock->read_unlock();
     return nullptr;
   }
 
   ut_ad(!buf_pool.watch_is_sentinel(*bpage));
 
-  switch (bpage->state()) {
+  switch (bpage->state())
+  {
   case BUF_BLOCK_ZIP_PAGE:
     bpage->fix();
     goto got_block;
@@ -2579,8 +2638,8 @@ buf_page_t* buf_page_get_zip(const page_id_t page_id, ulint zip_size)
       goto lookup;
     }
 
-    buf_block_buf_fix_inc(reinterpret_cast<buf_block_t*>(bpage),
-                          __FILE__, __LINE__);
+    buf_block_buf_fix_inc(reinterpret_cast<buf_block_t *>(bpage), __FILE__,
+                          __LINE__);
     goto got_block;
   default:
     break;
@@ -2599,7 +2658,8 @@ buf_page_t* buf_page_get_zip(const page_id_t page_id, ulint zip_size)
   buf_page_make_young_if_needed(bpage);
 
 #ifdef UNIV_DEBUG
-  if (!(++buf_dbg_counter % 5771)) buf_pool.validate();
+  if (!(++buf_dbg_counter % 5771))
+    buf_pool.validate();
 #endif /* UNIV_DEBUG */
   ut_ad(bpage->buf_fix_count());
   ut_ad(bpage->in_file());
@@ -2612,145 +2672,145 @@ buf_page_t* buf_page_get_zip(const page_id_t page_id, ulint zip_size)
   return bpage;
 }
 
-/********************************************************************//**
-Initialize some fields of a control block. */
+/********************************************************************/ /**
+ Initialize some fields of a control block. */
 UNIV_INLINE
-void
-buf_block_init_low(
-/*===============*/
-	buf_block_t*	block)	/*!< in: block to init */
+void buf_block_init_low(
+    /*===============*/
+    buf_block_t *block) /*!< in: block to init */
 {
 #ifdef BTR_CUR_HASH_ADAPT
-	/* No adaptive hash index entries may point to a previously
-	unused (and now freshly allocated) block. */
-	assert_block_ahi_empty_on_init(block);
-	block->index		= NULL;
-
-	block->n_hash_helps	= 0;
-	block->n_fields		= 1;
-	block->n_bytes		= 0;
-	block->left_side	= TRUE;
+  /* No adaptive hash index entries may point to a previously
+  unused (and now freshly allocated) block. */
+  assert_block_ahi_empty_on_init(block);
+  block->index= NULL;
+
+  block->n_hash_helps= 0;
+  block->n_fields= 1;
+  block->n_bytes= 0;
+  block->left_side= TRUE;
 #endif /* BTR_CUR_HASH_ADAPT */
 }
 
-/********************************************************************//**
-Decompress a block.
-@return TRUE if successful */
-ibool
-buf_zip_decompress(
-/*===============*/
-	buf_block_t*	block,	/*!< in/out: block */
-	ibool		check)	/*!< in: TRUE=verify the page checksum */
+/********************************************************************/ /**
+ Decompress a block.
+ @return TRUE if successful */
+ibool buf_zip_decompress(
+    /*===============*/
+    buf_block_t *block, /*!< in/out: block */
+    ibool check)        /*!< in: TRUE=verify the page checksum */
 {
-	const byte*	frame = block->page.zip.data;
-	ulint		size = page_zip_get_size(&block->page.zip);
-	/* The tablespace will not be found if this function is called
-	during IMPORT. */
-	fil_space_t* space= fil_space_t::get(block->page.id().space());
-	const unsigned key_version = mach_read_from_4(
-		frame + FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION);
-	fil_space_crypt_t* crypt_data = space ? space->crypt_data : NULL;
-	const bool encrypted = crypt_data
-		&& crypt_data->type != CRYPT_SCHEME_UNENCRYPTED
-		&& (!crypt_data->is_default_encryption()
-		    || srv_encrypt_tables);
-
-	ut_ad(block->zip_size());
-	ut_a(block->page.id().space() != 0);
-
-	if (UNIV_UNLIKELY(check && !page_zip_verify_checksum(frame, size))) {
-
-		ib::error() << "Compressed page checksum mismatch for "
-			<< (space ? space->chain.start->name : "")
-			<< block->page.id() << ": stored: "
-			<< mach_read_from_4(frame + FIL_PAGE_SPACE_OR_CHKSUM)
-			<< ", crc32: "
-			<< page_zip_calc_checksum(
-				frame, size, SRV_CHECKSUM_ALGORITHM_CRC32)
-			<< " innodb: "
-			<< page_zip_calc_checksum(
-				frame, size, SRV_CHECKSUM_ALGORITHM_INNODB)
-			<< ", none: "
-			<< page_zip_calc_checksum(
-				frame, size, SRV_CHECKSUM_ALGORITHM_NONE)
-			<< " (algorithm: " << srv_checksum_algorithm << ")";
-		goto err_exit;
-	}
-
-	switch (fil_page_get_type(frame)) {
-	case FIL_PAGE_INDEX:
-	case FIL_PAGE_RTREE:
-		if (page_zip_decompress(&block->page.zip,
-					block->frame, TRUE)) {
-			if (space) {
-				space->release();
-			}
-			return(TRUE);
-		}
-
-		ib::error() << "Unable to decompress "
-			<< (space ? space->chain.start->name : "")
-			<< block->page.id();
-		goto err_exit;
-	case FIL_PAGE_TYPE_ALLOCATED:
-	case FIL_PAGE_INODE:
-	case FIL_PAGE_IBUF_BITMAP:
-	case FIL_PAGE_TYPE_FSP_HDR:
-	case FIL_PAGE_TYPE_XDES:
-	case FIL_PAGE_TYPE_ZBLOB:
-	case FIL_PAGE_TYPE_ZBLOB2:
-		/* Copy to uncompressed storage. */
-		memcpy(block->frame, frame, block->zip_size());
-		if (space) {
-			space->release();
-		}
-
-		return(TRUE);
-	}
-
-	ib::error() << "Unknown compressed page type "
-		<< fil_page_get_type(frame)
-		<< " in " << (space ? space->chain.start->name : "")
-		<< block->page.id();
+  const byte *frame= block->page.zip.data;
+  ulint size= page_zip_get_size(&block->page.zip);
+  /* The tablespace will not be found if this function is called
+  during IMPORT. */
+  fil_space_t *space= fil_space_t::get(block->page.id().space());
+  const unsigned key_version=
+      mach_read_from_4(frame + FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION);
+  fil_space_crypt_t *crypt_data= space ? space->crypt_data : NULL;
+  const bool encrypted=
+      crypt_data && crypt_data->type != CRYPT_SCHEME_UNENCRYPTED &&
+      (!crypt_data->is_default_encryption() || srv_encrypt_tables);
+
+  ut_ad(block->zip_size());
+  ut_a(block->page.id().space() != 0);
+
+  if (UNIV_UNLIKELY(check && !page_zip_verify_checksum(frame, size)))
+  {
+
+    ib::error()
+        << "Compressed page checksum mismatch for "
+        << (space ? space->chain.start->name : "") << block->page.id()
+        << ": stored: " << mach_read_from_4(frame + FIL_PAGE_SPACE_OR_CHKSUM)
+        << ", crc32: "
+        << page_zip_calc_checksum(frame, size, SRV_CHECKSUM_ALGORITHM_CRC32)
+        << " innodb: "
+        << page_zip_calc_checksum(frame, size, SRV_CHECKSUM_ALGORITHM_INNODB)
+        << ", none: "
+        << page_zip_calc_checksum(frame, size, SRV_CHECKSUM_ALGORITHM_NONE)
+        << " (algorithm: " << srv_checksum_algorithm << ")";
+    goto err_exit;
+  }
+
+  switch (fil_page_get_type(frame))
+  {
+  case FIL_PAGE_INDEX:
+  case FIL_PAGE_RTREE:
+    if (page_zip_decompress(&block->page.zip, block->frame, TRUE))
+    {
+      if (space)
+      {
+        space->release();
+      }
+      return (TRUE);
+    }
+
+    ib::error() << "Unable to decompress "
+                << (space ? space->chain.start->name : "") << block->page.id();
+    goto err_exit;
+  case FIL_PAGE_TYPE_ALLOCATED:
+  case FIL_PAGE_INODE:
+  case FIL_PAGE_IBUF_BITMAP:
+  case FIL_PAGE_TYPE_FSP_HDR:
+  case FIL_PAGE_TYPE_XDES:
+  case FIL_PAGE_TYPE_ZBLOB:
+  case FIL_PAGE_TYPE_ZBLOB2:
+    /* Copy to uncompressed storage. */
+    memcpy(block->frame, frame, block->zip_size());
+    if (space)
+    {
+      space->release();
+    }
+
+    return (TRUE);
+  }
+
+  ib::error() << "Unknown compressed page type " << fil_page_get_type(frame)
+              << " in " << (space ? space->chain.start->name : "")
+              << block->page.id();
 
 err_exit:
-	if (encrypted) {
-		ib::info() << "Row compressed page could be encrypted"
-			" with key_version " << key_version;
-	}
-
-	if (space) {
-		if (encrypted) {
-			dict_set_encrypted_by_space(space);
-		} else {
-			dict_set_corrupted_by_space(space);
-		}
-
-		space->release();
-	}
-
-	return(FALSE);
+  if (encrypted)
+  {
+    ib::info() << "Row compressed page could be encrypted"
+                  " with key_version "
+               << key_version;
+  }
+
+  if (space)
+  {
+    if (encrypted)
+    {
+      dict_set_encrypted_by_space(space);
+    }
+    else
+    {
+      dict_set_corrupted_by_space(space);
+    }
+
+    space->release();
+  }
+
+  return (FALSE);
 }
 
 /** Wait for the block to be read in.
 @param[in]	block	The block to check */
-static
-void
-buf_wait_for_read(
-	buf_block_t*	block)
+static void buf_wait_for_read(buf_block_t *block)
 {
-	/* Note:
-
-	We are using the block->lock to check for IO state.
-	We set the IO_READ state under the protection of the hash_lock.
-	This is safe because another thread can only
-	access the block (and check for IO state) after the block has been
-	added to the page hashtable. */
-
-	while (block->page.io_fix() == BUF_IO_READ) {
-		rw_lock_s_lock(&block->lock);
-		rw_lock_s_unlock(&block->lock);
-	}
+  /* Note:
+
+  We are using the block->lock to check for IO state.
+  We set the IO_READ state under the protection of the hash_lock.
+  This is safe because another thread can only
+  access the block (and check for IO state) after the block has been
+  added to the page hashtable. */
+
+  while (block->page.io_fix() == BUF_IO_READ)
+  {
+    rw_lock_s_lock(&block->lock);
+    rw_lock_s_unlock(&block->lock);
+  }
 }
 
 #ifdef BTR_CUR_HASH_ADAPT
@@ -2760,7 +2820,8 @@ same block must be prevented by exclusive page latch. */
 ATTRIBUTE_COLD
 static void buf_defer_drop_ahi(buf_block_t *block, mtr_memo_type_t fix_type)
 {
-  switch (fix_type) {
+  switch (fix_type)
+  {
   case MTR_MEMO_BUF_FIX:
     /* We do not drop the adaptive hash index, because safely doing
     so would require acquiring block->lock, and that is not safe
@@ -2800,10 +2861,8 @@ static void buf_defer_drop_ahi(buf_block_t *block, mtr_memo_type_t fix_type)
 @param[in]	file		file name
 @param[in]	line		line where called
 @return pointer to locked block */
-static buf_block_t* buf_page_mtr_lock(buf_block_t *block,
-                                      ulint rw_latch,
-                                      mtr_t* mtr,
-                                      const char *file,
+static buf_block_t *buf_page_mtr_lock(buf_block_t *block, ulint rw_latch,
+                                      mtr_t *mtr, const char *file,
                                       unsigned line)
 {
   mtr_memo_type_t fix_type;
@@ -2856,553 +2915,597 @@ while reading the page from file
 then it makes sure that it does merging of change buffer changes while
 reading the page from file.
 @return pointer to the block or NULL */
-buf_block_t*
-buf_page_get_low(
-	const page_id_t		page_id,
-	ulint			zip_size,
-	ulint			rw_latch,
-	buf_block_t*		guess,
-	ulint			mode,
-	const char*		file,
-	unsigned		line,
-	mtr_t*			mtr,
-	dberr_t*		err,
-	bool			allow_ibuf_merge)
+buf_block_t *buf_page_get_low(const page_id_t page_id, ulint zip_size,
+                              ulint rw_latch, buf_block_t *guess, ulint mode,
+                              const char *file, unsigned line, mtr_t *mtr,
+                              dberr_t *err, bool allow_ibuf_merge)
 {
-	buf_block_t*	block;
-	unsigned	access_time;
-	ulint		retries = 0;
-	const ulint	fold = page_id.fold();
-
-	ut_ad((mtr == NULL) == (mode == BUF_EVICT_IF_IN_POOL));
-	ut_ad(!mtr || mtr->is_active());
-	ut_ad((rw_latch == RW_S_LATCH)
-	      || (rw_latch == RW_X_LATCH)
-	      || (rw_latch == RW_SX_LATCH)
-	      || (rw_latch == RW_NO_LATCH));
-	ut_ad(!allow_ibuf_merge
-	      || mode == BUF_GET
-	      || mode == BUF_GET_POSSIBLY_FREED
-	      || mode == BUF_GET_IF_IN_POOL
-	      || mode == BUF_GET_IF_IN_POOL_OR_WATCH);
-
-	if (err) {
-		*err = DB_SUCCESS;
-	}
+  buf_block_t *block;
+  unsigned access_time;
+  ulint retries= 0;
+  const ulint fold= page_id.fold();
+
+  ut_ad((mtr == NULL) == (mode == BUF_EVICT_IF_IN_POOL));
+  ut_ad(!mtr || mtr->is_active());
+  ut_ad((rw_latch == RW_S_LATCH) || (rw_latch == RW_X_LATCH) ||
+        (rw_latch == RW_SX_LATCH) || (rw_latch == RW_NO_LATCH));
+  ut_ad(!allow_ibuf_merge || mode == BUF_GET ||
+        mode == BUF_GET_POSSIBLY_FREED || mode == BUF_GET_IF_IN_POOL ||
+        mode == BUF_GET_IF_IN_POOL_OR_WATCH);
+
+  if (err)
+  {
+    *err= DB_SUCCESS;
+  }
 
 #ifdef UNIV_DEBUG
-	switch (mode) {
-	case BUF_EVICT_IF_IN_POOL:
-		/* After DISCARD TABLESPACE, the tablespace would not exist,
-		but in IMPORT TABLESPACE, PageConverter::operator() must
-		replace any old pages, which were not evicted during DISCARD.
-		Skip the assertion on space_page_size. */
-		break;
-	case BUF_PEEK_IF_IN_POOL:
-	case BUF_GET_IF_IN_POOL:
-		/* The caller may pass a dummy page size,
-		because it does not really matter. */
-		break;
-	default:
-		ut_error;
-	case BUF_GET_POSSIBLY_FREED:
-		break;
-	case BUF_GET_NO_LATCH:
-		ut_ad(rw_latch == RW_NO_LATCH);
-		/* fall through */
-	case BUF_GET:
-	case BUF_GET_IF_IN_POOL_OR_WATCH:
-		fil_space_t* s = fil_space_get(page_id.space());
-		ut_ad(s);
-		ut_ad(s->zip_size() == zip_size);
-	}
+  switch (mode)
+  {
+  case BUF_EVICT_IF_IN_POOL:
+    /* After DISCARD TABLESPACE, the tablespace would not exist,
+    but in IMPORT TABLESPACE, PageConverter::operator() must
+    replace any old pages, which were not evicted during DISCARD.
+    Skip the assertion on space_page_size. */
+    break;
+  case BUF_PEEK_IF_IN_POOL:
+  case BUF_GET_IF_IN_POOL:
+    /* The caller may pass a dummy page size,
+    because it does not really matter. */
+    break;
+  default:
+    ut_error;
+  case BUF_GET_POSSIBLY_FREED:
+    break;
+  case BUF_GET_NO_LATCH:
+    ut_ad(rw_latch == RW_NO_LATCH);
+    /* fall through */
+  case BUF_GET:
+  case BUF_GET_IF_IN_POOL_OR_WATCH:
+    fil_space_t *s= fil_space_get(page_id.space());
+    ut_ad(s);
+    ut_ad(s->zip_size() == zip_size);
+  }
 #endif /* UNIV_DEBUG */
 
-	ut_ad(!mtr || !ibuf_inside(mtr)
-	      || ibuf_page_low(page_id, zip_size, FALSE, file, line, NULL));
+  ut_ad(!mtr || !ibuf_inside(mtr) ||
+        ibuf_page_low(page_id, zip_size, FALSE, file, line, NULL));
 
-	buf_pool.stat.n_page_gets++;
+  buf_pool.stat.n_page_gets++;
 loop:
-	buf_block_t* fix_block;
-	block = guess;
-
-	page_hash_latch* hash_lock = buf_pool.page_hash.lock<false>(fold);
-
-	if (block) {
-
-		/* If the guess is a compressed page descriptor that
-		has been allocated by buf_page_alloc_descriptor(),
-		it may have been freed by buf_relocate(). */
-
-		if (!buf_pool.is_uncompressed(block)
-		    || page_id != block->page.id()
-		    || block->page.state() != BUF_BLOCK_FILE_PAGE) {
-			/* Our guess was bogus or things have changed
-			since. */
-			guess = nullptr;
-			goto lookup;
-		} else {
-			ut_ad(!block->page.in_zip_hash);
-		}
-	} else {
-lookup:
-		block = reinterpret_cast<buf_block_t*>(
-			buf_pool.page_hash_get_low(page_id, fold));
-	}
-
-	if (!block || buf_pool.watch_is_sentinel(block->page)) {
-		hash_lock->read_unlock();
-		block = nullptr;
-	}
-
-	if (UNIV_UNLIKELY(!block)) {
-		/* Page not in buf_pool: needs to be read from file */
-		if (mode == BUF_GET_IF_IN_POOL_OR_WATCH) {
-			hash_lock = buf_pool.page_hash.lock<true>(fold);
-
-			if (buf_page_t *bpage= buf_pool.watch_set(
-				    page_id, &hash_lock)) {
-				/* We can release hash_lock after we
-				increment the fix count to make
-				sure that no state change takes place. */
-				bpage->fix();
-				hash_lock->write_unlock();
-				block = reinterpret_cast<buf_block_t*>(bpage);
-				fix_block = block;
-				goto got_block;
-			}
-
-			hash_lock->write_unlock();
-		}
-
-		switch (mode) {
-		case BUF_GET_IF_IN_POOL:
-		case BUF_GET_IF_IN_POOL_OR_WATCH:
-		case BUF_PEEK_IF_IN_POOL:
-		case BUF_EVICT_IF_IN_POOL:
-			return(NULL);
-		}
-
-		/* The call path is buf_read_page() ->
-		buf_read_page_low() (fil_space_t::io()) ->
-		buf_page_read_complete() ->
-		buf_decrypt_after_read(). Here fil_space_t* is used
-		and we decrypt -> buf_page_check_corrupt() where page
-		checksums are compared. Decryption, decompression as
-		well as error handling takes place at a lower level.
-		Here we only need to know whether the page really is
-		corrupted, or if an encrypted page with a valid
-		checksum cannot be decypted. */
-
-		dberr_t local_err = buf_read_page(page_id, zip_size);
-
-		if (local_err == DB_SUCCESS) {
-			buf_read_ahead_random(page_id, zip_size,
-					      ibuf_inside(mtr));
-
-			retries = 0;
-		} else if (mode == BUF_GET_POSSIBLY_FREED) {
-			if (err) {
-				*err = local_err;
-			}
-			return NULL;
-		} else if (retries < BUF_PAGE_READ_MAX_RETRIES) {
-			++retries;
-
-			DBUG_EXECUTE_IF(
-				"innodb_page_corruption_retries",
-				retries = BUF_PAGE_READ_MAX_RETRIES;
-			);
-		} else {
-			if (err) {
-				*err = local_err;
-			}
-
-			/* Pages whose encryption key is unavailable or used
-			key, encryption algorithm or encryption method is
-			incorrect are marked as encrypted in
-			buf_page_check_corrupt(). Unencrypted page could be
-			corrupted in a way where the key_id field is
-			nonzero. There is no checksum on field
-			FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION. */
-			if (local_err == DB_DECRYPTION_FAILED) {
-				return (NULL);
-			}
-
-			if (local_err == DB_PAGE_CORRUPTED
-			    && srv_force_recovery) {
-				return NULL;
-			}
-
-			/* Try to set table as corrupted instead of
-			asserting. */
-			if (page_id.space() == TRX_SYS_SPACE) {
-			} else if (page_id.space() == SRV_TMP_SPACE_ID) {
-			} else if (fil_space_t* space= fil_space_t::get(
-					   page_id.space())) {
-				bool set = dict_set_corrupted_by_space(space);
-				space->release();
-				if (set) {
-					return NULL;
-				}
-			}
-
-			if (local_err == DB_IO_ERROR) {
-				return NULL;
-			}
-
-			ib::fatal() << "Unable to read page " << page_id
-				<< " into the buffer pool after "
-				<< BUF_PAGE_READ_MAX_RETRIES
-				<< ". The most probable cause"
-				" of this error may be that the"
-				" table has been corrupted."
-				" See https://mariadb.com/kb/en/library/innodb-recovery-modes/";
-		}
+  buf_block_t *fix_block;
+  block= guess;
+
+  page_hash_latch *hash_lock= buf_pool.page_hash.lock<false>(fold);
+
+  if (block)
+  {
+
+    /* If the guess is a compressed page descriptor that
+    has been allocated by buf_page_alloc_descriptor(),
+    it may have been freed by buf_relocate(). */
+
+    if (!buf_pool.is_uncompressed(block) || page_id != block->page.id() ||
+        block->page.state() != BUF_BLOCK_FILE_PAGE)
+    {
+      /* Our guess was bogus or things have changed
+      since. */
+      guess= nullptr;
+      goto lookup;
+    }
+    else
+    {
+      ut_ad(!block->page.in_zip_hash);
+    }
+  }
+  else
+  {
+  lookup:
+    block= reinterpret_cast<buf_block_t *>(
+        buf_pool.page_hash_get_low(page_id, fold));
+  }
+
+  if (!block || buf_pool.watch_is_sentinel(block->page))
+  {
+    hash_lock->read_unlock();
+    block= nullptr;
+  }
+
+  if (UNIV_UNLIKELY(!block))
+  {
+    /* Page not in buf_pool: needs to be read from file */
+    if (mode == BUF_GET_IF_IN_POOL_OR_WATCH)
+    {
+      hash_lock= buf_pool.page_hash.lock<true>(fold);
+
+      if (buf_page_t *bpage= buf_pool.watch_set(page_id, &hash_lock))
+      {
+        /* We can release hash_lock after we
+        increment the fix count to make
+        sure that no state change takes place. */
+        bpage->fix();
+        hash_lock->write_unlock();
+        block= reinterpret_cast<buf_block_t *>(bpage);
+        fix_block= block;
+        goto got_block;
+      }
+
+      hash_lock->write_unlock();
+    }
+
+    switch (mode)
+    {
+    case BUF_GET_IF_IN_POOL:
+    case BUF_GET_IF_IN_POOL_OR_WATCH:
+    case BUF_PEEK_IF_IN_POOL:
+    case BUF_EVICT_IF_IN_POOL:
+      return (NULL);
+    }
+
+    /* The call path is buf_read_page() ->
+    buf_read_page_low() (fil_space_t::io()) ->
+    buf_page_read_complete() ->
+    buf_decrypt_after_read(). Here fil_space_t* is used
+    and we decrypt -> buf_page_check_corrupt() where page
+    checksums are compared. Decryption, decompression as
+    well as error handling takes place at a lower level.
+    Here we only need to know whether the page really is
+    corrupted, or if an encrypted page with a valid
+    checksum cannot be decypted. */
+
+    dberr_t local_err= buf_read_page(page_id, zip_size);
+
+    if (local_err == DB_SUCCESS)
+    {
+      buf_read_ahead_random(page_id, zip_size, ibuf_inside(mtr));
+
+      retries= 0;
+    }
+    else if (mode == BUF_GET_POSSIBLY_FREED)
+    {
+      if (err)
+      {
+        *err= local_err;
+      }
+      return NULL;
+    }
+    else if (retries < BUF_PAGE_READ_MAX_RETRIES)
+    {
+      ++retries;
+
+      DBUG_EXECUTE_IF("innodb_page_corruption_retries",
+                      retries= BUF_PAGE_READ_MAX_RETRIES;);
+    }
+    else
+    {
+      if (err)
+      {
+        *err= local_err;
+      }
+
+      /* Pages whose encryption key is unavailable or used
+      key, encryption algorithm or encryption method is
+      incorrect are marked as encrypted in
+      buf_page_check_corrupt(). Unencrypted page could be
+      corrupted in a way where the key_id field is
+      nonzero. There is no checksum on field
+      FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION. */
+      if (local_err == DB_DECRYPTION_FAILED)
+      {
+        return (NULL);
+      }
+
+      if (local_err == DB_PAGE_CORRUPTED && srv_force_recovery)
+      {
+        return NULL;
+      }
+
+      /* Try to set table as corrupted instead of
+      asserting. */
+      if (page_id.space() == TRX_SYS_SPACE)
+      {
+      }
+      else if (page_id.space() == SRV_TMP_SPACE_ID)
+      {
+      }
+      else if (fil_space_t *space= fil_space_t::get(page_id.space()))
+      {
+        bool set= dict_set_corrupted_by_space(space);
+        space->release();
+        if (set)
+        {
+          return NULL;
+        }
+      }
+
+      if (local_err == DB_IO_ERROR)
+      {
+        return NULL;
+      }
+
+      ib::fatal()
+          << "Unable to read page " << page_id
+          << " into the buffer pool after " << BUF_PAGE_READ_MAX_RETRIES
+          << ". The most probable cause"
+             " of this error may be that the"
+             " table has been corrupted."
+             " See https://mariadb.com/kb/en/library/innodb-recovery-modes/";
+    }
 
 #ifdef UNIV_DEBUG
-		if (!(++buf_dbg_counter % 5771)) buf_pool.validate();
+    if (!(++buf_dbg_counter % 5771))
+      buf_pool.validate();
 #endif /* UNIV_DEBUG */
-		goto loop;
-	} else {
-		fix_block = block;
-	}
+    goto loop;
+  }
+  else
+  {
+    fix_block= block;
+  }
 
-	fix_block->fix();
-	hash_lock->read_unlock();
+  fix_block->fix();
+  hash_lock->read_unlock();
 
 got_block:
-	switch (mode) {
-	default:
-		ut_ad(block->zip_size() == zip_size);
-		break;
-	case BUF_GET_IF_IN_POOL:
-	case BUF_PEEK_IF_IN_POOL:
-	case BUF_EVICT_IF_IN_POOL:
-		if (fix_block->page.io_fix() == BUF_IO_READ) {
-			/* The page is being read to buffer pool,
-			but we cannot wait around for the read to
-			complete. */
-			fix_block->unfix();
-			return(NULL);
-		}
-	}
-
-	switch (UNIV_EXPECT(fix_block->page.state(), BUF_BLOCK_FILE_PAGE)) {
-	case BUF_BLOCK_FILE_PAGE:
-		if (fsp_is_system_temporary(page_id.space())
-		    && block->page.io_fix() != BUF_IO_NONE) {
-			/* This suggests that the page is being flushed.
-			Avoid returning reference to this page.
-			Instead wait for the flush action to complete. */
-			fix_block->unfix();
-			os_thread_sleep(WAIT_FOR_WRITE);
-			goto loop;
-		}
-
-		if (UNIV_UNLIKELY(mode == BUF_EVICT_IF_IN_POOL)) {
-evict_from_pool:
-			ut_ad(!fix_block->page.oldest_modification());
-			mysql_mutex_lock(&buf_pool.mutex);
-			fix_block->unfix();
-
-			if (!buf_LRU_free_page(&fix_block->page, true)) {
-				ut_ad(0);
-			}
-
-			mysql_mutex_unlock(&buf_pool.mutex);
-			return(NULL);
-		}
-
-		break;
-	default:
-		ut_error;
-		break;
-
-	case BUF_BLOCK_ZIP_PAGE:
-		if (UNIV_UNLIKELY(mode == BUF_EVICT_IF_IN_POOL)) {
-			goto evict_from_pool;
-		}
-
-		if (mode == BUF_PEEK_IF_IN_POOL) {
-			/* This mode is only used for dropping an
-			adaptive hash index.  There cannot be an
-			adaptive hash index for a compressed-only
-			page, so do not bother decompressing the page. */
-			fix_block->unfix();
-
-			return(NULL);
-		}
-
-		buf_page_t* bpage = &block->page;
-
-		/* Note: We have already buffer fixed this block. */
-		if (bpage->buf_fix_count() > 1
-		    || bpage->io_fix() != BUF_IO_NONE) {
-
-			/* This condition often occurs when the buffer
-			is not buffer-fixed, but I/O-fixed by
-			buf_page_init_for_read(). */
-			fix_block->unfix();
-
-			/* The block is buffer-fixed or I/O-fixed.
-			Try again later. */
-			os_thread_sleep(WAIT_FOR_READ);
-
-			goto loop;
-		}
-
-		/* Buffer-fix the block so that it cannot be evicted
-		or relocated while we are attempting to allocate an
-		uncompressed page. */
-
-		block = buf_LRU_get_free_block(false);
-		buf_block_init_low(block);
-
-		mysql_mutex_lock(&buf_pool.mutex);
-		hash_lock = buf_pool.page_hash.lock_get(fold);
-
-		hash_lock->write_lock();
-
-		/* Buffer-fixing prevents the page_hash from changing. */
-		ut_ad(bpage == buf_pool.page_hash_get_low(page_id, fold));
-
-		fix_block->unfix(); /* hash_lock protects us after this */
-
-		if (bpage->buf_fix_count() || bpage->io_fix() != BUF_IO_NONE) {
-			/* The block was buffer-fixed or I/O-fixed while
-			buf_pool.mutex was not held by this thread.
-			Free the block that was allocated and retry.
-			This should be extremely unlikely, for example,
-			if buf_page_get_zip() was invoked. */
-
-			hash_lock->write_unlock();
-			buf_LRU_block_free_non_file_page(block);
-			mysql_mutex_unlock(&buf_pool.mutex);
-
-			/* Try again */
-			goto loop;
-		}
+  switch (mode)
+  {
+  default:
+    ut_ad(block->zip_size() == zip_size);
+    break;
+  case BUF_GET_IF_IN_POOL:
+  case BUF_PEEK_IF_IN_POOL:
+  case BUF_EVICT_IF_IN_POOL:
+    if (fix_block->page.io_fix() == BUF_IO_READ)
+    {
+      /* The page is being read to buffer pool,
+      but we cannot wait around for the read to
+      complete. */
+      fix_block->unfix();
+      return (NULL);
+    }
+  }
+
+  switch (UNIV_EXPECT(fix_block->page.state(), BUF_BLOCK_FILE_PAGE))
+  {
+  case BUF_BLOCK_FILE_PAGE:
+    if (fsp_is_system_temporary(page_id.space()) &&
+        block->page.io_fix() != BUF_IO_NONE)
+    {
+      /* This suggests that the page is being flushed.
+      Avoid returning reference to this page.
+      Instead wait for the flush action to complete. */
+      fix_block->unfix();
+      os_thread_sleep(WAIT_FOR_WRITE);
+      goto loop;
+    }
+
+    if (UNIV_UNLIKELY(mode == BUF_EVICT_IF_IN_POOL))
+    {
+    evict_from_pool:
+      ut_ad(!fix_block->page.oldest_modification());
+      mysql_mutex_lock(&buf_pool.mutex);
+      fix_block->unfix();
+
+      if (!buf_LRU_free_page(&fix_block->page, true))
+      {
+        ut_ad(0);
+      }
+
+      mysql_mutex_unlock(&buf_pool.mutex);
+      return (NULL);
+    }
+
+    break;
+  default:
+    ut_error;
+    break;
+
+  case BUF_BLOCK_ZIP_PAGE:
+    if (UNIV_UNLIKELY(mode == BUF_EVICT_IF_IN_POOL))
+    {
+      goto evict_from_pool;
+    }
+
+    if (mode == BUF_PEEK_IF_IN_POOL)
+    {
+      /* This mode is only used for dropping an
+      adaptive hash index.  There cannot be an
+      adaptive hash index for a compressed-only
+      page, so do not bother decompressing the page. */
+      fix_block->unfix();
+
+      return (NULL);
+    }
+
+    buf_page_t *bpage= &block->page;
+
+    /* Note: We have already buffer fixed this block. */
+    if (bpage->buf_fix_count() > 1 || bpage->io_fix() != BUF_IO_NONE)
+    {
+
+      /* This condition often occurs when the buffer
+      is not buffer-fixed, but I/O-fixed by
+      buf_page_init_for_read(). */
+      fix_block->unfix();
+
+      /* The block is buffer-fixed or I/O-fixed.
+      Try again later. */
+      os_thread_sleep(WAIT_FOR_READ);
+
+      goto loop;
+    }
+
+    /* Buffer-fix the block so that it cannot be evicted
+    or relocated while we are attempting to allocate an
+    uncompressed page. */
+
+    block= buf_LRU_get_free_block(false);
+    buf_block_init_low(block);
+
+    mysql_mutex_lock(&buf_pool.mutex);
+    hash_lock= buf_pool.page_hash.lock_get(fold);
+
+    hash_lock->write_lock();
+
+    /* Buffer-fixing prevents the page_hash from changing. */
+    ut_ad(bpage == buf_pool.page_hash_get_low(page_id, fold));
+
+    fix_block->unfix(); /* hash_lock protects us after this */
+
+    if (bpage->buf_fix_count() || bpage->io_fix() != BUF_IO_NONE)
+    {
+      /* The block was buffer-fixed or I/O-fixed while
+      buf_pool.mutex was not held by this thread.
+      Free the block that was allocated and retry.
+      This should be extremely unlikely, for example,
+      if buf_page_get_zip() was invoked. */
+
+      hash_lock->write_unlock();
+      buf_LRU_block_free_non_file_page(block);
+      mysql_mutex_unlock(&buf_pool.mutex);
+
+      /* Try again */
+      goto loop;
+    }
+
+    fix_block= block;
+
+    /* Move the compressed page from bpage to block,
+    and uncompress it. */
+
+    /* Note: this is the uncompressed block and it is not
+    accessible by other threads yet because it is not in
+    any list or hash table */
+    mysql_mutex_lock(&buf_pool.flush_list_mutex);
+    buf_relocate(bpage, &block->page);
+
+    /* Set after buf_relocate(). */
+    block->page.set_buf_fix_count(1);
 
-		fix_block = block;
+    buf_flush_relocate_on_flush_list(bpage, &block->page);
+    mysql_mutex_unlock(&buf_pool.flush_list_mutex);
 
-		/* Move the compressed page from bpage to block,
-		and uncompress it. */
+    /* Buffer-fix, I/O-fix, and X-latch the block
+    for the duration of the decompression.
+    Also add the block to the unzip_LRU list. */
+    block->page.set_state(BUF_BLOCK_FILE_PAGE);
 
-		/* Note: this is the uncompressed block and it is not
-		accessible by other threads yet because it is not in
-		any list or hash table */
-		mysql_mutex_lock(&buf_pool.flush_list_mutex);
-		buf_relocate(bpage, &block->page);
+    /* Insert at the front of unzip_LRU list */
+    buf_unzip_LRU_add_block(block, FALSE);
+
+    block->page.set_io_fix(BUF_IO_READ);
+    rw_lock_x_lock_inline(&block->lock, 0, file, line);
+
+    MEM_UNDEFINED(bpage, sizeof *bpage);
+
+    mysql_mutex_unlock(&buf_pool.mutex);
+    hash_lock->write_unlock();
+    buf_pool.n_pend_unzip++;
+
+    access_time= block->page.is_accessed();
+
+    if (!access_time && !recv_no_ibuf_operations &&
+        ibuf_page_exists(block->page.id(), zip_size))
+    {
+      block->page.ibuf_exist= true;
+    }
 
-		/* Set after buf_relocate(). */
-		block->page.set_buf_fix_count(1);
+    buf_page_free_descriptor(bpage);
 
-		buf_flush_relocate_on_flush_list(bpage, &block->page);
-		mysql_mutex_unlock(&buf_pool.flush_list_mutex);
+    /* Decompress the page while not holding
+    buf_pool.mutex. */
 
-		/* Buffer-fix, I/O-fix, and X-latch the block
-		for the duration of the decompression.
-		Also add the block to the unzip_LRU list. */
-		block->page.set_state(BUF_BLOCK_FILE_PAGE);
+    if (!buf_zip_decompress(block, false))
+    {
+      rw_lock_x_unlock(&fix_block->lock);
+      fix_block->page.io_unfix();
+      fix_block->unfix();
+      --buf_pool.n_pend_unzip;
 
-		/* Insert at the front of unzip_LRU list */
-		buf_unzip_LRU_add_block(block, FALSE);
+      if (err)
+      {
+        *err= DB_PAGE_CORRUPTED;
+      }
+      return NULL;
+    }
 
-		block->page.set_io_fix(BUF_IO_READ);
-		rw_lock_x_lock_inline(&block->lock, 0, file, line);
+    rw_lock_x_unlock(&block->lock);
+    fix_block->page.io_unfix();
+    --buf_pool.n_pend_unzip;
+    break;
+  }
 
-		MEM_UNDEFINED(bpage, sizeof *bpage);
+  ut_ad(block == fix_block);
+  ut_ad(fix_block->page.buf_fix_count());
 
-		mysql_mutex_unlock(&buf_pool.mutex);
-		hash_lock->write_unlock();
-		buf_pool.n_pend_unzip++;
+  ut_ad(fix_block->page.state() == BUF_BLOCK_FILE_PAGE);
 
-		access_time = block->page.is_accessed();
+#if defined UNIV_DEBUG || defined UNIV_IBUF_DEBUG
+re_evict:
+  if (mode != BUF_GET_IF_IN_POOL && mode != BUF_GET_IF_IN_POOL_OR_WATCH)
+  {
+  }
+  else if (!ibuf_debug)
+  {
+  }
+  else if (fil_space_t *space= fil_space_t::get(page_id.space()))
+  {
+    /* Try to evict the block from the buffer pool, to use the
+    insert buffer (change buffer) as much as possible. */
 
-		if (!access_time && !recv_no_ibuf_operations
-		    && ibuf_page_exists(block->page.id(), zip_size)) {
-			block->page.ibuf_exist = true;
-		}
+    mysql_mutex_lock(&buf_pool.mutex);
 
-		buf_page_free_descriptor(bpage);
+    fix_block->unfix();
 
-		/* Decompress the page while not holding
-		buf_pool.mutex. */
+    /* Blocks cannot be relocated or enter or exit the
+    buf_pool while we are holding the buf_pool.mutex. */
+    const bool evicted= buf_LRU_free_page(&fix_block->page, true);
+    space->release();
 
-		if (!buf_zip_decompress(block, false)) {
-			rw_lock_x_unlock(&fix_block->lock);
-			fix_block->page.io_unfix();
-			fix_block->unfix();
-			--buf_pool.n_pend_unzip;
+    if (evicted)
+    {
+      hash_lock= buf_pool.page_hash.lock_get(fold);
+      hash_lock->write_lock();
+      mysql_mutex_unlock(&buf_pool.mutex);
+      /* We may set the watch, as it would have
+      been set if the page were not in the
+      buffer pool in the first place. */
+      block= reinterpret_cast<buf_block_t *>(
+          mode == BUF_GET_IF_IN_POOL_OR_WATCH
+              ? buf_pool.watch_set(page_id, &hash_lock)
+              : buf_pool.page_hash_get_low(page_id, fold));
+      hash_lock->write_unlock();
 
-			if (err) {
-				*err = DB_PAGE_CORRUPTED;
-			}
-			return NULL;
-		}
+      if (block != NULL)
+      {
+        /* Either the page has been read in or
+        a watch was set on that in the window
+        where we released the buf_pool.mutex
+        and before we acquire the hash_lock
+        above. Try again. */
+        guess= block;
 
-		rw_lock_x_unlock(&block->lock);
-		fix_block->page.io_unfix();
-		--buf_pool.n_pend_unzip;
-		break;
-	}
+        goto loop;
+      }
 
-	ut_ad(block == fix_block);
-	ut_ad(fix_block->page.buf_fix_count());
+      return (NULL);
+    }
 
-	ut_ad(fix_block->page.state() == BUF_BLOCK_FILE_PAGE);
+    fix_block->fix();
+    mysql_mutex_unlock(&buf_pool.mutex);
+    buf_flush_list();
+    buf_flush_wait_batch_end_acquiring_mutex(false);
+    while (buf_flush_list_space(space))
+      ;
+    os_aio_wait_until_no_pending_writes();
+
+    if (fix_block->page.buf_fix_count() == 1 &&
+        !fix_block->page.oldest_modification())
+    {
+      goto re_evict;
+    }
 
-#if defined UNIV_DEBUG || defined UNIV_IBUF_DEBUG
-re_evict:
-	if (mode != BUF_GET_IF_IN_POOL
-	    && mode != BUF_GET_IF_IN_POOL_OR_WATCH) {
-	} else if (!ibuf_debug) {
-	} else if (fil_space_t* space = fil_space_t::get(page_id.space())) {
-		/* Try to evict the block from the buffer pool, to use the
-		insert buffer (change buffer) as much as possible. */
-
-		mysql_mutex_lock(&buf_pool.mutex);
-
-		fix_block->unfix();
-
-		/* Blocks cannot be relocated or enter or exit the
-		buf_pool while we are holding the buf_pool.mutex. */
-		const bool evicted = buf_LRU_free_page(&fix_block->page, true);
-		space->release();
-
-		if (evicted) {
-			hash_lock = buf_pool.page_hash.lock_get(fold);
-			hash_lock->write_lock();
-			mysql_mutex_unlock(&buf_pool.mutex);
-			/* We may set the watch, as it would have
-			been set if the page were not in the
-			buffer pool in the first place. */
-			block= reinterpret_cast<buf_block_t*>(
-				mode == BUF_GET_IF_IN_POOL_OR_WATCH
-				? buf_pool.watch_set(page_id, &hash_lock)
-				: buf_pool.page_hash_get_low(page_id, fold));
-			hash_lock->write_unlock();
-
-			if (block != NULL) {
-				/* Either the page has been read in or
-				a watch was set on that in the window
-				where we released the buf_pool.mutex
-				and before we acquire the hash_lock
-				above. Try again. */
-				guess = block;
-
-				goto loop;
-			}
-
-			return(NULL);
-		}
-
-		fix_block->fix();
-		mysql_mutex_unlock(&buf_pool.mutex);
-		buf_flush_list();
-		buf_flush_wait_batch_end_acquiring_mutex(false);
-		while (buf_flush_list_space(space));
-		os_aio_wait_until_no_pending_writes();
-
-		if (fix_block->page.buf_fix_count() == 1
-		    && !fix_block->page.oldest_modification()) {
-			goto re_evict;
-		}
-
-		/* Failed to evict the page; change it directly */
-	}
+    /* Failed to evict the page; change it directly */
+  }
 #endif /* UNIV_DEBUG || UNIV_IBUF_DEBUG */
 
-	ut_ad(fix_block->page.buf_fix_count());
+  ut_ad(fix_block->page.buf_fix_count());
 
 #ifdef UNIV_DEBUG
-	/* We have already buffer fixed the page, and we are committed to
-	returning this page to the caller. Register for debugging.
-	Avoid debug latching if page/block belongs to system temporary
-	tablespace (Not much needed for table with single threaded access.). */
-	if (!fsp_is_system_temporary(page_id.space())) {
-		ibool   ret;
-		ret = rw_lock_s_lock_nowait(
-			fix_block->debug_latch, file, line);
-		ut_a(ret);
-	}
+  /* We have already buffer fixed the page, and we are committed to
+  returning this page to the caller. Register for debugging.
+  Avoid debug latching if page/block belongs to system temporary
+  tablespace (Not much needed for table with single threaded access.). */
+  if (!fsp_is_system_temporary(page_id.space()))
+  {
+    ibool ret;
+    ret= rw_lock_s_lock_nowait(fix_block->debug_latch, file, line);
+    ut_a(ret);
+  }
 #endif /* UNIV_DEBUG */
 
-	/* While tablespace is reinited the indexes are already freed but the
-	blocks related to it still resides in buffer pool. Trying to remove
-	such blocks from buffer pool would invoke removal of AHI entries
-	associated with these blocks. Logic to remove AHI entry will try to
-	load the block but block is already in free state. Handle the said case
-	with mode = BUF_PEEK_IF_IN_POOL that is invoked from
-	"btr_search_drop_page_hash_when_freed". */
-	ut_ad(mode == BUF_GET_POSSIBLY_FREED
-	      || mode == BUF_PEEK_IF_IN_POOL
-	      || fix_block->page.status != buf_page_t::FREED);
+  /* While tablespace is reinited the indexes are already freed but the
+  blocks related to it still resides in buffer pool. Trying to remove
+  such blocks from buffer pool would invoke removal of AHI entries
+  associated with these blocks. Logic to remove AHI entry will try to
+  load the block but block is already in free state. Handle the said case
+  with mode = BUF_PEEK_IF_IN_POOL that is invoked from
+  "btr_search_drop_page_hash_when_freed". */
+  ut_ad(mode == BUF_GET_POSSIBLY_FREED || mode == BUF_PEEK_IF_IN_POOL ||
+        fix_block->page.status != buf_page_t::FREED);
 
-	const bool not_first_access = fix_block->page.set_accessed();
+  const bool not_first_access= fix_block->page.set_accessed();
 
-	if (mode != BUF_PEEK_IF_IN_POOL) {
-		buf_page_make_young_if_needed(&fix_block->page);
-	}
+  if (mode != BUF_PEEK_IF_IN_POOL)
+  {
+    buf_page_make_young_if_needed(&fix_block->page);
+  }
 
 #ifdef UNIV_DEBUG
-	if (!(++buf_dbg_counter % 5771)) buf_pool.validate();
+  if (!(++buf_dbg_counter % 5771))
+    buf_pool.validate();
 #endif /* UNIV_DEBUG */
-	ut_ad(fix_block->page.state() == BUF_BLOCK_FILE_PAGE);
+  ut_ad(fix_block->page.state() == BUF_BLOCK_FILE_PAGE);
 
-	/* We have to wait here because the IO_READ state was set
-	under the protection of the hash_lock and not block->lock. */
-	buf_wait_for_read(fix_block);
+  /* We have to wait here because the IO_READ state was set
+  under the protection of the hash_lock and not block->lock. */
+  buf_wait_for_read(fix_block);
 
-	if (fix_block->page.id() != page_id) {
-		fix_block->unfix();
+  if (fix_block->page.id() != page_id)
+  {
+    fix_block->unfix();
 
 #ifdef UNIV_DEBUG
-		if (!fsp_is_system_temporary(page_id.space())) {
-			rw_lock_s_unlock(fix_block->debug_latch);
-		}
+    if (!fsp_is_system_temporary(page_id.space()))
+    {
+      rw_lock_s_unlock(fix_block->debug_latch);
+    }
 #endif /* UNIV_DEBUG */
 
-		if (err) {
-			*err = DB_PAGE_CORRUPTED;
-		}
-
-		return NULL;
-	}
-
-	if (fix_block->page.status != buf_page_t::FREED
-	    && allow_ibuf_merge
-	    && fil_page_get_type(fix_block->frame) == FIL_PAGE_INDEX
-	    && page_is_leaf(fix_block->frame)) {
-		rw_lock_x_lock_inline(&fix_block->lock, 0, file, line);
-
-		if (fix_block->page.ibuf_exist) {
-			fix_block->page.ibuf_exist = false;
-			ibuf_merge_or_delete_for_page(fix_block, page_id,
-						      zip_size);
-		}
-
-		if (rw_latch == RW_X_LATCH) {
-			mtr->memo_push(fix_block, MTR_MEMO_PAGE_X_FIX);
-		} else {
-			rw_lock_x_unlock(&fix_block->lock);
-			goto get_latch;
-		}
-	} else {
-get_latch:
-		fix_block = buf_page_mtr_lock(fix_block, rw_latch, mtr,
-					      file, line);
-	}
-
-	if (!not_first_access && mode != BUF_PEEK_IF_IN_POOL) {
-		/* In the case of a first access, try to apply linear
-		read-ahead */
-
-		buf_read_ahead_linear(page_id, zip_size, ibuf_inside(mtr));
-	}
-
-	return(fix_block);
+    if (err)
+    {
+      *err= DB_PAGE_CORRUPTED;
+    }
+
+    return NULL;
+  }
+
+  if (fix_block->page.status != buf_page_t::FREED && allow_ibuf_merge &&
+      fil_page_get_type(fix_block->frame) == FIL_PAGE_INDEX &&
+      page_is_leaf(fix_block->frame))
+  {
+    rw_lock_x_lock_inline(&fix_block->lock, 0, file, line);
+
+    if (fix_block->page.ibuf_exist)
+    {
+      fix_block->page.ibuf_exist= false;
+      ibuf_merge_or_delete_for_page(fix_block, page_id, zip_size);
+    }
+
+    if (rw_latch == RW_X_LATCH)
+    {
+      mtr->memo_push(fix_block, MTR_MEMO_PAGE_X_FIX);
+    }
+    else
+    {
+      rw_lock_x_unlock(&fix_block->lock);
+      goto get_latch;
+    }
+  }
+  else
+  {
+  get_latch:
+    fix_block= buf_page_mtr_lock(fix_block, rw_latch, mtr, file, line);
+  }
+
+  if (!not_first_access && mode != BUF_PEEK_IF_IN_POOL)
+  {
+    /* In the case of a first access, try to apply linear
+    read-ahead */
+
+    buf_read_ahead_linear(page_id, zip_size, ibuf_inside(mtr));
+  }
+
+  return (fix_block);
 }
 
 /** Get access to a database page. Buffered redo log may be applied.
@@ -3419,18 +3522,10 @@ BUF_PEEK_IF_IN_POOL, BUF_GET_NO_LATCH, or BUF_GET_IF_IN_POOL_OR_WATCH
 @param[in]	allow_ibuf_merge	Allow change buffer merge while
 reading the pages from file.
 @return pointer to the block or NULL */
-buf_block_t*
-buf_page_get_gen(
-	const page_id_t		page_id,
-	ulint			zip_size,
-	ulint			rw_latch,
-	buf_block_t*		guess,
-	ulint			mode,
-	const char*		file,
-	unsigned		line,
-	mtr_t*			mtr,
-	dberr_t*		err,
-	bool			allow_ibuf_merge)
+buf_block_t *buf_page_get_gen(const page_id_t page_id, ulint zip_size,
+                              ulint rw_latch, buf_block_t *guess, ulint mode,
+                              const char *file, unsigned line, mtr_t *mtr,
+                              dberr_t *err, bool allow_ibuf_merge)
 {
   if (buf_block_t *block= recv_sys.recover(page_id))
   {
@@ -3438,12 +3533,12 @@ buf_page_get_gen(
     ut_ad(rw_lock_s_lock_nowait(block->debug_latch, file, line));
     if (err)
       *err= DB_SUCCESS;
-    const bool must_merge= allow_ibuf_merge &&
-      ibuf_page_exists(page_id, block->zip_size());
+    const bool must_merge=
+        allow_ibuf_merge && ibuf_page_exists(page_id, block->zip_size());
     if (block->page.status == buf_page_t::FREED)
       ut_ad(mode == BUF_GET_POSSIBLY_FREED || mode == BUF_PEEK_IF_IN_POOL);
     else if (must_merge && fil_page_get_type(block->frame) == FIL_PAGE_INDEX &&
-	     page_is_leaf(block->frame))
+             page_is_leaf(block->frame))
     {
       rw_lock_x_lock_inline(&block->lock, 0, file, line);
       block->page.ibuf_exist= false;
@@ -3452,7 +3547,7 @@ buf_page_get_gen(
       if (rw_latch == RW_X_LATCH)
       {
         mtr->memo_push(block, MTR_MEMO_PAGE_X_FIX);
-	return block;
+        return block;
       }
       rw_lock_x_unlock(&block->lock);
     }
@@ -3460,100 +3555,109 @@ buf_page_get_gen(
     return block;
   }
 
-  return buf_page_get_low(page_id, zip_size, rw_latch,
-                          guess, mode, file, line, mtr, err, allow_ibuf_merge);
+  return buf_page_get_low(page_id, zip_size, rw_latch, guess, mode, file, line,
+                          mtr, err, allow_ibuf_merge);
 }
 
-/********************************************************************//**
-This is the general function used to get optimistic access to a database
-page.
-@return TRUE if success */
-ibool
-buf_page_optimistic_get(
-/*====================*/
-	ulint		rw_latch,/*!< in: RW_S_LATCH, RW_X_LATCH */
-	buf_block_t*	block,	/*!< in: guessed buffer block */
-	ib_uint64_t	modify_clock,/*!< in: modify clock value */
-	const char*	file,	/*!< in: file name */
-	unsigned	line,	/*!< in: line where called */
-	mtr_t*		mtr)	/*!< in: mini-transaction */
+/********************************************************************/ /**
+ This is the general function used to get optimistic access to a database
+ page.
+ @return TRUE if success */
+ibool buf_page_optimistic_get(
+    /*====================*/
+    ulint rw_latch,           /*!< in: RW_S_LATCH, RW_X_LATCH */
+    buf_block_t *block,       /*!< in: guessed buffer block */
+    ib_uint64_t modify_clock, /*!< in: modify clock value */
+    const char *file,         /*!< in: file name */
+    unsigned line,            /*!< in: line where called */
+    mtr_t *mtr)               /*!< in: mini-transaction */
 {
-	ibool		success;
+  ibool success;
 
-	ut_ad(block);
-	ut_ad(mtr);
-	ut_ad(mtr->is_active());
-	ut_ad(rw_latch == RW_S_LATCH || rw_latch == RW_X_LATCH);
+  ut_ad(block);
+  ut_ad(mtr);
+  ut_ad(mtr->is_active());
+  ut_ad(rw_latch == RW_S_LATCH || rw_latch == RW_X_LATCH);
 
-	if (UNIV_UNLIKELY(block->page.state() != BUF_BLOCK_FILE_PAGE
-			  || block->page.io_fix() != BUF_IO_NONE)) {
-		return FALSE;
-	}
+  if (UNIV_UNLIKELY(block->page.state() != BUF_BLOCK_FILE_PAGE ||
+                    block->page.io_fix() != BUF_IO_NONE))
+  {
+    return FALSE;
+  }
 
-	const page_id_t id(block->page.id());
+  const page_id_t id(block->page.id());
 
-	page_hash_latch *hash_lock = buf_pool.hash_lock_get(id);
-	hash_lock->read_lock();
+  page_hash_latch *hash_lock= buf_pool.hash_lock_get(id);
+  hash_lock->read_lock();
 
-	if (UNIV_UNLIKELY(id != block->page.id()
-			  || block->page.state() != BUF_BLOCK_FILE_PAGE
-			  || block->page.io_fix() != BUF_IO_NONE)) {
-		hash_lock->read_unlock();
-		return(FALSE);
-	}
+  if (UNIV_UNLIKELY(id != block->page.id() ||
+                    block->page.state() != BUF_BLOCK_FILE_PAGE ||
+                    block->page.io_fix() != BUF_IO_NONE))
+  {
+    hash_lock->read_unlock();
+    return (FALSE);
+  }
 
-	buf_block_buf_fix_inc(block, file, line);
-	hash_lock->read_unlock();
+  buf_block_buf_fix_inc(block, file, line);
+  hash_lock->read_unlock();
 
-	block->page.set_accessed();
+  block->page.set_accessed();
 
-	buf_page_make_young_if_needed(&block->page);
+  buf_page_make_young_if_needed(&block->page);
 
-	ut_ad(!ibuf_inside(mtr) || ibuf_page(id, block->zip_size(), NULL));
+  ut_ad(!ibuf_inside(mtr) || ibuf_page(id, block->zip_size(), NULL));
 
-	mtr_memo_type_t	fix_type;
+  mtr_memo_type_t fix_type;
 
-	if (rw_latch == RW_S_LATCH) {
-		fix_type = MTR_MEMO_PAGE_S_FIX;
-		success = rw_lock_s_lock_nowait(&block->lock, file, line);
-	} else {
-		fix_type = MTR_MEMO_PAGE_X_FIX;
-		success = rw_lock_x_lock_func_nowait_inline(
-			&block->lock, file, line);
-	}
+  if (rw_latch == RW_S_LATCH)
+  {
+    fix_type= MTR_MEMO_PAGE_S_FIX;
+    success= rw_lock_s_lock_nowait(&block->lock, file, line);
+  }
+  else
+  {
+    fix_type= MTR_MEMO_PAGE_X_FIX;
+    success= rw_lock_x_lock_func_nowait_inline(&block->lock, file, line);
+  }
 
-	ut_ad(id == block->page.id());
+  ut_ad(id == block->page.id());
 
-	if (!success) {
-		buf_block_buf_fix_dec(block);
-		return(FALSE);
-	}
+  if (!success)
+  {
+    buf_block_buf_fix_dec(block);
+    return (FALSE);
+  }
 
-	if (modify_clock != block->modify_clock) {
+  if (modify_clock != block->modify_clock)
+  {
 
-		buf_block_dbg_add_level(block, SYNC_NO_ORDER_CHECK);
+    buf_block_dbg_add_level(block, SYNC_NO_ORDER_CHECK);
 
-		if (rw_latch == RW_S_LATCH) {
-			rw_lock_s_unlock(&block->lock);
-		} else {
-			rw_lock_x_unlock(&block->lock);
-		}
+    if (rw_latch == RW_S_LATCH)
+    {
+      rw_lock_s_unlock(&block->lock);
+    }
+    else
+    {
+      rw_lock_x_unlock(&block->lock);
+    }
 
-		buf_block_buf_fix_dec(block);
-		return(FALSE);
-	}
+    buf_block_buf_fix_dec(block);
+    return (FALSE);
+  }
 
-	mtr_memo_push(mtr, block, fix_type);
+  mtr_memo_push(mtr, block, fix_type);
 
 #ifdef UNIV_DEBUG
-	if (!(++buf_dbg_counter % 5771)) buf_pool.validate();
+  if (!(++buf_dbg_counter % 5771))
+    buf_pool.validate();
 #endif /* UNIV_DEBUG */
-	ut_ad(block->page.buf_fix_count());
-	ut_ad(block->page.state() == BUF_BLOCK_FILE_PAGE);
+  ut_ad(block->page.buf_fix_count());
+  ut_ad(block->page.state() == BUF_BLOCK_FILE_PAGE);
 
-	buf_pool.stat.n_page_gets++;
+  buf_pool.stat.n_page_gets++;
 
-	return(TRUE);
+  return (TRUE);
 }
 
 /** Given a tablespace id and page number tries to get that page. If the
@@ -3564,20 +3668,15 @@ Suitable for using when holding the lock_sys_t::mutex.
 @param[in]	line	line where called
 @param[in]	mtr	mini-transaction
 @return pointer to a page or NULL */
-buf_block_t*
-buf_page_try_get_func(
-	const page_id_t		page_id,
-	const char*		file,
-	unsigned		line,
-	mtr_t*			mtr)
+buf_block_t *buf_page_try_get_func(const page_id_t page_id, const char *file,
+                                   unsigned line, mtr_t *mtr)
 {
   ut_ad(mtr);
   ut_ad(mtr->is_active());
 
   page_hash_latch *hash_lock;
-  buf_page_t *bpage= buf_pool.page_hash_get_locked<false>(page_id,
-                                                          page_id.fold(),
-                                                          &hash_lock);
+  buf_page_t *bpage= buf_pool.page_hash_get_locked<false>(
+      page_id, page_id.fold(), &hash_lock);
   if (!bpage)
     return nullptr;
   if (bpage->state() != BUF_BLOCK_FILE_PAGE)
@@ -3586,7 +3685,7 @@ buf_page_try_get_func(
     return nullptr;
   }
 
-  buf_block_t *block= reinterpret_cast<buf_block_t*>(bpage);
+  buf_block_t *block= reinterpret_cast<buf_block_t *>(bpage);
   buf_block_buf_fix_inc(block, file, line);
   hash_lock->read_unlock();
 
@@ -3606,7 +3705,8 @@ buf_page_try_get_func(
   mtr_memo_push(mtr, block, fix_type);
 
 #ifdef UNIV_DEBUG
-  if (!(++buf_dbg_counter % 5771)) buf_pool.validate();
+  if (!(++buf_dbg_counter % 5771))
+    buf_pool.validate();
 #endif /* UNIV_DEBUG */
   ut_ad(bpage->buf_fix_count());
   ut_ad(bpage->state() == BUF_BLOCK_FILE_PAGE);
@@ -3640,9 +3740,9 @@ FILE_PAGE (the other is buf_page_get_gen).
 @param[in,out]	mtr		mini-transaction
 @param[in,out]	free_block	pre-allocated buffer block
 @return pointer to the block, page bufferfixed */
-buf_block_t*
-buf_page_create(fil_space_t *space, uint32_t offset,
-                ulint zip_size, mtr_t *mtr, buf_block_t *free_block)
+buf_block_t *buf_page_create(fil_space_t *space, uint32_t offset,
+                             ulint zip_size, mtr_t *mtr,
+                             buf_block_t *free_block)
 {
   page_id_t page_id(space->id, offset);
   ut_ad(mtr->is_active());
@@ -3655,8 +3755,8 @@ buf_page_create(fil_space_t *space, uint32_t offset,
   mysql_mutex_lock(&buf_pool.mutex);
 
 loop:
-  buf_block_t *block= reinterpret_cast<buf_block_t*>
-    (buf_pool.page_hash_get_low(page_id, fold));
+  buf_block_t *block= reinterpret_cast<buf_block_t *>(
+      buf_pool.page_hash_get_low(page_id, fold));
 
   if (block && block->page.in_file() &&
       !buf_pool.watch_is_sentinel(block->page))
@@ -3664,7 +3764,8 @@ buf_page_create(fil_space_t *space, uint32_t offset,
 #ifdef BTR_CUR_HASH_ADAPT
     const dict_index_t *drop_hash_entry= nullptr;
 #endif
-    switch (UNIV_EXPECT(block->page.state(), BUF_BLOCK_FILE_PAGE)) {
+    switch (UNIV_EXPECT(block->page.state(), BUF_BLOCK_FILE_PAGE))
+    {
     default:
       ut_ad(0);
       break;
@@ -3743,8 +3844,8 @@ buf_page_create(fil_space_t *space, uint32_t offset,
 
   /* If we get here, the page was not in buf_pool: init it there */
 
-  DBUG_PRINT("ib_buf", ("create page %u:%u",
-                        page_id.space(), page_id.page_no()));
+  DBUG_PRINT("ib_buf",
+             ("create page %u:%u", page_id.space(), page_id.page_no()));
 
   block= free_block;
 
@@ -3796,8 +3897,7 @@ buf_page_create(fil_space_t *space, uint32_t offset,
   /* Delete possible entries for the page from the insert buffer:
   such can exist if the page belonged to an index which was dropped */
   if (page_id < page_id_t{SRV_SPACE_ID_UPPER_BOUND, 0} &&
-      !srv_is_undo_tablespace(page_id.space()) &&
-      !recv_recovery_is_on())
+      !srv_is_undo_tablespace(page_id.space()) && !recv_recovery_is_on())
     ibuf_merge_or_delete_for_page(nullptr, page_id, zip_size);
 
   static_assert(FIL_PAGE_PREV + 4 == FIL_PAGE_NEXT, "adjacent");
@@ -3814,7 +3914,8 @@ buf_page_create(fil_space_t *space, uint32_t offset,
   memset_aligned<8>(block->frame + FIL_PAGE_LSN, 0, 8);
 
 #ifdef UNIV_DEBUG
-  if (!(++buf_dbg_counter % 5771)) buf_pool.validate();
+  if (!(++buf_dbg_counter % 5771))
+    buf_pool.validate();
 #endif /* UNIV_DEBUG */
   return block;
 }
@@ -3823,116 +3924,119 @@ buf_page_create(fil_space_t *space, uint32_t offset,
 counter value in MONITOR_MODULE_BUF_PAGE.
 @param bpage   buffer page whose read or write was completed
 @param io_type BUF_IO_READ or BUF_IO_WRITE */
-ATTRIBUTE_COLD __attribute__((nonnull))
-void buf_page_monitor(const buf_page_t *bpage, buf_io_fix io_type)
+ATTRIBUTE_COLD __attribute__((nonnull)) void
+buf_page_monitor(const buf_page_t *bpage, buf_io_fix io_type)
 {
-	const byte*	frame;
-	monitor_id_t	counter;
-
-	ut_ad(io_type == BUF_IO_READ || io_type == BUF_IO_WRITE);
-
-	frame = bpage->zip.data
-		? bpage->zip.data
-		: ((buf_block_t*) bpage)->frame;
-
-	switch (fil_page_get_type(frame)) {
-		ulint	level;
-	case FIL_PAGE_TYPE_INSTANT:
-	case FIL_PAGE_INDEX:
-	case FIL_PAGE_RTREE:
-		level = btr_page_get_level(frame);
-
-		/* Check if it is an index page for insert buffer */
-		if (fil_page_get_type(frame) == FIL_PAGE_INDEX
-		    && btr_page_get_index_id(frame)
-		    == (index_id_t)(DICT_IBUF_ID_MIN + IBUF_SPACE_ID)) {
-			if (level == 0) {
-				counter = MONITOR_RW_COUNTER(
-					io_type, MONITOR_INDEX_IBUF_LEAF_PAGE);
-			} else {
-				counter = MONITOR_RW_COUNTER(
-					io_type,
-					MONITOR_INDEX_IBUF_NON_LEAF_PAGE);
-			}
-		} else {
-			if (level == 0) {
-				counter = MONITOR_RW_COUNTER(
-					io_type, MONITOR_INDEX_LEAF_PAGE);
-			} else {
-				counter = MONITOR_RW_COUNTER(
-					io_type, MONITOR_INDEX_NON_LEAF_PAGE);
-			}
-		}
-		break;
-
-	case FIL_PAGE_UNDO_LOG:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_UNDO_LOG_PAGE);
-		break;
-
-	case FIL_PAGE_INODE:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_INODE_PAGE);
-		break;
-
-	case FIL_PAGE_IBUF_FREE_LIST:
-		counter = MONITOR_RW_COUNTER(io_type,
-					     MONITOR_IBUF_FREELIST_PAGE);
-		break;
-
-	case FIL_PAGE_IBUF_BITMAP:
-		counter = MONITOR_RW_COUNTER(io_type,
-					     MONITOR_IBUF_BITMAP_PAGE);
-		break;
-
-	case FIL_PAGE_TYPE_SYS:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_SYSTEM_PAGE);
-		break;
-
-	case FIL_PAGE_TYPE_TRX_SYS:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_TRX_SYSTEM_PAGE);
-		break;
-
-	case FIL_PAGE_TYPE_FSP_HDR:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_FSP_HDR_PAGE);
-		break;
-
-	case FIL_PAGE_TYPE_XDES:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_XDES_PAGE);
-		break;
-
-	case FIL_PAGE_TYPE_BLOB:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_BLOB_PAGE);
-		break;
-
-	case FIL_PAGE_TYPE_ZBLOB:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_ZBLOB_PAGE);
-		break;
-
-	case FIL_PAGE_TYPE_ZBLOB2:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_ZBLOB2_PAGE);
-		break;
-
-	default:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_OTHER_PAGE);
-	}
-
-	MONITOR_INC_NOCHECK(counter);
+  const byte *frame;
+  monitor_id_t counter;
+
+  ut_ad(io_type == BUF_IO_READ || io_type == BUF_IO_WRITE);
+
+  frame= bpage->zip.data ? bpage->zip.data : ((buf_block_t *) bpage)->frame;
+
+  switch (fil_page_get_type(frame))
+  {
+    ulint level;
+  case FIL_PAGE_TYPE_INSTANT:
+  case FIL_PAGE_INDEX:
+  case FIL_PAGE_RTREE:
+    level= btr_page_get_level(frame);
+
+    /* Check if it is an index page for insert buffer */
+    if (fil_page_get_type(frame) == FIL_PAGE_INDEX &&
+        btr_page_get_index_id(frame) ==
+            (index_id_t) (DICT_IBUF_ID_MIN + IBUF_SPACE_ID))
+    {
+      if (level == 0)
+      {
+        counter= MONITOR_RW_COUNTER(io_type, MONITOR_INDEX_IBUF_LEAF_PAGE);
+      }
+      else
+      {
+        counter= MONITOR_RW_COUNTER(io_type, MONITOR_INDEX_IBUF_NON_LEAF_PAGE);
+      }
+    }
+    else
+    {
+      if (level == 0)
+      {
+        counter= MONITOR_RW_COUNTER(io_type, MONITOR_INDEX_LEAF_PAGE);
+      }
+      else
+      {
+        counter= MONITOR_RW_COUNTER(io_type, MONITOR_INDEX_NON_LEAF_PAGE);
+      }
+    }
+    break;
+
+  case FIL_PAGE_UNDO_LOG:
+    counter= MONITOR_RW_COUNTER(io_type, MONITOR_UNDO_LOG_PAGE);
+    break;
+
+  case FIL_PAGE_INODE:
+    counter= MONITOR_RW_COUNTER(io_type, MONITOR_INODE_PAGE);
+    break;
+
+  case FIL_PAGE_IBUF_FREE_LIST:
+    counter= MONITOR_RW_COUNTER(io_type, MONITOR_IBUF_FREELIST_PAGE);
+    break;
+
+  case FIL_PAGE_IBUF_BITMAP:
+    counter= MONITOR_RW_COUNTER(io_type, MONITOR_IBUF_BITMAP_PAGE);
+    break;
+
+  case FIL_PAGE_TYPE_SYS:
+    counter= MONITOR_RW_COUNTER(io_type, MONITOR_SYSTEM_PAGE);
+    break;
+
+  case FIL_PAGE_TYPE_TRX_SYS:
+    counter= MONITOR_RW_COUNTER(io_type, MONITOR_TRX_SYSTEM_PAGE);
+    break;
+
+  case FIL_PAGE_TYPE_FSP_HDR:
+    counter= MONITOR_RW_COUNTER(io_type, MONITOR_FSP_HDR_PAGE);
+    break;
+
+  case FIL_PAGE_TYPE_XDES:
+    counter= MONITOR_RW_COUNTER(io_type, MONITOR_XDES_PAGE);
+    break;
+
+  case FIL_PAGE_TYPE_BLOB:
+    counter= MONITOR_RW_COUNTER(io_type, MONITOR_BLOB_PAGE);
+    break;
+
+  case FIL_PAGE_TYPE_ZBLOB:
+    counter= MONITOR_RW_COUNTER(io_type, MONITOR_ZBLOB_PAGE);
+    break;
+
+  case FIL_PAGE_TYPE_ZBLOB2:
+    counter= MONITOR_RW_COUNTER(io_type, MONITOR_ZBLOB2_PAGE);
+    break;
+
+  default:
+    counter= MONITOR_RW_COUNTER(io_type, MONITOR_OTHER_PAGE);
+  }
+
+  MONITOR_INC_NOCHECK(counter);
 }
 
 /** Mark a table corrupted.
 @param[in]	bpage	corrupted page
 @param[in]	space	tablespace of the corrupted page */
 ATTRIBUTE_COLD
-static void buf_mark_space_corrupt(buf_page_t* bpage, const fil_space_t& space)
+static void buf_mark_space_corrupt(buf_page_t *bpage, const fil_space_t &space)
 {
-	/* If block is not encrypted find the table with specified
-	space id, and mark it corrupted. Encrypted tables
-	are marked unusable later e.g. in ::open(). */
-	if (!space.crypt_data
-	    || space.crypt_data->type == CRYPT_SCHEME_UNENCRYPTED) {
-		dict_set_corrupted_by_space(&space);
-	} else {
-		dict_set_encrypted_by_space(&space);
-	}
+  /* If block is not encrypted find the table with specified
+  space id, and mark it corrupted. Encrypted tables
+  are marked unusable later e.g. in ::open(). */
+  if (!space.crypt_data || space.crypt_data->type == CRYPT_SCHEME_UNENCRYPTED)
+  {
+    dict_set_corrupted_by_space(&space);
+  }
+  else
+  {
+    dict_set_encrypted_by_space(&space);
+  }
 }
 
 /** Release and evict a corrupted page.
@@ -3950,7 +4054,7 @@ ATTRIBUTE_COLD void buf_pool_t::corrupted_evict(buf_page_t *bpage)
   bpage->set_corrupt_id();
 
   if (bpage->state() == BUF_BLOCK_FILE_PAGE)
-    rw_lock_x_unlock_gen(&reinterpret_cast<buf_block_t*>(bpage)->lock,
+    rw_lock_x_unlock_gen(&reinterpret_cast<buf_block_t *>(bpage)->lock,
                          BUF_IO_READ);
 
   bpage->io_unfix();
@@ -3982,7 +4086,7 @@ static void buf_corrupt_page_release(buf_page_t *bpage, const fil_node_t &node)
 @param[in]	d		page
 @param[in]	is_compressed	compressed page
 @return true if page is corrupted or false if it isn't */
-static bool buf_page_full_crc32_is_corrupted(ulint space_id, const byte* d,
+static bool buf_page_full_crc32_is_corrupted(ulint space_id, const byte *d,
                                              bool is_compressed)
 {
   if (space_id != mach_read_from_4(d + FIL_PAGE_SPACE_ID))
@@ -3992,8 +4096,8 @@ static bool buf_page_full_crc32_is_corrupted(ulint space_id, const byte* d,
   static_assert(FIL_PAGE_FCRC32_END_LSN % 4 == 0, "alignment");
 
   return !is_compressed &&
-    memcmp_aligned<4>(FIL_PAGE_LSN + 4 + d,
-                      d + srv_page_size - FIL_PAGE_FCRC32_END_LSN, 4);
+         memcmp_aligned<4>(FIL_PAGE_LSN + 4 + d,
+                           d + srv_page_size - FIL_PAGE_FCRC32_END_LSN, 4);
 }
 
 /** Check if page is maybe compressed, encrypted or both when we encounter
@@ -4010,67 +4114,66 @@ after decryption normal page checksum does not match.
 static dberr_t buf_page_check_corrupt(buf_page_t *bpage,
                                       const fil_node_t &node)
 {
-	ut_ad(node.space->referenced());
-
-	byte* dst_frame = (bpage->zip.data) ? bpage->zip.data :
-		((buf_block_t*) bpage)->frame;
-	dberr_t err = DB_SUCCESS;
-	uint key_version = buf_page_get_key_version(dst_frame,
-						    node.space->flags);
-
-	/* In buf_decrypt_after_read we have either decrypted the page if
-	page post encryption checksum matches and used key_id is found
-	from the encryption plugin. If checksum did not match page was
-	not decrypted and it could be either encrypted and corrupted
-	or corrupted or good page. If we decrypted, there page could
-	still be corrupted if used key does not match. */
-	const bool seems_encrypted = !node.space->full_crc32() && key_version
-		&& node.space->crypt_data
-		&& node.space->crypt_data->type != CRYPT_SCHEME_UNENCRYPTED;
-	ut_ad(node.space->purpose != FIL_TYPE_TEMPORARY ||
-	      node.space->full_crc32());
-
-	/* If traditional checksums match, we assume that page is
-	not anymore encrypted. */
-	if (node.space->full_crc32()
-	    && !buf_is_zeroes(span<const byte>(dst_frame,
-					       node.space->physical_size()))
-	    && (key_version || node.space->is_compressed()
-		|| node.space->purpose == FIL_TYPE_TEMPORARY)) {
-		if (buf_page_full_crc32_is_corrupted(
-			    bpage->id().space(), dst_frame,
-			    node.space->is_compressed())) {
-			err = DB_PAGE_CORRUPTED;
-		}
-	} else if (buf_page_is_corrupted(true, dst_frame, node.space->flags)) {
-		err = DB_PAGE_CORRUPTED;
-	}
-
-	if (seems_encrypted && err == DB_PAGE_CORRUPTED
-	    && bpage->id().page_no() != 0) {
-		err = DB_DECRYPTION_FAILED;
-
-		ib::error()
-			<< "The page " << bpage->id()
-			<< " in file '" << node.name
-			<< "' cannot be decrypted.";
-
-		ib::info()
-			<< "However key management plugin or used key_version "
-			<< key_version
-			<< " is not found or"
-			" used encryption algorithm or method does not match.";
-
-		if (bpage->id().space() != TRX_SYS_SPACE) {
-			ib::info()
-				<< "Marking tablespace as missing."
-				" You may drop this table or"
-				" install correct key management plugin"
-				" and key file.";
-		}
-	}
-
-	return (err);
+  ut_ad(node.space->referenced());
+
+  byte *dst_frame=
+      (bpage->zip.data) ? bpage->zip.data : ((buf_block_t *) bpage)->frame;
+  dberr_t err= DB_SUCCESS;
+  uint key_version= buf_page_get_key_version(dst_frame, node.space->flags);
+
+  /* In buf_decrypt_after_read we have either decrypted the page if
+  page post encryption checksum matches and used key_id is found
+  from the encryption plugin. If checksum did not match page was
+  not decrypted and it could be either encrypted and corrupted
+  or corrupted or good page. If we decrypted, there page could
+  still be corrupted if used key does not match. */
+  const bool seems_encrypted=
+      !node.space->full_crc32() && key_version && node.space->crypt_data &&
+      node.space->crypt_data->type != CRYPT_SCHEME_UNENCRYPTED;
+  ut_ad(node.space->purpose != FIL_TYPE_TEMPORARY || node.space->full_crc32());
+
+  /* If traditional checksums match, we assume that page is
+  not anymore encrypted. */
+  if (node.space->full_crc32() &&
+      !buf_is_zeroes(
+          span<const byte>(dst_frame, node.space->physical_size())) &&
+      (key_version || node.space->is_compressed() ||
+       node.space->purpose == FIL_TYPE_TEMPORARY))
+  {
+    if (buf_page_full_crc32_is_corrupted(bpage->id().space(), dst_frame,
+                                         node.space->is_compressed()))
+    {
+      err= DB_PAGE_CORRUPTED;
+    }
+  }
+  else if (buf_page_is_corrupted(true, dst_frame, node.space->flags))
+  {
+    err= DB_PAGE_CORRUPTED;
+  }
+
+  if (seems_encrypted && err == DB_PAGE_CORRUPTED &&
+      bpage->id().page_no() != 0)
+  {
+    err= DB_DECRYPTION_FAILED;
+
+    ib::error() << "The page " << bpage->id() << " in file '" << node.name
+                << "' cannot be decrypted.";
+
+    ib::info() << "However key management plugin or used key_version "
+               << key_version
+               << " is not found or"
+                  " used encryption algorithm or method does not match.";
+
+    if (bpage->id().space() != TRX_SYS_SPACE)
+    {
+      ib::info() << "Marking tablespace as missing."
+                    " You may drop this table or"
+                    " install correct key management plugin"
+                    " and key file.";
+    }
+  }
+
+  return (err);
 }
 
 /** Complete a read request of a file page to buf_pool.
@@ -4099,8 +4202,8 @@ dberr_t buf_page_read_complete(buf_page_t *bpage, const fil_node_t &node)
   ut_ad(bpage->state() == BUF_BLOCK_FILE_PAGE || bpage->zip.data);
 
   const byte *frame= bpage->zip.data
-    ? bpage->zip.data
-    : reinterpret_cast<buf_block_t*>(bpage)->frame;
+                         ? bpage->zip.data
+                         : reinterpret_cast<buf_block_t *>(bpage)->frame;
   ut_ad(frame);
 
   dberr_t err;
@@ -4113,7 +4216,7 @@ dberr_t buf_page_read_complete(buf_page_t *bpage, const fil_node_t &node)
   if (bpage->zip.data && bpage->state() == BUF_BLOCK_FILE_PAGE)
   {
     buf_pool.n_pend_unzip++;
-    auto ok= buf_zip_decompress(reinterpret_cast<buf_block_t*>(bpage), FALSE);
+    auto ok= buf_zip_decompress(reinterpret_cast<buf_block_t *>(bpage), FALSE);
     buf_pool.n_pend_unzip--;
 
     if (!ok)
@@ -4128,16 +4231,18 @@ dberr_t buf_page_read_complete(buf_page_t *bpage, const fil_node_t &node)
     const page_id_t read_id(mach_read_from_4(frame + FIL_PAGE_SPACE_ID),
                             mach_read_from_4(frame + FIL_PAGE_OFFSET));
 
-    if (read_id == id);
+    if (read_id == id)
+      ;
     else if (read_id == page_id_t(0, 0))
       /* This is likely an uninitialized page. */;
     else if (!node.space->full_crc32() &&
              page_id_t(0, read_id.page_no()) == id)
       /* FIL_PAGE_SPACE_ID was written as garbage in the system tablespace
-      before MySQL 4.1.1, which introduced innodb_file_per_table. */;
+      before MySQL 4.1.1, which introduced innodb_file_per_table. */
+      ;
     else if (node.space->full_crc32() &&
-             *reinterpret_cast<const uint32_t*>
-             (&frame[FIL_PAGE_FCRC32_KEY_VERSION]) &&
+             *reinterpret_cast<const uint32_t *>(
+                 &frame[FIL_PAGE_FCRC32_KEY_VERSION]) &&
              node.space->crypt_data &&
              node.space->crypt_data->type != CRYPT_SCHEME_UNENCRYPTED)
     {
@@ -4153,20 +4258,19 @@ dberr_t buf_page_read_complete(buf_page_t *bpage, const fil_node_t &node)
   err= buf_page_check_corrupt(bpage, node);
   if (UNIV_UNLIKELY(err != DB_SUCCESS))
   {
-database_corrupted:
+  database_corrupted:
     /* Not a real corruption if it was triggered by error injection */
-    DBUG_EXECUTE_IF("buf_page_import_corrupt_failure",
-                    if (!is_predefined_tablespace(id.space()))
-                    {
-                      buf_corrupt_page_release(bpage, node);
-                      ib::info() << "Simulated IMPORT corruption";
-                      return err;
-                    }
-                    err= DB_SUCCESS;
-                    goto page_not_corrupt;);
+    DBUG_EXECUTE_IF(
+        "buf_page_import_corrupt_failure",
+        if (!is_predefined_tablespace(id.space())) {
+          buf_corrupt_page_release(bpage, node);
+          ib::info() << "Simulated IMPORT corruption";
+          return err;
+        } err= DB_SUCCESS;
+        goto page_not_corrupt;);
 
     if (bpage->zip.data && bpage->state() == BUF_BLOCK_FILE_PAGE)
-      memset(reinterpret_cast<buf_block_t*>(bpage)->frame, 0, srv_page_size);
+      memset(reinterpret_cast<buf_block_t *>(bpage)->frame, 0, srv_page_size);
 
     if (err == DB_PAGE_CORRUPTED)
     {
@@ -4193,12 +4297,12 @@ dberr_t buf_page_read_complete(buf_page_t *bpage, const fil_node_t &node)
     }
   }
 
-  DBUG_EXECUTE_IF("buf_page_import_corrupt_failure",
-                  page_not_corrupt: bpage= bpage; );
+  DBUG_EXECUTE_IF("buf_page_import_corrupt_failure", page_not_corrupt
+                  : bpage= bpage;);
 
   if (err == DB_PAGE_CORRUPTED || err == DB_DECRYPTION_FAILED)
   {
-release_page:
+  release_page:
     buf_corrupt_page_release(bpage, node);
     if (recv_recovery_is_on())
       recv_sys.free_corrupted_page(id);
@@ -4210,20 +4314,18 @@ dberr_t buf_page_read_complete(buf_page_t *bpage, const fil_node_t &node)
 
   if (bpage->state() == BUF_BLOCK_FILE_PAGE && !recv_no_ibuf_operations &&
       (!id.space() || !is_predefined_tablespace(id.space())) &&
-      fil_page_get_type(frame) == FIL_PAGE_INDEX &&
-      page_is_leaf(frame))
+      fil_page_get_type(frame) == FIL_PAGE_INDEX && page_is_leaf(frame))
     bpage->ibuf_exist= true;
 
   if (UNIV_UNLIKELY(MONITOR_IS_ON(MONITOR_MODULE_BUF_PAGE)))
     buf_page_monitor(bpage, BUF_IO_READ);
-  DBUG_PRINT("ib_buf", ("read page %u:%u",
-                        id.space(), id.page_no()));
+  DBUG_PRINT("ib_buf", ("read page %u:%u", id.space(), id.page_no()));
 
   /* Because this thread which does the unlocking might not be the same that
   did the locking, we use a pass value != 0 in unlock, which simply
   removes the newest lock debug record, without checking the thread id. */
   if (bpage->state() == BUF_BLOCK_FILE_PAGE)
-    rw_lock_x_unlock_gen(&((buf_block_t*) bpage)->lock, BUF_IO_READ);
+    rw_lock_x_unlock_gen(&((buf_block_t *) bpage)->lock, BUF_IO_READ);
   bpage->io_unfix();
 
   ut_d(auto n=) buf_pool.n_pend_reads--;
@@ -4242,7 +4344,7 @@ void buf_pool_t::assert_all_freed()
   mysql_mutex_lock(&mutex);
   const chunk_t *chunk= chunks;
   for (auto i= n_chunks; i--; chunk++)
-    if (const buf_block_t* block= chunk->not_freed())
+    if (const buf_block_t *block= chunk->not_freed())
       ib::fatal() << "Page " << block->page.id() << " still fixed or dirty";
   mysql_mutex_unlock(&mutex);
 }
@@ -4251,142 +4353,144 @@ void buf_pool_t::assert_all_freed()
 /** Refresh the statistics used to print per-second averages. */
 void buf_refresh_io_stats()
 {
-	buf_pool.last_printout_time = time(NULL);
-	buf_pool.old_stat = buf_pool.stat;
+  buf_pool.last_printout_time= time(NULL);
+  buf_pool.old_stat= buf_pool.stat;
 }
 
 /** Invalidate all pages in the buffer pool.
 All pages must be in a replaceable state (not modified or latched). */
 void buf_pool_invalidate()
 {
-	mysql_mutex_lock(&buf_pool.mutex);
+  mysql_mutex_lock(&buf_pool.mutex);
 
-	buf_flush_wait_batch_end(true);
-	buf_flush_wait_batch_end(false);
+  buf_flush_wait_batch_end(true);
+  buf_flush_wait_batch_end(false);
 
-	/* It is possible that a write batch that has been posted
-	earlier is still not complete. For buffer pool invalidation to
-	proceed we must ensure there is NO write activity happening. */
+  /* It is possible that a write batch that has been posted
+  earlier is still not complete. For buffer pool invalidation to
+  proceed we must ensure there is NO write activity happening. */
 
-	ut_d(mysql_mutex_unlock(&buf_pool.mutex));
-	ut_d(buf_pool.assert_all_freed());
-	ut_d(mysql_mutex_lock(&buf_pool.mutex));
+  ut_d(mysql_mutex_unlock(&buf_pool.mutex));
+  ut_d(buf_pool.assert_all_freed());
+  ut_d(mysql_mutex_lock(&buf_pool.mutex));
 
-	while (buf_LRU_scan_and_free_block());
+  while (buf_LRU_scan_and_free_block())
+    ;
 
-	ut_ad(UT_LIST_GET_LEN(buf_pool.LRU) == 0);
-	ut_ad(UT_LIST_GET_LEN(buf_pool.unzip_LRU) == 0);
+  ut_ad(UT_LIST_GET_LEN(buf_pool.LRU) == 0);
+  ut_ad(UT_LIST_GET_LEN(buf_pool.unzip_LRU) == 0);
 
-	buf_pool.freed_page_clock = 0;
-	buf_pool.LRU_old = NULL;
-	buf_pool.LRU_old_len = 0;
+  buf_pool.freed_page_clock= 0;
+  buf_pool.LRU_old= NULL;
+  buf_pool.LRU_old_len= 0;
 
-	memset(&buf_pool.stat, 0x00, sizeof(buf_pool.stat));
-	buf_refresh_io_stats();
-	mysql_mutex_unlock(&buf_pool.mutex);
+  memset(&buf_pool.stat, 0x00, sizeof(buf_pool.stat));
+  buf_refresh_io_stats();
+  mysql_mutex_unlock(&buf_pool.mutex);
 }
 
 #ifdef UNIV_DEBUG
 /** Validate the buffer pool. */
 void buf_pool_t::validate()
 {
-	ulint		n_lru		= 0;
-	ulint		n_flushing	= 0;
-	ulint		n_free		= 0;
-	ulint		n_zip		= 0;
-
-	mysql_mutex_lock(&mutex);
-
-	chunk_t* chunk = chunks;
-
-	/* Check the uncompressed blocks. */
-
-	for (auto i = n_chunks; i--; chunk++) {
-
-		ulint		j;
-		buf_block_t*	block = chunk->blocks;
-
-		for (j = chunk->size; j--; block++) {
-			switch (block->page.state()) {
-			case BUF_BLOCK_ZIP_PAGE:
-				/* This kind of block descriptors should
-				be allocated by malloc() only. */
-				ut_error;
-				break;
-
-			case BUF_BLOCK_NOT_USED:
-				n_free++;
-				break;
-
-			case BUF_BLOCK_MEMORY:
-			case BUF_BLOCK_REMOVE_HASH:
-				/* do nothing */
-				break;
-
-			case BUF_BLOCK_FILE_PAGE:
-				const page_id_t id = block->page.id();
-				ut_ad(page_hash_get_low(id, id.fold())
-				      == &block->page);
-				n_lru++;
-				break;
-
-			}
-		}
-	}
-
-	/* Check dirty blocks. */
-
-	mysql_mutex_lock(&flush_list_mutex);
-	for (buf_page_t* b = UT_LIST_GET_FIRST(flush_list); b;
-	     b = UT_LIST_GET_NEXT(list, b)) {
-		ut_ad(b->oldest_modification());
-		ut_ad(!fsp_is_system_temporary(b->id().space()));
-		n_flushing++;
-
-		switch (b->state()) {
-		case BUF_BLOCK_ZIP_PAGE:
-			n_lru++;
-			n_zip++;
-			break;
-		case BUF_BLOCK_FILE_PAGE:
-			/* uncompressed page */
-			break;
-		case BUF_BLOCK_NOT_USED:
-		case BUF_BLOCK_MEMORY:
-		case BUF_BLOCK_REMOVE_HASH:
-			ut_error;
-			break;
-		}
-		const page_id_t id = b->id();
-		ut_ad(page_hash_get_low(id, id.fold()) == b);
-	}
-
-	ut_ad(UT_LIST_GET_LEN(flush_list) == n_flushing);
-
-	mysql_mutex_unlock(&flush_list_mutex);
-
-	if (curr_size == old_size
-	    && n_lru + n_free > curr_size + n_zip) {
-
-		ib::fatal() << "n_LRU " << n_lru << ", n_free " << n_free
-			<< ", pool " << curr_size
-			<< " zip " << n_zip << ". Aborting...";
-	}
-
-	ut_ad(UT_LIST_GET_LEN(LRU) >= n_lru);
-
-	if (curr_size == old_size
-	    && UT_LIST_GET_LEN(free) != n_free) {
-
-		ib::fatal() << "Free list len "
-			<< UT_LIST_GET_LEN(free)
-			<< ", free blocks " << n_free << ". Aborting...";
-	}
-
-	mysql_mutex_unlock(&mutex);
-
-	ut_d(buf_LRU_validate());
-	ut_d(buf_flush_validate());
+  ulint n_lru= 0;
+  ulint n_flushing= 0;
+  ulint n_free= 0;
+  ulint n_zip= 0;
+
+  mysql_mutex_lock(&mutex);
+
+  chunk_t *chunk= chunks;
+
+  /* Check the uncompressed blocks. */
+
+  for (auto i= n_chunks; i--; chunk++)
+  {
+
+    ulint j;
+    buf_block_t *block= chunk->blocks;
+
+    for (j= chunk->size; j--; block++)
+    {
+      switch (block->page.state())
+      {
+      case BUF_BLOCK_ZIP_PAGE:
+        /* This kind of block descriptors should
+        be allocated by malloc() only. */
+        ut_error;
+        break;
+
+      case BUF_BLOCK_NOT_USED:
+        n_free++;
+        break;
+
+      case BUF_BLOCK_MEMORY:
+      case BUF_BLOCK_REMOVE_HASH:
+        /* do nothing */
+        break;
+
+      case BUF_BLOCK_FILE_PAGE:
+        const page_id_t id= block->page.id();
+        ut_ad(page_hash_get_low(id, id.fold()) == &block->page);
+        n_lru++;
+        break;
+      }
+    }
+  }
+
+  /* Check dirty blocks. */
+
+  mysql_mutex_lock(&flush_list_mutex);
+  for (buf_page_t *b= UT_LIST_GET_FIRST(flush_list); b;
+       b= UT_LIST_GET_NEXT(list, b))
+  {
+    ut_ad(b->oldest_modification());
+    ut_ad(!fsp_is_system_temporary(b->id().space()));
+    n_flushing++;
+
+    switch (b->state())
+    {
+    case BUF_BLOCK_ZIP_PAGE:
+      n_lru++;
+      n_zip++;
+      break;
+    case BUF_BLOCK_FILE_PAGE:
+      /* uncompressed page */
+      break;
+    case BUF_BLOCK_NOT_USED:
+    case BUF_BLOCK_MEMORY:
+    case BUF_BLOCK_REMOVE_HASH:
+      ut_error;
+      break;
+    }
+    const page_id_t id= b->id();
+    ut_ad(page_hash_get_low(id, id.fold()) == b);
+  }
+
+  ut_ad(UT_LIST_GET_LEN(flush_list) == n_flushing);
+
+  mysql_mutex_unlock(&flush_list_mutex);
+
+  if (curr_size == old_size && n_lru + n_free > curr_size + n_zip)
+  {
+
+    ib::fatal() << "n_LRU " << n_lru << ", n_free " << n_free << ", pool "
+                << curr_size << " zip " << n_zip << ". Aborting...";
+  }
+
+  ut_ad(UT_LIST_GET_LEN(LRU) >= n_lru);
+
+  if (curr_size == old_size && UT_LIST_GET_LEN(free) != n_free)
+  {
+
+    ib::fatal() << "Free list len " << UT_LIST_GET_LEN(free)
+                << ", free blocks " << n_free << ". Aborting...";
+  }
+
+  mysql_mutex_unlock(&mutex);
+
+  ut_d(buf_LRU_validate());
+  ut_d(buf_flush_validate());
 }
 #endif /* UNIV_DEBUG */
 
@@ -4394,104 +4498,110 @@ void buf_pool_t::validate()
 /** Write information of the buf_pool to the error log. */
 void buf_pool_t::print()
 {
-	index_id_t*	index_ids;
-	ulint*		counts;
-	ulint		size;
-	ulint		i;
-	ulint		j;
-	index_id_t	id;
-	ulint		n_found;
-	chunk_t*	chunk;
-	dict_index_t*	index;
-
-	size = curr_size;
-
-	index_ids = static_cast<index_id_t*>(
-		ut_malloc_nokey(size * sizeof *index_ids));
-
-	counts = static_cast<ulint*>(ut_malloc_nokey(sizeof(ulint) * size));
-
-	mysql_mutex_lock(&mutex);
-	mysql_mutex_lock(&flush_list_mutex);
-
-	ib::info()
-		<< "[buffer pool: size=" << curr_size
-		<< ", database pages=" << UT_LIST_GET_LEN(LRU)
-		<< ", free pages=" << UT_LIST_GET_LEN(free)
-		<< ", modified database pages="
-		<< UT_LIST_GET_LEN(flush_list)
-		<< ", n pending decompressions=" << n_pend_unzip
-		<< ", n pending reads=" << n_pend_reads
-		<< ", n pending flush LRU=" << n_flush_LRU_
-		<< " list=" << n_flush_list_
-		<< ", pages made young=" << stat.n_pages_made_young
-		<< ", not young=" << stat.n_pages_not_made_young
-		<< ", pages read=" << stat.n_pages_read
-		<< ", created=" << stat.n_pages_created
-		<< ", written=" << stat.n_pages_written << "]";
-
-	mysql_mutex_unlock(&flush_list_mutex);
-
-	/* Count the number of blocks belonging to each index in the buffer */
-
-	n_found = 0;
-
-	chunk = chunks;
-
-	for (i = n_chunks; i--; chunk++) {
-		buf_block_t*	block		= chunk->blocks;
-		ulint		n_blocks	= chunk->size;
-
-		for (; n_blocks--; block++) {
-			const buf_frame_t* frame = block->frame;
-
-			if (fil_page_index_page_check(frame)) {
-
-				id = btr_page_get_index_id(frame);
-
-				/* Look for the id in the index_ids array */
-				j = 0;
-
-				while (j < n_found) {
-
-					if (index_ids[j] == id) {
-						counts[j]++;
-
-						break;
-					}
-					j++;
-				}
-
-				if (j == n_found) {
-					n_found++;
-					index_ids[j] = id;
-					counts[j] = 1;
-				}
-			}
-		}
-	}
-
-	mysql_mutex_unlock(&mutex);
-
-	for (i = 0; i < n_found; i++) {
-		index = dict_index_get_if_in_cache(index_ids[i]);
-
-		if (!index) {
-			ib::info() << "Block count for index "
-				<< index_ids[i] << " in buffer is about "
-				<< counts[i];
-		} else {
-			ib::info() << "Block count for index " << index_ids[i]
-				<< " in buffer is about " << counts[i]
-				<< ", index " << index->name
-				<< " of table " << index->table->name;
-		}
-	}
-
-	ut_free(index_ids);
-	ut_free(counts);
-
-	validate();
+  index_id_t *index_ids;
+  ulint *counts;
+  ulint size;
+  ulint i;
+  ulint j;
+  index_id_t id;
+  ulint n_found;
+  chunk_t *chunk;
+  dict_index_t *index;
+
+  size= curr_size;
+
+  index_ids=
+      static_cast<index_id_t *>(ut_malloc_nokey(size * sizeof *index_ids));
+
+  counts= static_cast<ulint *>(ut_malloc_nokey(sizeof(ulint) * size));
+
+  mysql_mutex_lock(&mutex);
+  mysql_mutex_lock(&flush_list_mutex);
+
+  ib::info() << "[buffer pool: size=" << curr_size
+             << ", database pages=" << UT_LIST_GET_LEN(LRU)
+             << ", free pages=" << UT_LIST_GET_LEN(free)
+             << ", modified database pages=" << UT_LIST_GET_LEN(flush_list)
+             << ", n pending decompressions=" << n_pend_unzip
+             << ", n pending reads=" << n_pend_reads
+             << ", n pending flush LRU=" << n_flush_LRU_
+             << " list=" << n_flush_list_
+             << ", pages made young=" << stat.n_pages_made_young
+             << ", not young=" << stat.n_pages_not_made_young
+             << ", pages read=" << stat.n_pages_read
+             << ", created=" << stat.n_pages_created
+             << ", written=" << stat.n_pages_written << "]";
+
+  mysql_mutex_unlock(&flush_list_mutex);
+
+  /* Count the number of blocks belonging to each index in the buffer */
+
+  n_found= 0;
+
+  chunk= chunks;
+
+  for (i= n_chunks; i--; chunk++)
+  {
+    buf_block_t *block= chunk->blocks;
+    ulint n_blocks= chunk->size;
+
+    for (; n_blocks--; block++)
+    {
+      const buf_frame_t *frame= block->frame;
+
+      if (fil_page_index_page_check(frame))
+      {
+
+        id= btr_page_get_index_id(frame);
+
+        /* Look for the id in the index_ids array */
+        j= 0;
+
+        while (j < n_found)
+        {
+
+          if (index_ids[j] == id)
+          {
+            counts[j]++;
+
+            break;
+          }
+          j++;
+        }
+
+        if (j == n_found)
+        {
+          n_found++;
+          index_ids[j]= id;
+          counts[j]= 1;
+        }
+      }
+    }
+  }
+
+  mysql_mutex_unlock(&mutex);
+
+  for (i= 0; i < n_found; i++)
+  {
+    index= dict_index_get_if_in_cache(index_ids[i]);
+
+    if (!index)
+    {
+      ib::info() << "Block count for index " << index_ids[i]
+                 << " in buffer is about " << counts[i];
+    }
+    else
+    {
+      ib::info() << "Block count for index " << index_ids[i]
+                 << " in buffer is about " << counts[i] << ", index "
+                 << index->name << " of table " << index->table->name;
+    }
+  }
+
+  ut_free(index_ids);
+  ut_free(counts);
+
+  validate();
 }
 #endif /* UNIV_DEBUG_PRINT || UNIV_DEBUG */
 
@@ -4518,230 +4628,213 @@ ulint buf_get_latched_pages_number()
 @param[out]	pool_info	buffer pool metadata */
 void buf_stats_get_pool_info(buf_pool_info_t *pool_info)
 {
-	time_t			current_time;
-	double			time_elapsed;
-
-	mysql_mutex_lock(&buf_pool.mutex);
+  time_t current_time;
+  double time_elapsed;
 
-	pool_info->pool_size = buf_pool.curr_size;
+  mysql_mutex_lock(&buf_pool.mutex);
 
-	pool_info->lru_len = UT_LIST_GET_LEN(buf_pool.LRU);
+  pool_info->pool_size= buf_pool.curr_size;
 
-	pool_info->old_lru_len = buf_pool.LRU_old_len;
+  pool_info->lru_len= UT_LIST_GET_LEN(buf_pool.LRU);
 
-	pool_info->free_list_len = UT_LIST_GET_LEN(buf_pool.free);
+  pool_info->old_lru_len= buf_pool.LRU_old_len;
 
-	mysql_mutex_lock(&buf_pool.flush_list_mutex);
-	pool_info->flush_list_len = UT_LIST_GET_LEN(buf_pool.flush_list);
+  pool_info->free_list_len= UT_LIST_GET_LEN(buf_pool.free);
 
-	pool_info->n_pend_unzip = UT_LIST_GET_LEN(buf_pool.unzip_LRU);
-	mysql_mutex_unlock(&buf_pool.flush_list_mutex);
+  mysql_mutex_lock(&buf_pool.flush_list_mutex);
+  pool_info->flush_list_len= UT_LIST_GET_LEN(buf_pool.flush_list);
 
-	pool_info->n_pend_reads = buf_pool.n_pend_reads;
+  pool_info->n_pend_unzip= UT_LIST_GET_LEN(buf_pool.unzip_LRU);
+  mysql_mutex_unlock(&buf_pool.flush_list_mutex);
 
-	pool_info->n_pending_flush_lru = buf_pool.n_flush_LRU_;
+  pool_info->n_pend_reads= buf_pool.n_pend_reads;
 
-	pool_info->n_pending_flush_list = buf_pool.n_flush_list_;
+  pool_info->n_pending_flush_lru= buf_pool.n_flush_LRU_;
 
-	current_time = time(NULL);
-	time_elapsed = 0.001 + difftime(current_time,
-					buf_pool.last_printout_time);
+  pool_info->n_pending_flush_list= buf_pool.n_flush_list_;
 
-	pool_info->n_pages_made_young = buf_pool.stat.n_pages_made_young;
+  current_time= time(NULL);
+  time_elapsed= 0.001 + difftime(current_time, buf_pool.last_printout_time);
 
-	pool_info->n_pages_not_made_young =
-		buf_pool.stat.n_pages_not_made_young;
+  pool_info->n_pages_made_young= buf_pool.stat.n_pages_made_young;
 
-	pool_info->n_pages_read = buf_pool.stat.n_pages_read;
+  pool_info->n_pages_not_made_young= buf_pool.stat.n_pages_not_made_young;
 
-	pool_info->n_pages_created = buf_pool.stat.n_pages_created;
+  pool_info->n_pages_read= buf_pool.stat.n_pages_read;
 
-	pool_info->n_pages_written = buf_pool.stat.n_pages_written;
+  pool_info->n_pages_created= buf_pool.stat.n_pages_created;
 
-	pool_info->n_page_gets = buf_pool.stat.n_page_gets;
+  pool_info->n_pages_written= buf_pool.stat.n_pages_written;
 
-	pool_info->n_ra_pages_read_rnd = buf_pool.stat.n_ra_pages_read_rnd;
-	pool_info->n_ra_pages_read = buf_pool.stat.n_ra_pages_read;
+  pool_info->n_page_gets= buf_pool.stat.n_page_gets;
 
-	pool_info->n_ra_pages_evicted = buf_pool.stat.n_ra_pages_evicted;
+  pool_info->n_ra_pages_read_rnd= buf_pool.stat.n_ra_pages_read_rnd;
+  pool_info->n_ra_pages_read= buf_pool.stat.n_ra_pages_read;
 
-	pool_info->page_made_young_rate =
-	static_cast<double>(buf_pool.stat.n_pages_made_young
-			    - buf_pool.old_stat.n_pages_made_young)
-	/ time_elapsed;
+  pool_info->n_ra_pages_evicted= buf_pool.stat.n_ra_pages_evicted;
 
-	pool_info->page_not_made_young_rate =
-	static_cast<double>(buf_pool.stat.n_pages_not_made_young
-			    - buf_pool.old_stat.n_pages_not_made_young)
-	/ time_elapsed;
+  pool_info->page_made_young_rate=
+      static_cast<double>(buf_pool.stat.n_pages_made_young -
+                          buf_pool.old_stat.n_pages_made_young) /
+      time_elapsed;
 
-	pool_info->pages_read_rate =
-	static_cast<double>(buf_pool.stat.n_pages_read
-			    - buf_pool.old_stat.n_pages_read)
-	/ time_elapsed;
+  pool_info->page_not_made_young_rate=
+      static_cast<double>(buf_pool.stat.n_pages_not_made_young -
+                          buf_pool.old_stat.n_pages_not_made_young) /
+      time_elapsed;
 
-	pool_info->pages_created_rate =
-	static_cast<double>(buf_pool.stat.n_pages_created
-			    - buf_pool.old_stat.n_pages_created)
-	/ time_elapsed;
+  pool_info->pages_read_rate=
+      static_cast<double>(buf_pool.stat.n_pages_read -
+                          buf_pool.old_stat.n_pages_read) /
+      time_elapsed;
 
-	pool_info->pages_written_rate =
-	static_cast<double>(buf_pool.stat.n_pages_written
-			    - buf_pool.old_stat.n_pages_written)
-	/ time_elapsed;
+  pool_info->pages_created_rate=
+      static_cast<double>(buf_pool.stat.n_pages_created -
+                          buf_pool.old_stat.n_pages_created) /
+      time_elapsed;
 
-	pool_info->n_page_get_delta = buf_pool.stat.n_page_gets
-				      - buf_pool.old_stat.n_page_gets;
+  pool_info->pages_written_rate=
+      static_cast<double>(buf_pool.stat.n_pages_written -
+                          buf_pool.old_stat.n_pages_written) /
+      time_elapsed;
 
-	if (pool_info->n_page_get_delta) {
-		pool_info->page_read_delta = buf_pool.stat.n_pages_read
-					     - buf_pool.old_stat.n_pages_read;
+  pool_info->n_page_get_delta=
+      buf_pool.stat.n_page_gets - buf_pool.old_stat.n_page_gets;
 
-		pool_info->young_making_delta =
-			buf_pool.stat.n_pages_made_young
-			- buf_pool.old_stat.n_pages_made_young;
+  if (pool_info->n_page_get_delta)
+  {
+    pool_info->page_read_delta=
+        buf_pool.stat.n_pages_read - buf_pool.old_stat.n_pages_read;
 
-		pool_info->not_young_making_delta =
-			buf_pool.stat.n_pages_not_made_young
-			- buf_pool.old_stat.n_pages_not_made_young;
-	}
-	pool_info->pages_readahead_rnd_rate =
-	static_cast<double>(buf_pool.stat.n_ra_pages_read_rnd
-			    - buf_pool.old_stat.n_ra_pages_read_rnd)
-	/ time_elapsed;
+    pool_info->young_making_delta= buf_pool.stat.n_pages_made_young -
+                                   buf_pool.old_stat.n_pages_made_young;
 
+    pool_info->not_young_making_delta=
+        buf_pool.stat.n_pages_not_made_young -
+        buf_pool.old_stat.n_pages_not_made_young;
+  }
+  pool_info->pages_readahead_rnd_rate=
+      static_cast<double>(buf_pool.stat.n_ra_pages_read_rnd -
+                          buf_pool.old_stat.n_ra_pages_read_rnd) /
+      time_elapsed;
 
-	pool_info->pages_readahead_rate =
-	static_cast<double>(buf_pool.stat.n_ra_pages_read
-			    - buf_pool.old_stat.n_ra_pages_read)
-	/ time_elapsed;
+  pool_info->pages_readahead_rate=
+      static_cast<double>(buf_pool.stat.n_ra_pages_read -
+                          buf_pool.old_stat.n_ra_pages_read) /
+      time_elapsed;
 
-	pool_info->pages_evicted_rate =
-	static_cast<double>(buf_pool.stat.n_ra_pages_evicted
-			    - buf_pool.old_stat.n_ra_pages_evicted)
-	/ time_elapsed;
+  pool_info->pages_evicted_rate=
+      static_cast<double>(buf_pool.stat.n_ra_pages_evicted -
+                          buf_pool.old_stat.n_ra_pages_evicted) /
+      time_elapsed;
 
-	pool_info->unzip_lru_len = UT_LIST_GET_LEN(buf_pool.unzip_LRU);
+  pool_info->unzip_lru_len= UT_LIST_GET_LEN(buf_pool.unzip_LRU);
 
-	pool_info->io_sum = buf_LRU_stat_sum.io;
+  pool_info->io_sum= buf_LRU_stat_sum.io;
 
-	pool_info->io_cur = buf_LRU_stat_cur.io;
+  pool_info->io_cur= buf_LRU_stat_cur.io;
 
-	pool_info->unzip_sum = buf_LRU_stat_sum.unzip;
+  pool_info->unzip_sum= buf_LRU_stat_sum.unzip;
 
-	pool_info->unzip_cur = buf_LRU_stat_cur.unzip;
+  pool_info->unzip_cur= buf_LRU_stat_cur.unzip;
 
-	buf_refresh_io_stats();
-	mysql_mutex_unlock(&buf_pool.mutex);
+  buf_refresh_io_stats();
+  mysql_mutex_unlock(&buf_pool.mutex);
 }
 
-/*********************************************************************//**
-Prints info of the buffer i/o. */
-static
-void
-buf_print_io_instance(
-/*==================*/
-	buf_pool_info_t*pool_info,	/*!< in: buffer pool info */
-	FILE*		file)		/*!< in/out: buffer where to print */
+/*********************************************************************/ /**
+ Prints info of the buffer i/o. */
+static void buf_print_io_instance(
+    /*==================*/
+    buf_pool_info_t *pool_info, /*!< in: buffer pool info */
+    FILE *file)                 /*!< in/out: buffer where to print */
 {
-	ut_ad(pool_info);
-
-	fprintf(file,
-		"Buffer pool size   " ULINTPF "\n"
-		"Free buffers       " ULINTPF "\n"
-		"Database pages     " ULINTPF "\n"
-		"Old database pages " ULINTPF "\n"
-		"Modified db pages  " ULINTPF "\n"
-		"Percent of dirty pages(LRU & free pages): %.3f\n"
-		"Max dirty pages percent: %.3f\n"
-		"Pending reads " ULINTPF "\n"
-		"Pending writes: LRU " ULINTPF ", flush list " ULINTPF "\n",
-		pool_info->pool_size,
-		pool_info->free_list_len,
-		pool_info->lru_len,
-		pool_info->old_lru_len,
-		pool_info->flush_list_len,
-		static_cast<double>(pool_info->flush_list_len)
-		/ (static_cast<double>(pool_info->lru_len
-				       + pool_info->free_list_len) + 1.0)
-		* 100.0,
-		srv_max_buf_pool_modified_pct,
-		pool_info->n_pend_reads,
-		pool_info->n_pending_flush_lru,
-		pool_info->n_pending_flush_list);
-
-	fprintf(file,
-		"Pages made young " ULINTPF ", not young " ULINTPF "\n"
-		"%.2f youngs/s, %.2f non-youngs/s\n"
-		"Pages read " ULINTPF ", created " ULINTPF
-		", written " ULINTPF "\n"
-		"%.2f reads/s, %.2f creates/s, %.2f writes/s\n",
-		pool_info->n_pages_made_young,
-		pool_info->n_pages_not_made_young,
-		pool_info->page_made_young_rate,
-		pool_info->page_not_made_young_rate,
-		pool_info->n_pages_read,
-		pool_info->n_pages_created,
-		pool_info->n_pages_written,
-		pool_info->pages_read_rate,
-		pool_info->pages_created_rate,
-		pool_info->pages_written_rate);
-
-	if (pool_info->n_page_get_delta) {
-		double hit_rate = static_cast<double>(
-			pool_info->page_read_delta)
-			/ static_cast<double>(pool_info->n_page_get_delta);
-
-		if (hit_rate > 1) {
-			hit_rate = 1;
-		}
-
-		fprintf(file,
-			"Buffer pool hit rate " ULINTPF " / 1000,"
-			" young-making rate " ULINTPF " / 1000 not "
-			ULINTPF " / 1000\n",
-			ulint(1000 * (1 - hit_rate)),
-			ulint(1000
-			      * double(pool_info->young_making_delta)
-			      / double(pool_info->n_page_get_delta)),
-			ulint(1000 * double(pool_info->not_young_making_delta)
-			      / double(pool_info->n_page_get_delta)));
-	} else {
-		fputs("No buffer pool page gets since the last printout\n",
-		      file);
-	}
-
-	/* Statistics about read ahead algorithm */
-	fprintf(file, "Pages read ahead %.2f/s,"
-		" evicted without access %.2f/s,"
-		" Random read ahead %.2f/s\n",
-
-		pool_info->pages_readahead_rate,
-		pool_info->pages_evicted_rate,
-		pool_info->pages_readahead_rnd_rate);
-
-	/* Print some values to help us with visualizing what is
-	happening with LRU eviction. */
-	fprintf(file,
-		"LRU len: " ULINTPF ", unzip_LRU len: " ULINTPF "\n"
-		"I/O sum[" ULINTPF "]:cur[" ULINTPF "], "
-		"unzip sum[" ULINTPF "]:cur[" ULINTPF "]\n",
-		pool_info->lru_len, pool_info->unzip_lru_len,
-		pool_info->io_sum, pool_info->io_cur,
-		pool_info->unzip_sum, pool_info->unzip_cur);
+  ut_ad(pool_info);
+
+  fprintf(
+      file,
+      "Buffer pool size   " ULINTPF "\n"
+      "Free buffers       " ULINTPF "\n"
+      "Database pages     " ULINTPF "\n"
+      "Old database pages " ULINTPF "\n"
+      "Modified db pages  " ULINTPF "\n"
+      "Percent of dirty pages(LRU & free pages): %.3f\n"
+      "Max dirty pages percent: %.3f\n"
+      "Pending reads " ULINTPF "\n"
+      "Pending writes: LRU " ULINTPF ", flush list " ULINTPF "\n",
+      pool_info->pool_size, pool_info->free_list_len, pool_info->lru_len,
+      pool_info->old_lru_len, pool_info->flush_list_len,
+      static_cast<double>(pool_info->flush_list_len) /
+          (static_cast<double>(pool_info->lru_len + pool_info->free_list_len) +
+           1.0) *
+          100.0,
+      srv_max_buf_pool_modified_pct, pool_info->n_pend_reads,
+      pool_info->n_pending_flush_lru, pool_info->n_pending_flush_list);
+
+  fprintf(file,
+          "Pages made young " ULINTPF ", not young " ULINTPF "\n"
+          "%.2f youngs/s, %.2f non-youngs/s\n"
+          "Pages read " ULINTPF ", created " ULINTPF ", written " ULINTPF "\n"
+          "%.2f reads/s, %.2f creates/s, %.2f writes/s\n",
+          pool_info->n_pages_made_young, pool_info->n_pages_not_made_young,
+          pool_info->page_made_young_rate, pool_info->page_not_made_young_rate,
+          pool_info->n_pages_read, pool_info->n_pages_created,
+          pool_info->n_pages_written, pool_info->pages_read_rate,
+          pool_info->pages_created_rate, pool_info->pages_written_rate);
+
+  if (pool_info->n_page_get_delta)
+  {
+    double hit_rate= static_cast<double>(pool_info->page_read_delta) /
+                     static_cast<double>(pool_info->n_page_get_delta);
+
+    if (hit_rate > 1)
+    {
+      hit_rate= 1;
+    }
+
+    fprintf(file,
+            "Buffer pool hit rate " ULINTPF " / 1000,"
+            " young-making rate " ULINTPF " / 1000 not " ULINTPF " / 1000\n",
+            ulint(1000 * (1 - hit_rate)),
+            ulint(1000 * double(pool_info->young_making_delta) /
+                  double(pool_info->n_page_get_delta)),
+            ulint(1000 * double(pool_info->not_young_making_delta) /
+                  double(pool_info->n_page_get_delta)));
+  }
+  else
+  {
+    fputs("No buffer pool page gets since the last printout\n", file);
+  }
+
+  /* Statistics about read ahead algorithm */
+  fprintf(file,
+          "Pages read ahead %.2f/s,"
+          " evicted without access %.2f/s,"
+          " Random read ahead %.2f/s\n",
+
+          pool_info->pages_readahead_rate, pool_info->pages_evicted_rate,
+          pool_info->pages_readahead_rnd_rate);
+
+  /* Print some values to help us with visualizing what is
+  happening with LRU eviction. */
+  fprintf(file,
+          "LRU len: " ULINTPF ", unzip_LRU len: " ULINTPF "\n"
+          "I/O sum[" ULINTPF "]:cur[" ULINTPF "], "
+          "unzip sum[" ULINTPF "]:cur[" ULINTPF "]\n",
+          pool_info->lru_len, pool_info->unzip_lru_len, pool_info->io_sum,
+          pool_info->io_cur, pool_info->unzip_sum, pool_info->unzip_cur);
 }
 
-/*********************************************************************//**
-Prints info of the buffer i/o. */
-void
-buf_print_io(
-/*=========*/
-	FILE*	file)	/*!< in/out: buffer where to print */
+/*********************************************************************/ /**
+ Prints info of the buffer i/o. */
+void buf_print_io(
+    /*=========*/
+    FILE *file) /*!< in/out: buffer where to print */
 {
-	buf_pool_info_t	pool_info;
+  buf_pool_info_t pool_info;
 
-	buf_stats_get_pool_info(&pool_info);
-	buf_print_io_instance(&pool_info, file);
+  buf_stats_get_pool_info(&pool_info);
+  buf_print_io_instance(&pool_info, file);
 }
 
 /** Verify that post encryption checksum match with the calculated checksum.
@@ -4749,21 +4842,22 @@ This function should be called only if tablespace contains crypt data metadata.
 @param[in]	page		page frame
 @param[in]	fsp_flags	tablespace flags
 @return true if true if page is encrypted and OK, false otherwise */
-bool buf_page_verify_crypt_checksum(const byte* page, ulint fsp_flags)
+bool buf_page_verify_crypt_checksum(const byte *page, ulint fsp_flags)
 {
-	if (!fil_space_t::full_crc32(fsp_flags)) {
-		return fil_space_verify_crypt_checksum(
-			page, fil_space_t::zip_size(fsp_flags));
-	}
+  if (!fil_space_t::full_crc32(fsp_flags))
+  {
+    return fil_space_verify_crypt_checksum(page,
+                                           fil_space_t::zip_size(fsp_flags));
+  }
 
-	return !buf_page_is_corrupted(true, page, fsp_flags);
+  return !buf_page_is_corrupted(true, page, fsp_flags);
 }
 
 /** Print the given page_id_t object.
 @param[in,out]	out	the output stream
 @param[in]	page_id	the page_id_t object to be printed
 @return the output stream */
-std::ostream& operator<<(std::ostream &out, const page_id_t page_id)
+std::ostream &operator<<(std::ostream &out, const page_id_t page_id)
 {
   out << "[page id: space=" << page_id.space()
       << ", page number=" << page_id.page_no() << "]";
diff --git storage/innobase/include/ut0lst.h storage/innobase/include/ut0lst.h
index 9a5f3059826..c47b67d7fe6 100644
--- storage/innobase/include/ut0lst.h
+++ storage/innobase/include/ut0lst.h
@@ -17,13 +17,13 @@ this program; if not, write to the Free Software Foundation, Inc.,
 
 *****************************************************************************/
 
-/******************************************************************//**
-@file include/ut0lst.h
-List utilities
+/******************************************************************/ /**
+ @file include/ut0lst.h
+ List utilities
 
-Created 9/10/1995 Heikki Tuuri
-Rewritten by Sunny Bains Dec 2011.
-***********************************************************************/
+ Created 9/10/1995 Heikki Tuuri
+ Rewritten by Sunny Bains Dec 2011.
+ ***********************************************************************/
 
 #ifndef ut0lst_h
 #define ut0lst_h
@@ -36,530 +36,561 @@ Rewritten by Sunny Bains Dec 2011.
 list node may belong to two or more lists, but is only on one list
 at a time. */
 
-/*******************************************************************//**
-The two way list node.
-@param TYPE the list node type name */
-template <typename Type>
-struct ut_list_node {
-	Type*		prev;			/*!< pointer to the previous
-						node, NULL if start of list */
-	Type*		next;			/*!< pointer to next node,
-						NULL if end of list */
-
-	void reverse()
-	{
-		Type*	tmp = prev;
-		prev = next;
-		next = tmp;
-	}
+/*******************************************************************/ /**
+ The two way list node.
+ @param TYPE the list node type name */
+template <typename Type> struct ut_list_node
+{
+  Type *prev; /*!< pointer to the previous
+              node, NULL if start of list */
+  Type *next; /*!< pointer to next node,
+              NULL if end of list */
+
+  void reverse()
+  {
+    Type *tmp= prev;
+    prev= next;
+    next= tmp;
+  }
 };
 
 /** Macro used for legacy reasons */
-#define UT_LIST_NODE_T(t)		ut_list_node<t>
-
-/*******************************************************************//**
-The two-way list base node. The base node contains pointers to both ends
-of the list and a count of nodes in the list (excluding the base node
-from the count). We also store a pointer to the member field so that it
-doesn't have to be specified when doing list operations.
-@param Type the type of the list element
-@param NodePtr field member pointer that points to the list node */
-template <typename Type, typename NodePtr>
-struct ut_list_base {
-	typedef Type elem_type;
-	typedef NodePtr node_ptr;
-	typedef ut_list_node<Type> node_type;
-
-	ulint		count;			/*!< count of nodes in list */
-	elem_type*	start;			/*!< pointer to list start,
-						NULL if empty */
-	elem_type*	end;			/*!< pointer to list end,
-						NULL if empty */
-	node_ptr	node;			/*!< Pointer to member field
-						that is used as a link node */
+#define UT_LIST_NODE_T(t) ut_list_node<t>
+
+/*******************************************************************/ /**
+ The two-way list base node. The base node contains pointers to both ends
+ of the list and a count of nodes in the list (excluding the base node
+ from the count). We also store a pointer to the member field so that it
+ doesn't have to be specified when doing list operations.
+ @param Type the type of the list element
+ @param NodePtr field member pointer that points to the list node */
+template <typename Type, typename NodePtr> struct ut_list_base
+{
+  typedef Type elem_type;
+  typedef NodePtr node_ptr;
+  typedef ut_list_node<Type> node_type;
+
+  ulint count;      /*!< count of nodes in list */
+  elem_type *start; /*!< pointer to list start,
+                    NULL if empty */
+  elem_type *end;   /*!< pointer to list end,
+                    NULL if empty */
+  node_ptr node;    /*!< Pointer to member field
+                    that is used as a link node */
 #ifdef UNIV_DEBUG
-	ulint		init;			/*!< UT_LIST_INITIALISED if
-						the list was initialised with
-						UT_LIST_INIT() */
-#endif /* UNIV_DEBUG */
-
-	void reverse()
-	{
-		Type*	tmp = start;
-		start = end;
-		end = tmp;
-	}
+  ulint init; /*!< UT_LIST_INITIALISED if
+              the list was initialised with
+              UT_LIST_INIT() */
+#endif        /* UNIV_DEBUG */
+
+  void reverse()
+  {
+    Type *tmp= start;
+    start= end;
+    end= tmp;
+  }
 };
 
-#define UT_LIST_BASE_NODE_T(t)	ut_list_base<t, ut_list_node<t> t::*>
+#define UT_LIST_BASE_NODE_T(t) ut_list_base<t, ut_list_node<t> t::*>
 
 #ifdef UNIV_DEBUG
-# define UT_LIST_INITIALISED		0xCAFE
-# define UT_LIST_INITIALISE(b)		(b).init = UT_LIST_INITIALISED
-# define UT_LIST_IS_INITIALISED(b)	ut_a(((b).init == UT_LIST_INITIALISED))
+#define UT_LIST_INITIALISED 0xCAFE
+#define UT_LIST_INITIALISE(b) (b).init= UT_LIST_INITIALISED
+#define UT_LIST_IS_INITIALISED(b) ut_a(((b).init == UT_LIST_INITIALISED))
 #else
-# define UT_LIST_INITIALISE(b)
-# define UT_LIST_IS_INITIALISED(b)
+#define UT_LIST_INITIALISE(b)
+#define UT_LIST_IS_INITIALISED(b)
 #endif /* UNIV_DEBUG */
 
-/*******************************************************************//**
-Note: This is really the list constructor. We should be able to use
-placement new here.
-Initializes the base node of a two-way list.
-@param b the list base node
-@param pmf point to member field that will be used as the link node */
-#define UT_LIST_INIT(b, pmf)						\
-{									\
-	(b).count = 0;							\
-	(b).start = 0;							\
-	(b).end   = 0;							\
-	(b).node  = pmf;						\
-	UT_LIST_INITIALISE(b);						\
-}
+/*******************************************************************/ /**
+ Note: This is really the list constructor. We should be able to use
+ placement new here.
+ Initializes the base node of a two-way list.
+ @param b the list base node
+ @param pmf point to member field that will be used as the link node */
+#define UT_LIST_INIT(b, pmf)                                                  \
+  {                                                                           \
+    (b).count= 0;                                                             \
+    (b).start= 0;                                                             \
+    (b).end= 0;                                                               \
+    (b).node= pmf;                                                            \
+    UT_LIST_INITIALISE(b);                                                    \
+  }
 
 /** Functor for accessing the embedded node within a list element. This is
 required because some lists can have the node emebedded inside a nested
 struct/union. See lock0priv.h (table locks) for an example. It provides a
 specialised functor to grant access to the list node. */
-template <typename Type>
-struct GenericGetNode {
+template <typename Type> struct GenericGetNode
+{
 
-	typedef ut_list_node<Type> node_type;
+  typedef ut_list_node<Type> node_type;
 
-	GenericGetNode(node_type Type::* node) : m_node(node) {}
+  GenericGetNode(node_type Type::*node) : m_node(node) {}
 
-	node_type& operator() (Type& elem)
-	{
-		return(elem.*m_node);
-	}
+  node_type &operator()(Type &elem) { return (elem.*m_node); }
 
-	node_type	Type::*m_node;
+  node_type Type::*m_node;
 };
 
-/*******************************************************************//**
-Adds the node as the first element in a two-way linked list.
-@param list the base node (not a pointer to it)
-@param elem the element to add */
+/*******************************************************************/ /**
+ Adds the node as the first element in a two-way linked list.
+ @param list the base node (not a pointer to it)
+ @param elem the element to add */
 template <typename List>
-void
-ut_list_prepend(
-	List&				list,
-	typename List::elem_type*	elem)
+void ut_list_prepend(List &list, typename List::elem_type *elem)
 {
-	typename List::node_type&	elem_node = elem->*list.node;
+  typename List::node_type &elem_node= elem->*list.node;
 
-	UT_LIST_IS_INITIALISED(list);
+  UT_LIST_IS_INITIALISED(list);
 
-	elem_node.prev = 0;
-	elem_node.next = list.start;
+  elem_node.prev= 0;
+  elem_node.next= list.start;
 
-	if (list.start != 0) {
-		typename List::node_type&	base_node =
-			list.start->*list.node;
+  if (list.start != 0)
+  {
+    typename List::node_type &base_node= list.start->*list.node;
 
-		ut_ad(list.start != elem);
+    ut_ad(list.start != elem);
 
-		base_node.prev = elem;
-	}
+    base_node.prev= elem;
+  }
 
-	list.start = elem;
+  list.start= elem;
 
-	if (list.end == 0) {
-		list.end = elem;
-	}
+  if (list.end == 0)
+  {
+    list.end= elem;
+  }
 
-	++list.count;
+  ++list.count;
 }
 
-/*******************************************************************//**
-Adds the node as the first element in a two-way linked list.
-@param LIST the base node (not a pointer to it)
-@param ELEM the element to add */
-#define UT_LIST_ADD_FIRST(LIST, ELEM)	ut_list_prepend(LIST, ELEM)
-
-/*******************************************************************//**
-Adds the node as the last element in a two-way linked list.
-@param list list
-@param elem the element to add
-@param get_node to get the list node for that element */
+/*******************************************************************/ /**
+ Adds the node as the first element in a two-way linked list.
+ @param LIST the base node (not a pointer to it)
+ @param ELEM the element to add */
+#define UT_LIST_ADD_FIRST(LIST, ELEM) ut_list_prepend(LIST, ELEM)
+
+/*******************************************************************/ /**
+ Adds the node as the last element in a two-way linked list.
+ @param list list
+ @param elem the element to add
+ @param get_node to get the list node for that element */
 template <typename List, typename Functor>
-void
-ut_list_append(
-	List&				list,
-	typename List::elem_type*	elem,
-	Functor				get_node)
+void ut_list_append(List &list, typename List::elem_type *elem,
+                    Functor get_node)
 {
-	typename List::node_type&	node = get_node(*elem);
+  typename List::node_type &node= get_node(*elem);
 
-	UT_LIST_IS_INITIALISED(list);
+  UT_LIST_IS_INITIALISED(list);
 
-	node.next = 0;
-	node.prev = list.end;
+  node.next= 0;
+  node.prev= list.end;
 
-	if (list.end != 0) {
-		typename List::node_type&	base_node = get_node(*list.end);
+  if (list.end != 0)
+  {
+    typename List::node_type &base_node= get_node(*list.end);
 
-		ut_ad(list.end != elem);
+    ut_ad(list.end != elem);
 
-		base_node.next = elem;
-	}
+    base_node.next= elem;
+  }
 
-	list.end = elem;
+  list.end= elem;
 
-	if (list.start == 0) {
-		list.start = elem;
-	}
+  if (list.start == 0)
+  {
+    list.start= elem;
+  }
 
-	++list.count;
+  ++list.count;
 }
 
-/*******************************************************************//**
-Adds the node as the last element in a two-way linked list.
-@param list list
-@param elem the element to add */
+/*******************************************************************/ /**
+ Adds the node as the last element in a two-way linked list.
+ @param list list
+ @param elem the element to add */
 template <typename List>
-void
-ut_list_append(
-	List&				list,
-	typename List::elem_type*	elem)
+void ut_list_append(List &list, typename List::elem_type *elem)
+{
+  ut_list_append(list, elem,
+                 GenericGetNode<typename List::elem_type>(list.node));
+}
+
+/*******************************************************************/ /**
+ Adds the node as the last element in a two-way linked list.
+ @param LIST list base node (not a pointer to it)
+ @param ELEM the element to add */
+#define UT_LIST_ADD_LAST(LIST, ELEM) ut_list_append(LIST, ELEM)
+
+/*******************************************************************/ /**
+ Adds the node as the last element in a two-way linked list.
+ @param list1 list
+ @param list2 the list to concat
+ @param get_node to get the list1's node for that element */
+template <typename List, typename Functor>
+void ut_list_concat(List &list1, List &list2, Functor get_node)
+{
+  UT_LIST_IS_INITIALISED(list1);
+  UT_LIST_IS_INITIALISED(list2);
+
+  if (list2.count == 0)
+  {
+    return;
+  }
+
+  typename List::node_type &start_of_list2= get_node(*list2.start);
+
+  if (list1.count == 0)
+  {
+    list1.start= list2.start;
+    list1.end= list2.end;
+    list1.count= list2.count;
+    return;
+  }
+
+  typename List::node_type &end_of_list1= get_node(*list1.end);
+  start_of_list2.prev= list1.end;
+  end_of_list1.next= list2.start;
+  list1.end= list2.end;
+
+  list1.count+= list2.count;
+}
+
+/*******************************************************************/ /**
+ concat two separate list
+ @param list1 list
+ @param list2 the list to concat */
+template <typename List> void ut_list_concat(List &list1, List &list2)
 {
-	ut_list_append(
-		list, elem,
-		GenericGetNode<typename List::elem_type>(list.node));
+  ut_list_concat(list1, list2,
+                 GenericGetNode<typename List::elem_type>(list1.node));
 }
 
-/*******************************************************************//**
-Adds the node as the last element in a two-way linked list.
-@param LIST list base node (not a pointer to it)
-@param ELEM the element to add */
-#define UT_LIST_ADD_LAST(LIST, ELEM)	ut_list_append(LIST, ELEM)
-
-/*******************************************************************//**
-Inserts a ELEM2 after ELEM1 in a list.
-@param list the base node
-@param elem1 node after which ELEM2 is inserted
-@param elem2 node being inserted after ELEM1 */
+/*******************************************************************/ /**
+ concat two separate linked list
+ @param LIST1 first list
+ @param LIST2 the list to concat */
+#define UT_LIST_CONCAT(LIST1, LIST2) ut_list_concat(LIST1, LIST2)
+
+/*******************************************************************/ /**
+ Inserts a ELEM2 after ELEM1 in a list.
+ @param list the base node
+ @param elem1 node after which ELEM2 is inserted
+ @param elem2 node being inserted after ELEM1 */
 template <typename List>
-void
-ut_list_insert(
-	List&				list,
-	typename List::elem_type*	elem1,
-	typename List::elem_type*	elem2)
+void ut_list_insert(List &list, typename List::elem_type *elem1,
+                    typename List::elem_type *elem2)
 {
-	ut_ad(elem1 != elem2);
-	UT_LIST_IS_INITIALISED(list);
+  ut_ad(elem1 != elem2);
+  UT_LIST_IS_INITIALISED(list);
 
-	typename List::node_type&	elem1_node = elem1->*list.node;
-	typename List::node_type&	elem2_node = elem2->*list.node;
+  typename List::node_type &elem1_node= elem1->*list.node;
+  typename List::node_type &elem2_node= elem2->*list.node;
 
-	elem2_node.prev = elem1;
-	elem2_node.next = elem1_node.next;
+  elem2_node.prev= elem1;
+  elem2_node.next= elem1_node.next;
 
-	if (elem1_node.next != NULL) {
-		typename List::node_type&	next_node =
-			elem1_node.next->*list.node;
+  if (elem1_node.next != NULL)
+  {
+    typename List::node_type &next_node= elem1_node.next->*list.node;
 
-		next_node.prev = elem2;
-	}
+    next_node.prev= elem2;
+  }
 
-	elem1_node.next = elem2;
+  elem1_node.next= elem2;
 
-	if (list.end == elem1) {
-		list.end = elem2;
-	}
+  if (list.end == elem1)
+  {
+    list.end= elem2;
+  }
 
-	++list.count;
+  ++list.count;
 }
 
-/*******************************************************************//**
-Inserts a ELEM2 after ELEM1 in a list.
-@param LIST list base node (not a pointer to it)
-@param ELEM1 node after which ELEM2 is inserted
-@param ELEM2 node being inserted after ELEM1 */
-#define UT_LIST_INSERT_AFTER(LIST, ELEM1, ELEM2)			\
-	ut_list_insert(LIST, ELEM1, ELEM2)
-
-/*******************************************************************//**
-Inserts a ELEM2 after ELEM1 in a list.
-@param list the base node
-@param elem1 node after which ELEM2 is inserted
-@param elem2 node being inserted after ELEM1
-@param get_node to get the list node for that element */
+/*******************************************************************/ /**
+ Inserts a ELEM2 after ELEM1 in a list.
+ @param LIST list base node (not a pointer to it)
+ @param ELEM1 node after which ELEM2 is inserted
+ @param ELEM2 node being inserted after ELEM1 */
+#define UT_LIST_INSERT_AFTER(LIST, ELEM1, ELEM2)                              \
+  ut_list_insert(LIST, ELEM1, ELEM2)
+
+/*******************************************************************/ /**
+ Inserts a ELEM2 after ELEM1 in a list.
+ @param list the base node
+ @param elem1 node after which ELEM2 is inserted
+ @param elem2 node being inserted after ELEM1
+ @param get_node to get the list node for that element */
 
 template <typename List, typename Functor>
-void
-ut_list_insert(
-	List&				list,
-	typename List::elem_type*	elem1,
-        typename List::elem_type*	elem2,
-	Functor				get_node)
+void ut_list_insert(List &list, typename List::elem_type *elem1,
+                    typename List::elem_type *elem2, Functor get_node)
 {
-	ut_ad(elem1 != elem2);
-	UT_LIST_IS_INITIALISED(list);
-
-	typename List::node_type&	elem1_node = get_node(*elem1);
-	typename List::node_type&	elem2_node = get_node(*elem2);
+  ut_ad(elem1 != elem2);
+  UT_LIST_IS_INITIALISED(list);
 
-	elem2_node.prev = elem1;
-	elem2_node.next = elem1_node.next;
+  typename List::node_type &elem1_node= get_node(*elem1);
+  typename List::node_type &elem2_node= get_node(*elem2);
 
-	if (elem1_node.next != NULL) {
-		typename List::node_type&	next_node =
-			get_node(*elem1_node.next);
+  elem2_node.prev= elem1;
+  elem2_node.next= elem1_node.next;
 
-		next_node.prev = elem2;
-	}
+  if (elem1_node.next != NULL)
+  {
+    typename List::node_type &next_node= get_node(*elem1_node.next);
 
-	elem1_node.next = elem2;
+    next_node.prev= elem2;
+  }
 
-	if (list.end == elem1) {
-		list.end = elem2;
-	}
+  elem1_node.next= elem2;
 
-	++list.count;
+  if (list.end == elem1)
+  {
+    list.end= elem2;
+  }
 
+  ++list.count;
 }
-/*******************************************************************//**
-Removes a node from a two-way linked list.
-@param list the base node (not a pointer to it)
-@param node member node within list element that is to be removed
-@param get_node functor to get the list node from elem */
+/*******************************************************************/ /**
+ Removes a node from a two-way linked list.
+ @param list the base node (not a pointer to it)
+ @param node member node within list element that is to be removed
+ @param get_node functor to get the list node from elem */
 template <typename List, typename Functor>
-void
-ut_list_remove(
-	List&				list,
-	typename List::node_type&	node,
-	Functor				get_node)
+void ut_list_remove(List &list, typename List::node_type &node,
+                    Functor get_node)
 {
-	ut_a(list.count > 0);
-	UT_LIST_IS_INITIALISED(list);
-
-	if (node.next != NULL) {
-		typename List::node_type&	next_node =
-			get_node(*node.next);
-
-		next_node.prev = node.prev;
-	} else {
-		list.end = node.prev;
-	}
-
-	if (node.prev != NULL) {
-		typename List::node_type&	prev_node =
-			get_node(*node.prev);
-
-		prev_node.next = node.next;
-	} else {
-		list.start = node.next;
-	}
-
-	node.next = 0;
-	node.prev = 0;
-
-	--list.count;
+  ut_a(list.count > 0);
+  UT_LIST_IS_INITIALISED(list);
+
+  if (node.next != NULL)
+  {
+    typename List::node_type &next_node= get_node(*node.next);
+
+    next_node.prev= node.prev;
+  }
+  else
+  {
+    list.end= node.prev;
+  }
+
+  if (node.prev != NULL)
+  {
+    typename List::node_type &prev_node= get_node(*node.prev);
+
+    prev_node.next= node.next;
+  }
+  else
+  {
+    list.start= node.next;
+  }
+
+  node.next= 0;
+  node.prev= 0;
+
+  --list.count;
 }
 
-/*******************************************************************//**
-Removes a node from a two-way linked list.
-@param list the base node (not a pointer to it)
-@param elem element to be removed from the list
-@param get_node functor to get the list node from elem */
+/*******************************************************************/ /**
+ Removes a node from a two-way linked list.
+ @param list the base node (not a pointer to it)
+ @param elem element to be removed from the list
+ @param get_node functor to get the list node from elem */
 template <typename List, typename Functor>
-void
-ut_list_remove(
-	List&				list,
-	typename List::elem_type*	elem,
-	Functor				get_node)
+void ut_list_remove(List &list, typename List::elem_type *elem,
+                    Functor get_node)
 {
-	ut_list_remove(list, get_node(*elem), get_node);
+  ut_list_remove(list, get_node(*elem), get_node);
 }
 
-/*******************************************************************//**
-Removes a node from a two-way linked list.
-@param list the base node (not a pointer to it)
-@param elem element to be removed from the list */
+/*******************************************************************/ /**
+ Removes a node from a two-way linked list.
+ @param list the base node (not a pointer to it)
+ @param elem element to be removed from the list */
 template <typename List>
-void
-ut_list_remove(
-	List&				list,
-	typename List::elem_type*	elem)
+void ut_list_remove(List &list, typename List::elem_type *elem)
 {
-	ut_list_remove(
-		list, elem->*list.node,
-		GenericGetNode<typename List::elem_type>(list.node));
+  ut_list_remove(list, elem->*list.node,
+                 GenericGetNode<typename List::elem_type>(list.node));
 }
 
-/*******************************************************************//**
-Removes a node from a two-way linked list.
-@param LIST the base node (not a pointer to it)
-@param ELEM node to be removed from the list */
-#define UT_LIST_REMOVE(LIST, ELEM)	ut_list_remove(LIST, ELEM)
-
-/********************************************************************//**
-Gets the next node in a two-way list.
-@param NAME list name
-@param N pointer to a node
-@return the successor of N in NAME, or NULL */
-#define UT_LIST_GET_NEXT(NAME, N)	(((N)->NAME).next)
-
-/********************************************************************//**
-Gets the previous node in a two-way list.
-@param NAME list name
-@param N pointer to a node
-@return the predecessor of N in NAME, or NULL */
-#define UT_LIST_GET_PREV(NAME, N)	(((N)->NAME).prev)
-
-/********************************************************************//**
-Alternative macro to get the number of nodes in a two-way list, i.e.,
-its length.
-@param BASE the base node (not a pointer to it).
-@return the number of nodes in the list */
-#define UT_LIST_GET_LEN(BASE)		(BASE).count
-
-/********************************************************************//**
-Gets the first node in a two-way list.
-@param BASE the base node (not a pointer to it)
-@return first node, or NULL if the list is empty */
-#define UT_LIST_GET_FIRST(BASE)		(BASE).start
-
-/********************************************************************//**
-Gets the last node in a two-way list.
-@param BASE the base node (not a pointer to it)
-@return last node, or NULL if the list is empty */
-#define UT_LIST_GET_LAST(BASE)		(BASE).end
-
-struct NullValidate { void operator()(const void*) const {} };
+/*******************************************************************/ /**
+ Removes a node from a two-way linked list.
+ @param LIST the base node (not a pointer to it)
+ @param ELEM node to be removed from the list */
+#define UT_LIST_REMOVE(LIST, ELEM) ut_list_remove(LIST, ELEM)
+
+/********************************************************************/ /**
+ Gets the next node in a two-way list.
+ @param NAME list name
+ @param N pointer to a node
+ @return the successor of N in NAME, or NULL */
+#define UT_LIST_GET_NEXT(NAME, N) (((N)->NAME).next)
+
+/********************************************************************/ /**
+ Gets the previous node in a two-way list.
+ @param NAME list name
+ @param N pointer to a node
+ @return the predecessor of N in NAME, or NULL */
+#define UT_LIST_GET_PREV(NAME, N) (((N)->NAME).prev)
+
+/********************************************************************/ /**
+ Alternative macro to get the number of nodes in a two-way list, i.e.,
+ its length.
+ @param BASE the base node (not a pointer to it).
+ @return the number of nodes in the list */
+#define UT_LIST_GET_LEN(BASE) (BASE).count
+
+/********************************************************************/ /**
+ Gets the first node in a two-way list.
+ @param BASE the base node (not a pointer to it)
+ @return first node, or NULL if the list is empty */
+#define UT_LIST_GET_FIRST(BASE) (BASE).start
+
+/********************************************************************/ /**
+ Gets the last node in a two-way list.
+ @param BASE the base node (not a pointer to it)
+ @return last node, or NULL if the list is empty */
+#define UT_LIST_GET_LAST(BASE) (BASE).end
+
+struct NullValidate
+{
+  void operator()(const void *) const {}
+};
 
 /** Iterate over all the elements and call the functor for each element.
 @param[in]	list	base node (not a pointer to it)
 @param[in,out]	functor	Functor that is called for each element in the list */
 template <typename List, class Functor>
-inline void ut_list_map(const List& list, Functor& functor)
+inline void ut_list_map(const List &list, Functor &functor)
 {
-	ulint count = 0;
+  ulint count= 0;
 
-	UT_LIST_IS_INITIALISED(list);
+  UT_LIST_IS_INITIALISED(list);
 
-	for (typename List::elem_type* elem = list.start; elem;
-	     elem = (elem->*list.node).next, ++count) {
+  for (typename List::elem_type *elem= list.start; elem;
+       elem= (elem->*list.node).next, ++count)
+  {
 
-		functor(elem);
-	}
+    functor(elem);
+  }
 
-	ut_a(count == list.count);
+  ut_a(count == list.count);
 }
 
 /** Iterate over all the elements and call the functor for each element.
 @param[in]	list	base node (not a pointer to it)
 @param[in]	functor	Functor that is called for each element in the list */
 template <typename List, class Functor>
-inline void ut_list_map(const List& list, const Functor& functor)
+inline void ut_list_map(const List &list, const Functor &functor)
 {
-	ulint count = 0;
+  ulint count= 0;
 
-	UT_LIST_IS_INITIALISED(list);
+  UT_LIST_IS_INITIALISED(list);
 
-	for (typename List::elem_type* elem = list.start; elem;
-	     elem = (elem->*list.node).next, ++count) {
+  for (typename List::elem_type *elem= list.start; elem;
+       elem= (elem->*list.node).next, ++count)
+  {
 
-		functor(elem);
-	}
+    functor(elem);
+  }
 
-	ut_a(count == list.count);
+  ut_a(count == list.count);
 }
 
 /** Check the consistency of a doubly linked list.
 @param[in] list		base node (not a pointer to it)
 @param[in,out] functor	Functor that is called for each element in the list */
 template <typename List, class Functor>
-void ut_list_validate(const List& list, Functor& functor)
+void ut_list_validate(const List &list, Functor &functor)
 {
-	ut_list_map(list, functor);
+  ut_list_map(list, functor);
 
-	/* Validate the list backwards. */
-	ulint		count = 0;
+  /* Validate the list backwards. */
+  ulint count= 0;
 
-	for (typename List::elem_type* elem = list.end;
-	     elem != 0;
-	     elem = (elem->*list.node).prev) {
-		++count;
-	}
+  for (typename List::elem_type *elem= list.end; elem != 0;
+       elem= (elem->*list.node).prev)
+  {
+    ++count;
+  }
 
-	ut_a(count == list.count);
+  ut_a(count == list.count);
 }
 
 /** Check the consistency of a doubly linked list.
 @param[in] list		base node (not a pointer to it)
 @param[in] functor	Functor that is called for each element in the list */
 template <typename List, class Functor>
-inline void ut_list_validate(const List& list, const Functor& functor)
+inline void ut_list_validate(const List &list, const Functor &functor)
 {
-	ut_list_map(list, functor);
+  ut_list_map(list, functor);
 
-	/* Validate the list backwards. */
-	ulint		count = 0;
+  /* Validate the list backwards. */
+  ulint count= 0;
 
-	for (typename List::elem_type* elem = list.end;
-	     elem != 0;
-	     elem = (elem->*list.node).prev) {
-		++count;
-	}
+  for (typename List::elem_type *elem= list.end; elem != 0;
+       elem= (elem->*list.node).prev)
+  {
+    ++count;
+  }
 
-	ut_a(count == list.count);
+  ut_a(count == list.count);
 }
 
-template <typename List>
-inline void ut_list_validate(const List& list)
+template <typename List> inline void ut_list_validate(const List &list)
 {
-	ut_list_validate(list, NullValidate());
+  ut_list_validate(list, NullValidate());
 }
 
 #ifdef UNIV_DEBUG
-template <typename List>
-inline void ut_list_reverse(List& list)
+template <typename List> inline void ut_list_reverse(List &list)
 {
-	UT_LIST_IS_INITIALISED(list);
+  UT_LIST_IS_INITIALISED(list);
 
-	for (typename List::elem_type* elem = list.start;
-	     elem != 0;
-	     elem = (elem->*list.node).prev) {
-		(elem->*list.node).reverse();
-	}
+  for (typename List::elem_type *elem= list.start; elem != 0;
+       elem= (elem->*list.node).prev)
+  {
+    (elem->*list.node).reverse();
+  }
 
-	list.reverse();
+  list.reverse();
 }
 
 /** Check if the given element exists in the list.
 @param[in,out]	list	the list object
 @param[in]	elem	the element of the list which will be checked */
 template <typename List>
-inline bool ut_list_exists(const List& list, typename List::elem_type* elem)
+inline bool ut_list_exists(const List &list, typename List::elem_type *elem)
 {
-	for (typename List::elem_type* e1 = UT_LIST_GET_FIRST(list); e1;
-	     e1 = (e1->*list.node).next) {
-		if (elem == e1) {
-			return true;
-		}
-	}
-	return false;
+  for (typename List::elem_type *e1= UT_LIST_GET_FIRST(list); e1;
+       e1= (e1->*list.node).next)
+  {
+    if (elem == e1)
+    {
+      return true;
+    }
+  }
+  return false;
 }
 #endif
 
 /** Move the given element to the beginning of the list.
 @param[in,out]	list	the list object
 @param[in]	elem	the element of the list which will be moved
-			to the beginning of the list. */
+                        to the beginning of the list. */
 template <typename List>
-void
-ut_list_move_to_front(
-	List&				list,
-	typename List::elem_type*	elem)
+void ut_list_move_to_front(List &list, typename List::elem_type *elem)
 {
-	ut_ad(ut_list_exists(list, elem));
+  ut_ad(ut_list_exists(list, elem));
 
-	if (UT_LIST_GET_FIRST(list) != elem) {
-		ut_list_remove(list, elem);
-		ut_list_prepend(list, elem);
-	}
+  if (UT_LIST_GET_FIRST(list) != elem)
+  {
+    ut_list_remove(list, elem);
+    ut_list_prepend(list, elem);
+  }
 }
 
 #ifdef UNIV_DEBUG
